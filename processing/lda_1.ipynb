{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import lda\n",
    "import textmining\n",
    "import pickle\n",
    "from ggplot import *\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "data.to_csv('./data_pd.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./pickles/data_pd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bokeh_plot(data_in, num_points, x_col, y_col, title, tooltips):\n",
    "    shuffle = np.random.permutation(data_in.shape[0])\n",
    "    data_rdm = data_in.loc[shuffle[:num_points], :].copy()\n",
    "    output_notebook()\n",
    "    plot_tfidf = bp.figure(plot_width=700, plot_height=600, title=title,\n",
    "        tools=\"pan, wheel_zoom, box_zoom, reset, hover, previewsave\",\n",
    "        x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "    plot_tfidf.scatter(x=x_col, y=y_col, source=data_rdm)\n",
    "    hover = plot_tfidf.select(dict(type=HoverTool))\n",
    "    hover.tooltips=tooltips\n",
    "    show(plot_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ggplot_plot(data_in, num_points, x_col, y_col, title): \n",
    "    rndperm = np.random.permutation(data_in.shape[0])\n",
    "    data_rdm = data_in.loc[rndperm[:num_points], :].copy()\n",
    "    chart = ggplot(data_rdm, aes(x=x_col, y=y_col) ) \\\n",
    "            + geom_point(size=75,alpha=0.8) \\\n",
    "            + ggtitle(title)\n",
    "    chart.show()\n",
    "# ggplot_plot(data, 4000, 'pca-one', 'pca-two', 'TF-IDF Clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_plot(df, mat, n_components):\n",
    "    if n_components < 2: raise ValueError('Needs to be > 3 components')\n",
    "    ursvd = PCA(n_components=10)\n",
    "    ursvd_res = ursvd.fit_transform(mat)\n",
    "    df['pca-one'] = ursvd_res[:,0]\n",
    "    df['pca-two'] = ursvd_res[:,1] \n",
    "    df['pca-three'] = ursvd_res[:,2]\n",
    "    print('Variation per principal component: {}'.format(ursvd.explained_variance_ratio_))\n",
    "    bokeh_plot(df, 4000, 'pca-one', 'pca-two', 'PCA Clustering', {\"title\": \"@title\", \"authors\":\"@authors\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TSVD_plot(df, mat, n_components):\n",
    "    if n_components < 2: raise ValueError('Needs to be > 3 components')\n",
    "    ursvd = TruncatedSVD(n_components=10)\n",
    "    ursvd_res = ursvd.fit_transform(mat)\n",
    "    df['pca-one'] = ursvd_res[:,0]\n",
    "    df['pca-two'] = ursvd_res[:,1] \n",
    "    df['pca-three'] = ursvd_res[:,2]\n",
    "    print('Variation per principal component: {}'.format(ursvd.explained_variance_ratio_))\n",
    "    bokeh_plot(df, 4000, 'pca-one', 'pca-two', 'PCA Clustering', {\"title\": \"@title\", \"authors\":\"@authors\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF - then TruncatedSVD (PCA with Spare Matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vz_mat = TfidfVectorizer(min_df=5, max_features=30000, stop_words = 'english').fit_transform(data['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TSVD_plot(data, vz_mat, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "#### Using the approximation that there are ~ 50 papers per overarching topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdm = textmining.TermDocumentMatrix()\n",
    "for row in data['summary'].values:\n",
    "    row_text = ' '.join(textmining.simple_tokenize_remove_stopwords(row))\n",
    "    tdm.add_doc(row_text)\n",
    "tdm.write_csv('./pickles/lda_prep/tdm.csv', cutoff=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = pd.read_csv('./pickles/lda_prep/tdm.csv', dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full_file = np.array(tdm.rows(cutoff=5))\n",
    "vocab = file.columns.values\n",
    "X = np.array(file.iloc[0:, :].values) #NOTE THE ONE OFFSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = {}\n",
    "i = 0\n",
    "for item in vocab:\n",
    "    id2word[i] = item\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = lda.LDA(n_topics=int(len(data)/50), n_iter=1500, random_state=1) #NOTE THE ONE OFFSET ON THE SAVED FILES\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "print(np.shape(doc_topic))\n",
    "for i in range(10):\n",
    "     print(\"{} (top topic: {})\".format(i, doc_topic[i].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pca_plot(data, topic_dist, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file=open('./pickles/lda_topics.pickle', 'wb'), obj=topic_word)\n",
    "pickle.dump(file=open('./pickles/lda_dist.pickle', 'wb'), obj=doc_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Gensim instead of LDA (with Mallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(line.strip() for line in open('./pickles/lda_prep/stopwords.txt'))\n",
    "texts = [[i for i in doc.lower().split() if i not in stopwords] for doc in data['summary'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file = open('./pickles/lda_prep/text_stopped.pickle', 'wb'), obj=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts) #Create Gensim Dictionary\n",
    "dictionary.filter_extremes(no_below=10, no_above=1.0, keep_n=None) #Filter extremes\n",
    "corpus = [dictionary.doc2bow(text) for text in texts] #NOW CONVERT TO DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.save('./pickles/lda_prep/text_dict.txtdic') #Save backup\n",
    "pickle.dump(file=open('./pickles/lda_prep/text_corpus.corpus', 'wb'), obj=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.wrappers.LdaMallet('../../Mallet/bin/mallet', corpus, num_topics=750, iterations=2000, id2word=dictionary)\n",
    "docs_corpus = model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs_corpus = np.array(docs_corpus) #Topic model corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learnt_topics = model.show_topics(num_topics=-1, num_words=15, log=False, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file = open('./pickles/mallet_learnt_topics.pickle', 'wb'), obj = learnt_topics)\n",
    "pickle.dump(file = open('./pickles/mallet_doc_corpus.pickle', 'wb'), obj = docs_corpus[:,:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17060,\n",
       "  'Continuous State-Space Models for Optimal Sepsis Treatment - a Deep\\n  Reinforcement Learning Approach')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in enumerate(data['title'].values) if 'Continuous State-Space Models for Optimal Sepsis Treatment' in i[1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                                17060\n",
      "title         Continuous State-Space Models for Optimal Seps...\n",
      "summary       Sepsis is a leading cause of mortality in inte...\n",
      "date                                                 1495559591\n",
      "authors       ['Aniruddh Raghu', 'Matthieu Komorowski', 'Leo...\n",
      "tags                                                  ['cs.LG']\n",
      "Name: 17060, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[17060, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
