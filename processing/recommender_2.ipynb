{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import bokeh as bk\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from bokeh.models import ColumnDataSource\n",
    "import bokeh.plotting \n",
    "from bokeh.models.graphs import from_networkx, NodesAndLinkedEdges, EdgesAndLinkedNodes, StaticLayoutProvider\n",
    "from bokeh.palettes import Spectral4, Spectral8, Paired8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matplot(distribution): \n",
    "    plt.scatter(np.arange(len(distribution)), distribution)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bokeh_plot(data_in, num_points, x_col, y_col, title, tooltips):\n",
    "    shuffle = np.random.permutation(data_in.shape[0])\n",
    "    data_rdm = data_in.loc[shuffle[:num_points], :].copy()\n",
    "    output_notebook()\n",
    "    plot_tfidf = bk.plotting.figure(plot_width=700, plot_height=600, title=title,\n",
    "        tools=\"pan, wheel_zoom, box_zoom, reset, hover, previewsave\",\n",
    "        x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "    plot_tfidf.scatter(x=x_col, y=y_col, source=data_rdm)\n",
    "    hover = plot_tfidf.select(dict(type=HoverTool))\n",
    "    hover.tooltips=tooltips\n",
    "    show(plot_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_plot(df, mat, n_components):\n",
    "    if n_components < 2: raise ValueError('Needs to be > 3 components')\n",
    "    ursvd = PCA(n_components=10)\n",
    "    ursvd_res = ursvd.fit_transform(mat)\n",
    "    df['pca-one'] = ursvd_res[:,0]\n",
    "    df['pca-two'] = ursvd_res[:,1] \n",
    "    df['pca-three'] = ursvd_res[:,2]\n",
    "    print('Variation per principal component: {}'.format(ursvd.explained_variance_ratio_))\n",
    "    bokeh_plot(df, 4000, 'pca-one', 'pca-two', 'PCA Clustering', {\"title\": \"@title\", \"authors\":\"@authors\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_original = pd.read_csv('./pickles/data_pd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of summary lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066.30492214\n",
      "26\n",
      "3871\n",
      "362.949552699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x112ed2ac8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD3CAYAAAAQYlNPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112ed2080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summaries = data_original['summary'].values\n",
    "lengths = np.array([len(i) for i in summaries])\n",
    "print(np.mean(lengths))\n",
    "print(np.min(lengths))\n",
    "print(np.max(lengths))\n",
    "print(np.sqrt(np.var(lengths)))\n",
    "sns.distplot(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_corpus = pickle.load(file=open('./pickles/mallet_doc_corpus.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>date</th>\n",
       "      <th>authors</th>\n",
       "      <th>tags</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Minimax deviation strategies for machine learn...</td>\n",
       "      <td>The article is devoted to the problem of small...</td>\n",
       "      <td>1500196508</td>\n",
       "      <td>['Michail Schlesinger', 'Evgeniy Vodolazskiy']</td>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>1707.04849v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mlbench: How Good Are Machine Learning Clouds ...</td>\n",
       "      <td>We conduct an empirical study of machine learn...</td>\n",
       "      <td>1501365558</td>\n",
       "      <td>['Hantian Zhang', 'Luyuan Zeng', 'Wentao Wu', ...</td>\n",
       "      <td>['cs.DC', 'cs.LG', 'stat.ML']</td>\n",
       "      <td>1707.09562v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Introduction to Machine Learning: Class Notes ...</td>\n",
       "      <td>Introduction to Machine learning covering Stat...</td>\n",
       "      <td>1240486857</td>\n",
       "      <td>['Amnon Shashua']</td>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>0904.3664v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AutoCompete: A Framework for Machine Learning ...</td>\n",
       "      <td>In this paper, we propose AutoCompete, a highl...</td>\n",
       "      <td>1436368059</td>\n",
       "      <td>['Abhishek Thakur', 'Artus Krohn-Grimberghe']</td>\n",
       "      <td>['stat.ML', 'cs.LG']</td>\n",
       "      <td>1507.02188v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Joint Training of Deep Boltzmann Machines</td>\n",
       "      <td>We introduce a new method for training deep Bo...</td>\n",
       "      <td>1355277567</td>\n",
       "      <td>['Ian Goodfellow', 'Aaron Courville', 'Yoshua ...</td>\n",
       "      <td>['stat.ML', 'cs.LG']</td>\n",
       "      <td>1212.2686v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Minimax deviation strategies for machine learn...   \n",
       "1           1  mlbench: How Good Are Machine Learning Clouds ...   \n",
       "2           2  Introduction to Machine Learning: Class Notes ...   \n",
       "3           3  AutoCompete: A Framework for Machine Learning ...   \n",
       "4           4          Joint Training of Deep Boltzmann Machines   \n",
       "\n",
       "                                             summary        date  \\\n",
       "0  The article is devoted to the problem of small...  1500196508   \n",
       "1  We conduct an empirical study of machine learn...  1501365558   \n",
       "2  Introduction to Machine learning covering Stat...  1240486857   \n",
       "3  In this paper, we propose AutoCompete, a highl...  1436368059   \n",
       "4  We introduce a new method for training deep Bo...  1355277567   \n",
       "\n",
       "                                             authors  \\\n",
       "0     ['Michail Schlesinger', 'Evgeniy Vodolazskiy']   \n",
       "1  ['Hantian Zhang', 'Luyuan Zeng', 'Wentao Wu', ...   \n",
       "2                                  ['Amnon Shashua']   \n",
       "3      ['Abhishek Thakur', 'Artus Krohn-Grimberghe']   \n",
       "4  ['Ian Goodfellow', 'Aaron Courville', 'Yoshua ...   \n",
       "\n",
       "                            tags            id  \n",
       "0                      ['cs.LG']  1707.04849v1  \n",
       "1  ['cs.DC', 'cs.LG', 'stat.ML']  1707.09562v2  \n",
       "2                      ['cs.LG']   0904.3664v1  \n",
       "3           ['stat.ML', 'cs.LG']  1507.02188v1  \n",
       "4           ['stat.ML', 'cs.LG']   1212.2686v1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Topic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_words = pickle.load(file = open('./pickles/mallet_learnt_topics.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " [('however,', 0.11407316),\n",
       "  ('and,', 0.054866709),\n",
       "  ('therefore,', 0.051456913),\n",
       "  ('difficult', 0.042467453),\n",
       "  ('typically', 0.04184749),\n",
       "  ('thus,', 0.038437694),\n",
       "  ('paper,', 0.037817731),\n",
       "  ('requires', 0.034717917),\n",
       "  ('numerous', 0.023248605),\n",
       "  ('moreover,', 0.023248605),\n",
       "  ('generally', 0.01983881),\n",
       "  ('hence,', 0.019528829),\n",
       "  ('unfortunately,', 0.018598884),\n",
       "  ('highly', 0.018288903),\n",
       "  ('suitable', 0.017048977)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 Input topics\n",
      "Setting topic threshold at 0.1\n",
      "Pruned to 598 topics\n",
      "Zeroing any values below 0.01\n"
     ]
    }
   ],
   "source": [
    "#Get Topics\n",
    "topic_words = pickle.load(file=open('./pickles/mallet_learnt_topics.pickle','rb'))\n",
    "topics = [0]*len(topic_words)\n",
    "i = 0\n",
    "for topic in topic_words:\n",
    "    topics[i] = np.array(topic[1])[:, 0]\n",
    "    i+=1\n",
    "print(len(topics), 'Input topics')\n",
    "\n",
    "#Augment Vector if Required\n",
    "data_in = data_corpus[:]\n",
    "data_agg = np.zeros(np.shape(data_in)[1])\n",
    "threshold = 0.10\n",
    "min_score = 1\n",
    "threshold_prob = 0.01\n",
    "\n",
    "#Set baseline threshold for entire corpus\n",
    "print('Setting topic threshold at', threshold)\n",
    "for paper in data_in:\n",
    "    chk = paper[paper > threshold]\n",
    "    data_agg = np.add(data_agg, (paper > threshold).astype(int))\n",
    "prune = (data_agg >= min_score).astype(int) #Stuff to keep\n",
    "idx_arr = np.arange(np.shape(data_in)[1])\n",
    "\n",
    "idx_arr = idx_arr[prune == 0]\n",
    "#Clean corresponding topics\n",
    "for i in reversed(idx_arr):\n",
    "    del(topics[i])\n",
    "    del(topic_words[i])\n",
    "    \n",
    "data_in = data_in[:, prune == 1]\n",
    "print('Pruned to', len(topics), 'topics')\n",
    "\n",
    "#Remove near-zero values\n",
    "data_in[data_in < threshold_prob] = 0\n",
    "print('Zeroing any values below', threshold_prob)\n",
    "\n",
    "#Sum to 1?\n",
    "sum_one = np.sum(data_in, axis = 1)\n",
    "sum_one[sum_one == 0] = 1 #Resolve any 0 errors\n",
    "\n",
    "data_in = data_in/sum_one[:,None]\n",
    "\n",
    "# data_in = StandardScaler().fit_transform(data_in)\n",
    "# print('Normalised to zero-mean and unit variance')\n",
    "# OR\n",
    "# data_in = np.subtract(data_in, np.min(data_in, axis = 0))/(np.max(data_in, axis = 0) - np.min(data_in, axis = 0))\n",
    "# print('Max-min normalised')\n",
    "# sns.distplot(data_in[:, 5])\n",
    "#data_in = np.subtract(data_in, np.mean(data_in, axis = 0))/np.var(data_in, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain' 'functional' 'imaging' 'connectivity' 'magnetic' 'fmri'\n",
      " 'cognitive' 'neuroimaging' 'human' 'resonance' 'analysis' 'activity'\n",
      " 'subjects' 'studies' 'data']\n",
      "['fault' 'monitoring' 'failure' 'machine' 'systems' 'tolerance'\n",
      " 'maintenance' 'failures' 'execution' 'high' 'faults' 'distributed'\n",
      " 'replication' 'ensure' 'reliable']\n",
      "['candidate' 'set' 'results' 'candidates' 'find' 'select' 'selecting'\n",
      " 'selected' 'good' 'approach' 'promising' 'pool' 'ideal' 'propose'\n",
      " 'identify']\n",
      "['social' 'media' 'twitter' 'users' 'information' 'tweets' 'online'\n",
      " 'content' 'user' 'facebook' 'public' 'posts' 'media.' 'tweet' 'accounts']\n",
      "['polynomial' 'time' 'problem' 'give' 'exponential' 'algorithm' 'hardness'\n",
      " 'result' 'complexity' 'time.' 'constant' 'bounded' 'hard' 'prove' 'number']\n",
      "['cloud' 'computing' 'service' 'management' 'services' 'resources'\n",
      " 'infrastructure' 'applications' 'grid' 'resource' 'deployment'\n",
      " 'distributed' 'execution' 'virtual' 'services.']\n",
      "['energy' 'consumption' 'power' 'demand' 'load' 'electricity' 'smart'\n",
      " 'reduce' 'usage' 'temperature' 'consumption.' 'thermal' 'efficiency'\n",
      " 'energy.' 'achieve']\n",
      "['projection' 'random' 'projections' 'method' 'high-dimensional'\n",
      " 'projected' 'data' 'original' 'theoretical' 'data.' 'experiments'\n",
      " 'reduction' 'leads' 'projecting' 'dimensionality']\n",
      "['role' 'important' 'play' 'plays' 'roles' 'key' 'crucial' 'central'\n",
      " 'understanding' 'playing' 'major' 'played' 'role.' 'essential' 'vital']\n",
      "['gradient' 'descent' 'stochastic' 'sgd' 'gradients' 'optimization'\n",
      " 'mirror' 'convergence' '(sgd)' 'updates' 'update' 'projected' 'descent.'\n",
      " 'descent,' 'conjugate']\n",
      "['learning' 'technology' 'management' 'technologies' 'e-learning'\n",
      " 'research' 'tools' 'collaborative' 'educational' 'provide' 'support'\n",
      " 'education' 'development' 'environment' 'enhance']\n",
      "['vector' 'vectors' 'product' 'vectors.' 'vectors,' 'linear' 'vector.'\n",
      " 'represented' 'vector,' 'representing' 'dot' 'quantization' 'similar'\n",
      " 'input' 'scalar']\n",
      "['algorithms' 'algorithm' 'algorithms.' 'algorithms,' 'existing'\n",
      " 'algorithm,' 'analyze' 'design' 'well-known' 'vertical' 'work.'\n",
      " 'fundamentally' 'slightly' 'refer' 'gradually']\n",
      "['operator' 'operators' 'present' 'splitting' 'proximity' 'operator.'\n",
      " 'proximal' 'efficiently' 'operators.' 'computed' 'called' 'operator,'\n",
      " 'elementary' 'problems' 'operators,']\n",
      "['language' 'grammar' 'natural' 'abstract' 'machine' 'grammars' 'formal'\n",
      " 'language,' 'present' 'syntax' 'language.' 'languages' 'formalism' 'paper'\n",
      " 'describe']\n",
      "['cancer' 'diagnosis' 'disease' 'accuracy' 'patients' 'diagnostic' 'breast'\n",
      " 'classification' 'medical' 'clinical' 'sensitivity' 'tumor' 'lung'\n",
      " 'tissue' 'diseases']\n",
      "['data' 'survey' 'present' 'astronomical' 'galaxy' 'large' 'surveys'\n",
      " 'photometric' 'machine' 'scientific' 'sky' 'observed' 'sources' 'variable'\n",
      " 'astronomy']\n",
      "['concept' 'concepts' 'planning' 'learning' 'drift' 'plan' 'plans'\n",
      " 'concepts.' 'introduce' 'learned' 'specific' 'integrated' 'planning.'\n",
      " 'context' 'concept,']\n",
      "['experiments' 'proposed' 'extensive' 'propose' 'existing' 'datasets'\n",
      " 'state-of-the-art' 'demonstrate' 'outperforms' 'specifically,' 'paper,'\n",
      " 'conducted' 'benchmark' 'validate' 'superiority']\n",
      "['class' 'problems' 'general' 'broad' 'including' 'includes' 'include'\n",
      " 'study' 'wide' 'broader' 'applies' 'applicable' 'range' 'refer' 'class,']\n",
      "['hashing' 'binary' 'hash' 'codes' 'retrieval' 'large-scale'\n",
      " 'state-of-the-art' 'search' 'similarity' 'image' 'compact' 'supervised'\n",
      " 'code' 'experiments' 'hamming']\n",
      "['scheduling' 'jobs' 'job' 'problem' 'time' 'machine' 'machines'\n",
      " 'processing' 'approximation' 'schedule' 'assignment' 'machines.'\n",
      " 'minimize' 'total' 'identical']\n",
      "['predictive' 'models' 'model' 'prediction' 'performance' 'predict'\n",
      " 'models.' 'accuracy' 'predicting' 'power' 'data.' 'model.' 'identifying'\n",
      " 'building' 'modeling']\n",
      "['random' 'forest' 'forests' 'trees' 'rf' 'regression' 'decision'\n",
      " 'ensemble' 'classification' 'accuracy' 'importance' 'methods' 'forests.'\n",
      " 'variable' 'good']\n",
      "['user' 'users' \"user's\" 'de' 'users.' 'profile' 'interactive' \"users'\"\n",
      " 'user.' 'interface' 'profiles' 'users,' 'la' 'user,' 'personalized']\n",
      "['direct' 'approach' 'directly' 'based' 'show' 'propose' 'indirect'\n",
      " 'demonstrate' 'application' 'requires' 'standard' 'actual' 'moreover,'\n",
      " 'paper,' 'alternative']\n",
      "['bias' 'variance' 'estimates' 'biased' 'however,' 'biases' 'lead'\n",
      " 'standard' 'reduce' 'unbiased' 'leads' 'importance' 'variance.' 'bias.'\n",
      " 'empirical']\n",
      "['loss' 'function' 'functions' 'loss.' 'losses' 'loss,' 'surrogate'\n",
      " 'function.' 'hinge' 'function,' 'convex' 'functions,' 'functions.'\n",
      " 'squared' 'losses.']\n",
      "['analysis' 'canonical' 'linear' 'correlation' 'discriminant' 'method'\n",
      " 'cca' 'proposed' 'analysis,' 'lda' 'applied' 'derived' 'spreadsheet'\n",
      " 'analysis.' 'common']\n",
      "['learning' 'tasks' 'multi-task' 'task' 'multiple' 'tasks.' 'related'\n",
      " 'tasks,' 'simultaneously' 'mtl' 'framework,' 'jointly' 'improve' 'task.'\n",
      " 'shared']\n",
      "['high' 'dimensional' 'low' 'dimensions.' 'dimensions' 'dimensions,'\n",
      " 'dimension' 'space.' 'higher' 'deal' 'dimensionality' 'dimensionality.'\n",
      " 'spaces.' 'high-dimensional' 'real']\n",
      "['system' 'system.' 'system,' 'systems' 'intelligent' 'systems,' 'systems.'\n",
      " 'implemented' 'developed' 'combined' 'composed' 'characteristics' 'only.'\n",
      " 'creating' 'automated']\n",
      "['error' 'generalization' 'error.' 'bounds' 'error,' 'bound' 'derive'\n",
      " 'expected' 'terms' 'bounded' 'squared' 'involves' 'minimizing'\n",
      " 'rademacher' 'depend']\n",
      "['derive' 'analytical' 'derived' 'numerical' 'analytic' 'formula' 'order'\n",
      " 'analytically' 'closed-form' 'deriving' 'form' 'expressions'\n",
      " 'approximations' 'expression' 'derivation']\n",
      "['segmentation' 'image' 'semantic' 'segmentation.' 'convolutional'\n",
      " 'segmentation,' 'fully' 'segment' 'segments' 'contour' 'pixel' 'images'\n",
      " 'labeling' 'task' 'segmenting']\n",
      "['mechanism' 'mechanisms' 'auction' 'design' 'optimal' 'truthful' 'price'\n",
      " 'mechanisms.' 'show' 'welfare' 'mechanism.' 'study' 'strategic' 'auctions'\n",
      " 'revenue']\n",
      "['behaviour' 'modelling' 'optimisation' 'analyse' 'generalisation'\n",
      " 'approach' 'behaviour.' 'kind' 'behaviours' 'behavioural' 'focus'\n",
      " 'modelled' 'behaviour,' 'neighbourhood' 'generalise']\n",
      "['gene' 'expression' 'data' 'genes' 'cancer' 'biological' 'analysis'\n",
      " 'genomic' 'microarray' 'data.' 'regulatory' 'dna' 'data,' 'genome'\n",
      " 'sequencing']\n",
      "['reinforcement' 'learning' 'agent' 'rl' 'reward' 'environments'\n",
      " 'environment' 'deep' 'rewards' 'atari' '(rl)' 'actions' 'exploration'\n",
      " 'learning.' 'policy']\n",
      "['learning' 'class' 'dimension' 'complexity' 'show' 'concept' 'agnostic'\n",
      " 'vc' 'pac' 'learnable' 'learnability' 'classes' 'dimension.' 'results'\n",
      " 'uniform']\n",
      "['explicit' 'implicit' 'introduce' 'explicitly' 'paper,' 'demonstrate'\n",
      " 'implicitly' 'approaches' 'makes' 'provide' 'avoids' 'furthermore,'\n",
      " 'additional' 'form' 'argue']\n",
      "['access' 'based' 'provide' 'random' 'protocol' 'control' 'paper,'\n",
      " 'complete' 'protocols' 'specifically,' 'implemented' 'number' 'consists'\n",
      " 'high' 'solution']\n",
      "['formulation' 'degrees' 'formulations' 'develop' 'framework' 'freedom'\n",
      " 'enables' 'efficient' 'formulation.' 'varying' 'formulate' 'form' 'derive'\n",
      " 'formulation,' 'empirical']\n",
      "['parallel' 'paper' 'machine' 'machining' 'fixed' 'angle' 'design'\n",
      " 'kinematic' 'tool' 'applications.' 'developed' 'workspace' 'analysis'\n",
      " 'moves' 'stiffness']\n",
      "['devices' 'cellular' 'wireless' 'communication' 'm2m' 'communications'\n",
      " 'machine-to-machine' 'massive' 'networks.' 'access' 'networks' '(m2m)'\n",
      " 'requirements' 'transmission' 'latency']\n",
      "['strategy' 'strategies' 'strategy,' 'strategies.' 'strategy.' 'effective'\n",
      " 'strategies,' 'work' 'choose' 'general,' 'leading' 'means' 'knowledge,'\n",
      " 'respect' 'large']\n",
      "['source' 'sources' 'separation' 'blind' 'sources.' 'sources,' 'source.'\n",
      " 'problem' 'components' 'separate' 'observed' 'here,' 'single' 'mixing'\n",
      " 'separation.']\n",
      "['structure' 'structures' 'structures.' 'underlying' 'intrinsic' 'complex'\n",
      " 'structures,' 'efficiently' 'structure.' 'called' 'capture' 'complicated'\n",
      " 'data,' 'structure,' 'manner.']\n",
      "['parameter' 'tuning' 'parameters' 'parameterized' 'regularization'\n",
      " 'parameter.' 'choice' 'parameter,' 'parameters.' 'parameters,' 'optimal'\n",
      " 'require' 'tunable' 'values' 'careful']\n",
      "['training' 'learning' 'testing' 'supervised' 'set,' 'set.' 'examples.'\n",
      " 'strategy' 'data,' 'examples' 'phase.' 'explore' 'increase' 'treating'\n",
      " 'substantially']\n",
      "['observations' 'observation' 'observations.' 'noisy' 'problem'\n",
      " 'observations,' 'unknown' 'underlying' 'observed' 'estimating' 'establish'\n",
      " 'past' 'estimate' 'case' 'illustrate']\n",
      "['geometric' 'material' 'algebraic' 'geometry' 'symmetry' 'materials'\n",
      " 'orientation' 'properties' 'spherical' 'planar' 'introduce' 'directional'\n",
      " 'possibility' 'fundamental' 'three-dimensional']\n",
      "['al.,' '&' 'al' 'shown' 'recently' 'al.' 'similar' 'previously' 'show'\n",
      " 'recent' 'result' 'note' '2014)' '2015)' '2015).']\n",
      "['study' 'studies' 'empirical' 'systematic' 'conduct' 'findings' 'analysis'\n",
      " 'comparative' 'suggest' 'extensive' 'investigate' 'found' 'popular'\n",
      " 'investigation' 'studies.']\n",
      "['discriminative' 'classification' 'learning' 'generative' 'discrimination'\n",
      " 'paper,' 'state-of-the-art' 'learn' 'propose' 'classification.'\n",
      " 'max-margin' 'demonstrate' 'ability' 'datasets' 'aims']\n",
      "['gaussian' 'process' 'gp' 'processes' 'regression' 'covariance' '(gp)'\n",
      " 'function' 'gps' 'functions' 'predictive' 'processes.' 'regression.'\n",
      " 'flexible' 'uncertainty']\n",
      "['number' 'constant' 'show' 'fixed' 'depends' 'independent' '(up'\n",
      " 'particular,' 'arbitrary' 'depending' 'that,' 'depend' 'constant.'\n",
      " 'setting' 'piecewise']\n",
      "['target' 'targets' 'source' 'proposed' 'multiple' 'targets.' 'radar'\n",
      " 'similar' 'target.' 'aperture' 'sar' 'target,' 'achieve' 'desired'\n",
      " 'conventional']\n",
      "['models' 'explain' 'understand' 'variability' 'explanation' 'provide'\n",
      " 'important' 'interpretable' 'complex' 'explanations' 'however,'\n",
      " 'difficult' 'interpretation' 'explaining' 'understanding']\n",
      "['dependency' 'parsing' 'parser' 'syntactic' 'tagging' 'parse'\n",
      " 'part-of-speech' 'present' 'pos' 'dependencies' 'accuracy' 'learns'\n",
      " 'representations' 'parsers' 'parsing,']\n",
      "['fully' 'connected' 'field' 'show' 'work' 'introduce' 'full' 'receptive'\n",
      " 'lattice' 'effectively' 'integrating' 'embedded' 'inspired' 'densely'\n",
      " 'applied']\n",
      "['word' 'embeddings' 'representations' 'embedding' 'words' 'vector'\n",
      " 'vectors' 'learn' 'semantic' 'embeddings.' 'representation' 'tasks'\n",
      " 'distributed' 'tasks.' 'embeddings,']\n",
      "['simple' 'easy' 'implement' 'simple,' 'easily' 'subsampling' 'practical'\n",
      " 'effective' 'efficient' 'conceptually' 'implement,' 'making' 'simpler'\n",
      " 'obtain' 'extremely']\n",
      "['prior' 'knowledge' 'knowledge.' 'incorporate' 'knowledge,' 'require'\n",
      " 'domain' 'form' 'available.' 'incorporating' 'priori' 'exploit'\n",
      " 'incorporation' 'beliefs' 'e.g.,']\n",
      "['rate' 'error' 'show' 'rates' 'rate.' 'rate,' 'obtain' 'decay'\n",
      " 'misclassification' 'achieves' 'equal' 'obtains' 'average' 'growth'\n",
      " 'finally,']\n",
      "['show' 'presence' 'leads' 'that,' 'results' 'absence' 'finally,'\n",
      " 'moreover,' 'leading' 'particular,' 'naturally' 'arises' 'pure' 'paper,'\n",
      " 'significant']\n",
      "['improve' 'performance' 'additional' 'significantly' 'improved' 'improves'\n",
      " 'performance.' 'augmentation' 'adding' 'improving' 'demonstrate' 'shown'\n",
      " 'benefits' 'achieving' 'increase']\n",
      "['performance' 'benchmark' 'evaluate' 'compare' 'comparison' 'benchmarks'\n",
      " 'standard' 'state-of-the-art' 'evaluation' 'competitive' 'present'\n",
      " 'benchmark.' 'benchmarking' 'comparable' 'benchmark,']\n",
      "['performance' 'cross-validation' 'sleep' 'achieved' 'simple' 'called'\n",
      " 'including' 'found' 'ability' 'estimate' 'key' 'applied' 'resampling'\n",
      " 'test' 'cross-validation.']\n",
      "['distributions' 'distribution' 'probability' 'distributions.'\n",
      " 'distributions,' 'distribution.' 'gaussian' 'moment' 'moments'\n",
      " 'distribution,' 'bernoulli' 'tail' 'family' 'heavy-tailed' 'multinomial']\n",
      "['applied' 'successfully' 'paper,' 'however,' 'proposed' 'age' 'widely'\n",
      " 'learning' 'based' 'recently,' 'addition,' 'personalized' 'aging'\n",
      " 'neighboring' 'moreover,']\n",
      "['interpretation' 'visualization' 'provide' 'present' 'intuitive'\n",
      " 'interactive' 'providing' 'visualize' 'interpreted' 'understanding'\n",
      " 'explore' 'insight' 'interpret' 'visualizing' 'means']\n",
      "['coding' 'codes' 'code' 'decoding' 'scheme' 'distortion' 'codes,'\n",
      " 'encoding' 'shown' 'codes.' 'coded' 'paper,' 'simultaneously' 'joint'\n",
      " 'redundancy']\n",
      "['based' 'reliable' 'key' 'characteristics' 'unique' 'provide'\n",
      " 'authentication' 'due' 'highly' 'biometric' 'required' 'reliably'\n",
      " 'ability' 'considered' 'identity']\n",
      "['automata' 'finite' 'languages' 'deterministic' 'machines' 'infinite'\n",
      " 'turing' 'show' 'automaton' 'probabilistic' 'pushdown' 'automata,' 'class'\n",
      " 'nondeterministic' 'rational']\n",
      "['asymptotic' 'sample' 'asymptotically' 'study' 'regime' 'prove' 'finite'\n",
      " 'size' 'theoretical' 'limit' 'properties' 'number' 'consistency' 'derive'\n",
      " 'behavior']\n",
      "['decision' 'making' 'decisions' 'make' 'made' 'decision-making'\n",
      " 'decisions.' 'makes' 'maker' 'goal' 'sequential' 'making.' 'decide'\n",
      " 'decisions,' 'complete']\n",
      "['predict' 'predicting' 'prediction' 'future' 'model' 'predicted'\n",
      " 'predicts' 'accurately' 'task' 'prediction.' 'current' 'predictions'\n",
      " 'dataset' 'long-term' 'train']\n",
      "['entity' 'entities' 'knowledge' 'named' 'information' 'base'\n",
      " 'state-of-the-art' 'record' 'entities.' 'names' 'entities,' 'task' 'facts'\n",
      " 'bases' 'coreference']\n",
      "['process' 'based' 'process.' 'process,' 'approach' 'order' 'propose'\n",
      " 'business' 'technique' 'information' 'making' 'change' 'driven'\n",
      " 'moreover,' 'involving']\n",
      "['number' 'time' 'increase' 'required' 'reduce' 'reduces' 'amount'\n",
      " 'decrease' 'increasing' 'reducing' 'increases' 'increased' 'time.'\n",
      " 'reduced' 'needed']\n",
      "['propagation' 'belief' 'free' 'inference' 'bp' 'algorithm' 'bethe' 'loopy'\n",
      " 'propagation.' 'approximate' 'exact' 'marginals' 'message-passing'\n",
      " 'graphical' 'partition']\n",
      "['signal' 'signals' 'processing' 'signals.' 'signals,' 'processing,'\n",
      " 'signal.' 'processing.' 'signal,' 'applications' 'input' 'processed'\n",
      " 'array' 'derived' 'and/or']\n",
      "['methods' 'existing' 'propose' 'however,' 'methods.' 'outperforms'\n",
      " 'paper,' 'state-of-the-art' 'rely' 'exploit' 'utilize' 'experiments'\n",
      " 'fail' 'incorporate' 'ones.']\n",
      "['including' 'variety' 'demonstrate' 'applicable' 'work,' 'resulting'\n",
      " 'present' 'include' 'widely' 'directly' 'typically' 'performing' 'apply'\n",
      " 'problems,' 'settings.']\n",
      "['cell' 'cells' 'approach' 'single' 'present' 'based' 'methods' 'multiple'\n",
      " 'microscopy' 'developed' 'major' 'performed' 'found' 'cells.' 'electron']\n",
      "['present' 'real' 'paper' 'developed' 'tests' 'approach' 'relative'\n",
      " 'merits' 'numerical' 'inherent' 'existing' 'framework' 'exploiting'\n",
      " 'demonstrate' 'potential']\n",
      "['sparse' 'sparsity' 'dense' 'high-dimensional' 'sparsity,' 'sparsity.'\n",
      " 'efficient' 'linear' 'sparse,' 'non-zero' 'components' 'non-sparse'\n",
      " 'sparse.' 'sparseness' 'nonzero']\n",
      "['discuss' 'describe' 'give' 'finally,' 'introduction' 'section' 'basic'\n",
      " 'briefly' 'tutorial' 'review' 'overview' 'explain' 'present' 'focus'\n",
      " 'detail']\n",
      "['sentiment' 'product' 'analysis' 'reviews' 'review' 'opinion' 'products'\n",
      " 'opinions' 'polarity' 'text' 'online' 'popular' 'products.' 'analysis,'\n",
      " 'reviews,']\n",
      "['challenge' 'team' 'competition' 'achieved' 'describes' 'teams'\n",
      " 'challenge.' 'submitted' 'place' 'task' 'top' 'paper' 'dataset' 'solution'\n",
      " 'final']\n",
      "['regression' 'linear' 'squares' 'ridge' 'regression.' 'regression,'\n",
      " 'response' 'nonparametric' 'regularized' 'generalized' 'additive'\n",
      " 'least-squares' 'ordinary' 'predictors' 'regressor']\n",
      "['learning' 'difference' 'function' 'temporal' 'learning.' 'trace' 'traces'\n",
      " 'methods' 'reinforcement' 'off-policy' 'show' 'perform' 'td' 'linear'\n",
      " 'approximation']\n",
      "['approximate' 'exact' 'efficient' 'approximation' 'computation'\n",
      " 'computational' 'expectation' 'intractable' 'compute' 'computing'\n",
      " 'approximations' 'inference' 'abc' 'ep' 'propagation']\n",
      "['causal' 'variables' 'observational' 'inference' 'data.' 'data'\n",
      " 'discovery' 'causality' 'observed' 'relationships' 'structure' 'effect'\n",
      " 'statistical' 'variables.' 'inferring']\n",
      "['definition' 'define' 'defined' 'formal' 'defining' 'concept' 'means'\n",
      " 'definitions' 'formally' 'properties' 'notion' 'defines' 'fundamental'\n",
      " 'core' 'is,']\n",
      "['propose' 'smoothing' 'show' 'called' 'classic' 'paper,' 'problem'\n",
      " 'applying' 'leads' 'technique' 'widely' 'method,' 'popular' 'original'\n",
      " 'smoothed']\n",
      "['activity' 'human' 'activities' 'recognition' 'daily' 'activities.'\n",
      " 'collected' 'important' 'understanding' 'activity.' 'activities,'\n",
      " 'egocentric' 'wearable' 'dataset' 'specific']\n",
      "['produce' 'accurate' 'show' 'approach' 'produces' 'produced' 'results'\n",
      " 'present' 'producing' 'bottom-up' 'simple' 'top-down' 'outputs' 'improve'\n",
      " 'combine']\n",
      "['hardware' 'gpu' 'performance' 'memory' 'computing' 'implementation'\n",
      " 'processing' 'implementations' 'power' 'parallel' 'gpus' 'cpu' 'embedded'\n",
      " 'hardware.' 'intel']\n",
      "['computational' 'cost' 'cost.' 'efficiency' 'high' 'reduce' 'terms'\n",
      " 'accuracy' 'low' 'efficiency.' 'burden' 'cost,' 'substantial'\n",
      " 'computation' 'complexity.']\n",
      "['signal' 'sensing' 'measurements' 'sparse' 'compressed' 'recovery'\n",
      " 'measurement' 'compressive' 'measurements.' 'signals' 'linear' 'cs'\n",
      " 'sparsity' 'numerical' 'reconstruction']\n",
      "['learning' 'process.' 'follow' 'kind' 'make' 'capabilities' 'exist' 'vary'\n",
      " '\"learning' 'expand' 'context' 'act' 'adapting' 'setting.' 'memoryless']\n",
      "['information' 'side' 'information.' 'additional' 'information,'\n",
      " 'auxiliary' 'improve' 'incorporate' 'form' 'incorporating' 'incorporates'\n",
      " 'privileged' 'addition' 'extra' 'utilize']\n",
      "['memory' 'memory.' 'memory,' 'store' 'stored' 'associative' 'usage'\n",
      " 'external' 'requirements' 'storing' 'memories' 'requires' 'internal'\n",
      " 'past' 'storage']\n",
      "['emotion' 'emotional' 'research' 'participants' 'study' 'gender'\n",
      " 'emotions' 'findings' 'human' 'affective' 'studies' 'effect' 'subjective'\n",
      " 'personality' 'affect']\n",
      "['mining' 'data' 'discovery' 'techniques' 'discover' 'frequent'\n",
      " 'discovered' 'knowledge' 'patterns' 'mining.' 'discovering' 'extracting'\n",
      " 'finding' 'motifs' 'interesting']\n",
      "['dataset' 'datasets' 'dataset,' 'dataset.' 'publicly' 'large-scale'\n",
      " 'collected' 'benchmark' 'datasets.' 'datasets,' 'baseline' 'evaluation'\n",
      " 'public' 'evaluate' 'largest']\n",
      "['predictions' 'prediction' 'accurate' 'make' 'predict' 'predictions.'\n",
      " 'accuracy' 'making' 'prediction.' 'made' 'predicting' 'predictions,'\n",
      " 'test' 'full' 'produce']\n",
      "['view' 'multi-view' 'views' 'multiple' 'learning' 'views.' 'single'\n",
      " 'simultaneously' 'unified' 'including' 'views,' 'viewpoint' 'view,'\n",
      " 'learning.' 'multiview']\n",
      "['partition' 'partitioning' 'partitions' 'cut' 'number' 'balanced' 'space'\n",
      " 'normalized' 'partitioned' 'show' 'merging' 'data' 'sets' 'simple'\n",
      " 'solution']\n",
      "['learning' 'learner' 'learners' 'learning.' 'learner.' 'learners.'\n",
      " \"learner's\" 'process,' 'learner,' 'learn' 'learners,' 'benefit' 'respect'\n",
      " 'however,' 'showing']\n",
      "['theoretically' 'analyze' 'empirically' 'theoretical' 'practical'\n",
      " 'empirical' 'show' 'provide' 'good' 'prove' 'experimentally' 'finally,'\n",
      " 'empirically,' 'setting.' 'motivated']\n",
      "['design' 'designing' 'design.' 'designs' 'design,' 'principles' 'designed'\n",
      " 'engineering' 'develop' 'enable' 'addressed' 'designs.' 'critical' 'meet'\n",
      " 'designs,']\n",
      "['module' 'modules' 'modular' 'consists' 'describe' 'multiple' 'propose'\n",
      " 'design' 'composed' 'enables' 'separate' 'complex' 'combination'\n",
      " 'modules.' 'specialized']\n",
      "['data' 'large' 'amount' 'amounts' 'data.' 'huge' 'data,' 'collection'\n",
      " 'collected' 'applications' 'small' 'collecting' 'vast' 'available.'\n",
      " 'collect']\n",
      "['choice' 'depends' 'choices' 'make' 'choose' 'depend' 'good' 'success'\n",
      " 'options' 'set' 'show' 'applications' 'find' 'design' 'option']\n",
      "['estimator' 'estimators' 'estimation' 'estimator.' 'estimator,'\n",
      " 'estimators.' 'estimating' 'statistical' 'sample' 'estimate' 'consistent'\n",
      " 'nonparametric' 'unbiased' 'asymptotic' 'estimated']\n",
      "['open' 'problem' 'question' 'problem.' 'work' 'remains' 'result'\n",
      " 'fundamental' 'provide' 'posed' 'left' 'efficient' 'main' 'progress'\n",
      " 'door']\n",
      "['bayes' 'naive' 'classification' 'accuracy' 'methods' 'results' 'paper'\n",
      " 'performance' 'classifier' 'classifiers' 'na\\\\\"ive' 'compared' 'performed'\n",
      " 'showed' 'bayes,']\n",
      "['reference' 'work' 'previous' 'previously' 'requires' 'make' 'work,'\n",
      " 'unlike' 'however,' 'published' 'makes' 'frequently' 'attempts' 'applies'\n",
      " 'results,']\n",
      "['missing' 'data' 'values' 'values.' 'incomplete' 'data.' 'imputation'\n",
      " 'values,' 'data,' 'complete' 'datasets' 'observed' 'handling' 'presence'\n",
      " 'handle']\n",
      "['total' 'variation' 'show' 'results' 'moreover,' 'obtain' 'variations'\n",
      " 'number' 'tv' 'applying' 'result' 'give' '${\\\\cal' 'paper,' 'i.e.,']\n",
      "['driving' 'autonomous' 'vehicle' 'safety' 'car' 'vehicles' 'driver' 'safe'\n",
      " 'road' 'systems' 'behavior' 'avoid' 'navigation' 'lane' 'cars']\n",
      "['method' 'alternating' 'direction' 'algorithm' 'optimization'\n",
      " 'multipliers' 'admm' 'solve' 'problem' 'convergence' 'augmented'\n",
      " 'minimization' 'lagrangian' 'constrained' '(admm)']\n",
      "['code' 'source' 'open' 'api' 'software' 'code.' 'publicly' 'public' 'run'\n",
      " 'project' 'application' 'developers' 'including' 'running' 'provided']\n",
      "['matrix' 'factorization' 'nonnegative' 'non-negative' 'nmf' 'matrices'\n",
      " '(nmf)' 'data' 'factorization.' 'product' 'factorization,' 'low-rank'\n",
      " 'factor' 'mf' 'sparse']\n",
      "['privacy' 'private' 'differential' 'data' 'sensitive' 'differentially'\n",
      " 'information' 'privacy.' 'preserving' 'privacy,' 'privacy-preserving'\n",
      " 'mechanism' 'utility' 'guarantees' 'personal']\n",
      "['objects' 'object' 'objects.' 'objects,' 'object.' 'grasp' 'learns'\n",
      " 'object,' 'grasping' 'task' 'variety' 'appearance' 'grasps' 'cluttered'\n",
      " 'challenging']\n",
      "['computational' 'workshop' 'volume' 'international' 'aim' 'work' 'ideas'\n",
      " 'models' 'presenting' 'traditional' 'held' 'papers' 'current'\n",
      " 'researchers' 'presented']\n",
      "['errors' 'error' 'correct' 'errors.' 'correction' 'order' 'errors,'\n",
      " 'incorrect' 'measurement' 'result' 'lead' 'output' 'corrected' 'typically'\n",
      " 'avoid']\n",
      "['scheme' 'schemes' 'proposed' 'scheme,' 'scheme.' 'efficient' 'schemes.'\n",
      " 'schemes,' 'propose' 'well-known' 'typical' 'design' 'aware' 'robustness'\n",
      " 'desirable']\n",
      "['features' 'features,' 'features.' 'extracted' 'feature' 'extract'\n",
      " 'combination' 'relevant' 'enhance' 'derived' 'characteristics'\n",
      " 'identifying' 'distinguishing' 'types' 'classify']\n",
      "['authors' 'author' 'study' 'techniques' 'specific' 'related' 'analysis'\n",
      " 'aim' 'b)' 'a)' 'suggested' 'set' 'authorship' 'included' 'methods']\n",
      "['research' 'scientific' 'literature' 'papers' 'academic' 'published'\n",
      " 'researchers' 'work' 'relevant' 'field' 'claim' 'article' 'ways'\n",
      " 'publications' 'increasingly']\n",
      "['numerical' 'equations' 'differential' 'equation' 'solution' 'equations.'\n",
      " 'ordinary' 'linear' 'partial' 'solving' 'solutions' 'integral'\n",
      " 'mathematical' 'machine' 'integration']\n",
      "['criterion' 'based' 'criteria' 'performance' 'stopping' 'proposed' 'order'\n",
      " 'applied' 'criterion.' 'criteria.' 'good' 'alternatives' 'criterion,'\n",
      " 'determine' 'choosing']\n",
      "['graphical' 'models' 'conditional' 'models.' 'gaussian' 'structure'\n",
      " 'models,' 'variables' 'independence' 'dependencies' 'probabilistic'\n",
      " 'undirected' 'variables.' 'graph' 'marginal']\n",
      "['show' 'margin' 'large' 'propose' 'experiments' 'based' 'maximum'\n",
      " 'outperforms' 'margin.' 'popular' 'resulting' 'i.e.,' 'lead' 'minimum'\n",
      " 'maximizing']\n",
      "['speech' 'recognition' 'speaker' 'acoustic' 'automatic' 'system' 'spoken'\n",
      " 'recognition,' 'speech.' 'phoneme' 'conventional' 'audio' 'recognition.'\n",
      " 'voice' 'asr']\n",
      "['matrix' 'matrices' 'singular' 'matrix.' 'column' 'decomposition'\n",
      " 'columns' 'rows' 'row' 'rank' 'matrices.' 'low-rank' 'matrices,' 'low'\n",
      " 'matrix,']\n",
      "['ground' 'truth' 'propose' 'show' 'based' 'current' 'multiple' 'results'\n",
      " 'state-of-the-art' 'framework' 'work,' 'rely' 'automatically' 'truth.'\n",
      " 'available,']\n",
      "['algorithm' 'proposed' 'iterative' 'based' 'thresholding' 'propose'\n",
      " 'algorithm.' 'hard' 'method' 'compared' 'iteratively' 'paper,'\n",
      " 'reweighted' 'algorithm,' 'procedure']\n",
      "['function' 'objective' 'function.' 'function,' 'optimize' 'minimize'\n",
      " 'optimizing' 'functions' 'cost' 'minimizing' 'defined' 'objective,'\n",
      " 'defining' 'corresponds' 'modify']\n",
      "['relational' 'learning' 'data.' 'approaches' 'approach' 'statistical'\n",
      " 'relations' 'models' 'representation' 'data,' 'present' 'collective'\n",
      " 'demonstrate' 'dependencies' 'linked']\n",
      "['million' '10' '3' '4' '5' '2' '1' '8' 'times' '30' 'billion' 'hours' '7'\n",
      " 'dataset' '100']\n",
      "['limited' 'capacity' 'ability' 'current' 'learn' 'amount' 'due'\n",
      " 'increasing' 'large' 'powerful' 'potential' 'increase' 'argue' 'larger'\n",
      " 'however,']\n",
      "['protein' 'prediction' 'structure' 'sequence' 'accuracy' 'method'\n",
      " 'binding' 'proteins' 'sequences' 'predict' 'dna' 'biological'\n",
      " 'information' 'bioinformatics' 'secondary']\n",
      "['synthesis' 'desired' 'generate' 'highly' 'synthesize' 'synthesized'\n",
      " 'realistic' 'present' 'learn' 'generating' 'demonstrate' 'generated'\n",
      " 'task' 'complex' 'synthesizing']\n",
      "['shared' 'sharing' 'multiple' 'common' 'share' 'information' 'learn'\n",
      " 'individual' 'simultaneously' 'jointly' 'others.' 'enables' 'them.'\n",
      " 'manner' 'introduce']\n",
      "['question' 'questions' 'answer' 'answering' 'answers' 'questions.' 'qa'\n",
      " 'vqa' 'question,' 'questions,' 'question.' 'question:' 'natural'\n",
      " 'reasoning' 'answers.']\n",
      "['tool' 'tools' 'powerful' 'analysis' 'modern' 'techniques' 'developed'\n",
      " 'analyzing' 'tools.' 'suggest' 'development' 'numerous' 'tools,' 'aim'\n",
      " 'tool.']\n",
      "['processes' 'process' 'processes.' 'underlying' 'stochastic' 'processes,'\n",
      " 'introduce' 'continuous-time' 'process.' 'nature' 'describe' 'application'\n",
      " 'time,' 'theory' 'construct']\n",
      "['end-to-end' 'trained' 'model' 'directly' 'learns' 'state-of-the-art'\n",
      " 'present' 'challenging' 'jointly' 'differentiable' 'task.' 'learn'\n",
      " 'trainable' 'task' 'single']\n",
      "['attention' 'model' 'mechanism' 'neural' 'propose' 'network' 'input'\n",
      " 'focus' 'state-of-the-art' 'recurrent' 'mechanism.' 'end-to-end'\n",
      " 'architecture' 'mechanisms' 'mechanism,']\n",
      "['measure' 'measures' 'measures.' 'measures,' 'measure,' 'relative'\n",
      " 'measuring' 'measure.' 'comparing' 'define' 'specific' 'quantify'\n",
      " 'compare' 'evaluating' 'assess']\n",
      "['hierarchical' 'hierarchy' 'structure' 'nested' 'levels' 'hierarchy.'\n",
      " 'hierarchies' 'flat' 'structure.' 'representing' 'structured'\n",
      " 'hierarchically' 'structures' 'structure,' 'automatically']\n",
      "['testing' 'hypothesis' 'hypotheses' 'test' 'null' 'multiple' 'statistical'\n",
      " 'testing.' 'tested' 'testing,' 'hypothesis.' 'hypotheses.' 'tests'\n",
      " 'distinguish' 'study']\n",
      "['show' 'call' 'natural' 'describe' 'introduce' 'efficiently' 'ordering'\n",
      " 'apply' 'leads' 'ordered' 'extend' 'dimensions' 'standard' '(such'\n",
      " 'finally']\n",
      "['approximation' 'approximate' 'approximations' 'function' 'approximated'\n",
      " 'approximation.' 'approximating' 'error' 'approximation,' 'fast'\n",
      " 'approximations.' 'approximates' 'algorithm' 'compute' 'cost']\n",
      "['stable' 'stability' 'show' 'small' 'results' 'numerical' 'respect'\n",
      " 'stability.' 'instability' 'unstable' 'result' 'introduce' 'leads'\n",
      " 'perturbations' 'numerically']\n",
      "['operations' 'implemented' 'machine' 'operation' 'operations.'\n",
      " 'arithmetic' 'require' 'addition' 'numbers' 'implementation' 'basic'\n",
      " 'describe' 'easily' 'operations,' 'perform']\n",
      "['students' 'student' 'teaching' 'educational' 'education' 'teacher'\n",
      " 'courses' 'university' \"students'\" 'online' 'higher' 'students.'\n",
      " 'computer' 'learning' 'teachers']\n",
      "['support' 'vector' 'machine' 'machines' 'machines,' 'machines.' 'machine.'\n",
      " '(svm)' 'classifiers,' 'machine,' '(svm).' '(svm),' '(svr)' 'intelligent'\n",
      " 'leading']\n",
      "['transfer' 'learning' 'knowledge' 'training' 'task' 'transferring'\n",
      " 'source' 'experiments' 'transferred' 'target' 'tasks.' 'learned' 'improve'\n",
      " 'related' 'task.']\n",
      "['prediction' 'predictors' 'predictor' 'prediction.' 'predict'\n",
      " 'prediction,' 'predictive' 'predicting' 'accuracy' 'conformal'\n",
      " 'predictors.' 'construct' 'predicted' 'predictions' 'predictors,']\n",
      "['data' 'big' 'data.' 'data,' 'analytics' 'processing' 'massive' 'machine'\n",
      " 'challenges' 'volume' 'amounts' 'huge' 'scale' 'volumes' 'mining']\n",
      "['condition' 'property' 'restricted' 'sufficient' 'conditions' 'general'\n",
      " 'satisfy' 'satisfies' 'prove' 'result' 'condition.' 'holds' 'condition,'\n",
      " 'optimality' 'bounded']\n",
      "['logic' 'reasoning' 'logical' 'symbolic' 'inductive' 'knowledge'\n",
      " 'programming' 'first-order' 'reasoning.' 'reason' 'programs' 'background'\n",
      " 'forms' 'semantics' 'formulas']\n",
      "['learning' 'mapping' 'machine' 'ml' '(ml)' 'mappings' 'algorithms' 'order'\n",
      " 'present' 'achieve' 'mapping.' 'algorithms,' 'resulting' 'framework'\n",
      " 'build']\n",
      "['sentence' 'sentences' 'language' 'natural' 'phrases' 'phrase'\n",
      " 'linguistic' 'semantic' 'sentences.' 'noun' 'words' 'textual' 'syntactic'\n",
      " 'word' 'sentence.']\n",
      "['people' 'place' 'important' 'make' 'paper' 'understand' 'etc.'\n",
      " 'information' 'understanding' 'personal' 'learn' 'day' 'end' 'places'\n",
      " 'home']\n",
      "['performance' 'adaptive' 'distributed' 'results' 'shown' 'analysis'\n",
      " 'strategies' 'adaptation' 'terms' 'part' 'detailed' 'diffusion' '[1]'\n",
      " 'strategy' 'lms']\n",
      "['social' 'individuals' 'collective' 'interaction' 'trust' 'influence'\n",
      " 'behavior' 'group' 'interactions' 'members' 'formation' 'individual'\n",
      " 'online' 'emergence' 'networks,']\n",
      "['bayesian' 'posterior' 'prior' 'priors' 'distribution' 'inference'\n",
      " 'prior.' 'prior,' 'priors.' 'frequentist' 'probabilities' 'distribution.'\n",
      " 'probability' 'hierarchical' 'distributions']\n",
      "['graph' 'graphs' 'graphs.' 'graph.' 'vertices' 'graphs,' 'edges' 'vertex'\n",
      " 'edge' 'graph,' 'subgraph' 'connected' 'graph-based' 'subgraphs'\n",
      " 'undirected']\n",
      "['rules' 'rule' 'based' 'rules.' 'set' 'rules,' 'rule.' 'association'\n",
      " 'rule,' 'simple' 'technique' 'update' 'safe' 'that,' \"bayes'\"]\n",
      "['machine' 'learning,' 'applications' 'including' 'etc.' 'important'\n",
      " 'learning.' 'analysis,' 'processing,' 'widely' 'statistics,' 'applied'\n",
      " 'statistical' 'numerous' 'areas']\n",
      "['show' 'degree' 'results' 'high' 'strong' 'simple' 'exhibit' 'finally,'\n",
      " 'analyze' 'specifically,' 'present' 'lead' 'depending' 'paper'\n",
      " 'experimentally']\n",
      "['spectrum' 'primary' 'cognitive' 'users' 'proposed' 'radio' 'secondary'\n",
      " 'base' 'wireless' 'user' 'throughput' 'interference' 'distributed'\n",
      " 'access' 'algorithm']\n",
      "['computer' 'science' 'scientific' 'computational' 'fields' 'science,'\n",
      " 'applications' 'problems' 'areas' 'physics' 'machine' 'statistical'\n",
      " 'science.' 'tools' 'fundamental']\n",
      "['bounds' 'lower' 'upper' 'bound' 'provide' 'derive' 'general' 'minimax'\n",
      " 'tight' 'bounds.' 'obtain' 'study' 'prove' 'bounds,' 'particular,']\n",
      "['general' 'specific' 'generic' 'present' 'framework' 'purpose'\n",
      " 'specialized' 'related' 'works' 'suitable' 'paper' 'further,' 'applied'\n",
      " 'resulting' 'forms']\n",
      "['visual' 'object' 'semantic' 'recognition' 'zero-shot' 'images' 'image'\n",
      " 'unseen' 'features' 'learned' 'recognition,' 'vision' 'dataset' 'zsl'\n",
      " 'classes']\n",
      "['finite' 'set' 'infinite' 'number' 'show' 'case' 'particular,' 'limit'\n",
      " 'infinitely' 'analyze' 'define' 'fact' 'i.e.,' 'family' 'call']\n",
      "['research' 'project' 'learned' 'science' 'lessons' 'describe'\n",
      " 'collaboration' 'collaborative' 'experience' 'potential' 'experiences'\n",
      " 'share' 'projects' 'report' 'community']\n",
      "['minimum' 'length' 'principle' 'number' 'description' 'means' 'general'\n",
      " 'minimal' 'maximum' 'principle,' 'mdl' 'practical' '(mdl)' 'ideal'\n",
      " 'considered']\n",
      "['regularization' 'regularized' 'norm' 'sparse' 'regularizer' '$\\\\ell_1$'\n",
      " 'sparsity' 'penalty' 'l1' 'regularization.' 'norms' 'term'\n",
      " 'regularization,' 'convex' 'regularizers']\n",
      "['result' 'main' 'paper' 'shows' 'proper' 'implies' 'result,' 'case'\n",
      " 'applied' 'interesting' 'composite' 'terms' 'turn' 'extend' 'considers']\n",
      "['approach' 'proposed' 'approach.' 'propose' 'based' 'demonstrate'\n",
      " 'approach,' 'effectiveness' 'experiments' 'compound' 'advantages'\n",
      " 'presented' 'applicability' 'accomplished' 'subsequently']\n",
      "['filter' 'filtering' 'particle' 'filters' 'kalman' 'state' 'trend'\n",
      " 'filters.' 'filter.' 'extended' 'filtering,' 'noise' 'filters,'\n",
      " 'state-space' 'filtering.']\n",
      "['metric' 'distance' 'metrics' 'learning' 'wasserstein' 'metric.' 'measure'\n",
      " 'mahalanobis' 'transport' 'distances' 'similarity' 'metric,' 'metrics.'\n",
      " 'metrics,' 'euclidean']\n",
      "['part' 'parts' 'paper' 'parts.' 'parts,' 'essential' 'part,' 'represent'\n",
      " 'combined' 'consists' 'proposes' 'part-based' 'employed' 'and-or' 'find']\n",
      "['information' 'information.' 'mutual' 'information,' 'theoretic' 'fisher'\n",
      " 'amount' 'contained' 'incomplete' 'relevant' 'address' 'gather' 'utilizes'\n",
      " 'informational' 'pieces']\n",
      "['environment' 'system' 'virtual' 'environment.' 'environments' 'operating'\n",
      " 'computers' 'systems' 'designed' 'reality' 'environment,' 'machine'\n",
      " 'implementation' 'design' 'user']\n",
      "['factors' 'factor' 'model' 'important' 'factors,' 'factors.' 'key'\n",
      " 'analysis' 'identify' 'underlying' 'affecting' 'variation' 'affect'\n",
      " 'impact' 'limiting']\n",
      "['selection' 'model' 'select' 'variable' 'selection.' 'number' 'selected'\n",
      " 'selecting' 'criterion' 'selection,' 'criteria' 'choosing' 'choose'\n",
      " 'optimal' 'procedure']\n",
      "['variant' 'variants' 'show' 'present' 'standard' 'permutation' 'popular'\n",
      " 'simple' 'call' 'perform' 'moreover,' 'permutations' 'classical'\n",
      " 'comparable' 'alternative']\n",
      "['music' 'audio' 'musical' 'note' 'results' 'automatic' 'song' 'genre'\n",
      " 'harmonic' 'chord' 'introduce' 'evaluate' 'music.' 'instrument' 'present']\n",
      "['word' 'words' 'sense' 'lexical' 'semantic' 'words.' 'language'\n",
      " 'disambiguation' 'lexicon' 'words,' 'corpus' 'linguistic' 'meaning' 'text'\n",
      " 'meanings']\n",
      "['semi-supervised' 'labeled' 'unlabeled' 'data' 'data.' 'learning'\n",
      " 'supervised' 'training' 'learning.' 'data,' 'unsupervised' 'label'\n",
      " 'labels' 'transductive' 'graph-based']\n",
      "['expert' 'experts' 'domain' 'learning' 'advice' 'experts.' 'knowledge'\n",
      " 'experts,' 'prediction' 'learn' 'expertise' 'knowledge.' 'expert.'\n",
      " 'effort' 'novice']\n",
      "['fast' 'accurate' 'method' 'efficient' 'runtime' 'large' 'time' 'highly'\n",
      " 'methods' 'slow' 'fast,' 'extremely' 'faster' 'computation' 'speed']\n",
      "['initial' 'initialization' 'results' 'starting' 'simple' 'makes'\n",
      " 'suitable' 'refined' 'respect' 'refine' 'start' 'starts' 'good'\n",
      " 'algorithms.' 'reach']\n",
      "['light' 'field' 'present' 'made' 'shed' 'field.' 'paper' 'potential'\n",
      " 'sheds' 'interesting' 'complex' 'introduce' 'angular' 'enables' 'recently']\n",
      "['machine' 'systems' 'smart' 'intelligent' 'technologies' 'development'\n",
      " 'advanced' 'modern' 'systems.' 'future' 'offer' 'computing' 'systems,'\n",
      " 'challenges' 'industry']\n",
      "['3d' 'shape' '2d' 'surface' 'shapes' 'learned' 'volumetric'\n",
      " 'reconstruction' 'images.' 'shapes.' 'geometry' 'geometric' 'normal'\n",
      " 'object' 'shape.']\n",
      "['mixture' 'gaussian' 'em' 'mixtures' 'algorithm' 'expectation' '(em)'\n",
      " 'model' 'components' 'maximization' 'expectation-maximization' 'models'\n",
      " 'parameters' 'component' 'gaussians']\n",
      "['transformation' 'transformations' 'invariant' 'invariance' 'affine'\n",
      " 'transformed' 'transformations.' 'rotation' 'input' 'transform' 'original'\n",
      " 'transformations,' 'introduce' 'transformation,' 'transformation.']\n",
      "['storage' 'data' 'reduce' 'applications' 'overhead' 'i/o' 'reducing'\n",
      " 'design' 'current' 'amount' 'transmission' 'popular' 'increasing' 'disk'\n",
      " 'common']\n",
      "['scenarios' 'scenarios.' 'scenario' 'evaluate' 'real-world' 'paper,'\n",
      " 'performance' 'realistic' 'scenarios,' 'practical' 'approaches'\n",
      " 'scenario,' 'application' 'propose' 'scenario.']\n",
      "['robot' 'robots' 'robotic' 'manipulation' 'environment' 'robotics'\n",
      " 'autonomous' 'environments.' 'robot.' 'learn' 'planning' 'simulated'\n",
      " 'navigation' 'environment.' \"robot's\"]\n",
      "['patterns' 'pattern' 'patterns.' 'find' 'patterns,' 'represent' 'similar'\n",
      " 'identify' 'pattern.' 'discover' 'specific' 'represents' 'reveal'\n",
      " 'discovering' 'pattern,']\n",
      "['research' 'area' 'areas' 'application' 'researchers' 'field' 'research,'\n",
      " 'important' 'work' 'paper' 'focus' 'focused' 'topic' 'approaches' 'main']\n",
      "['distributed' 'communication' 'decentralized' 'centralized' 'local'\n",
      " 'cooperative' 'communication.' 'asynchronous' 'machines' 'consensus'\n",
      " 'communicate' 'large-scale' 'communication,' 'rounds' 'machines.']\n",
      "['character' 'chinese' 'line' 'characters' 'recognition' 'handwritten'\n",
      " 'lines' 'symbol' 'symbols' 'present' 'script' 'bin' 'packing' 'printed'\n",
      " 'layout']\n",
      "['uncertainty' 'bayesian' 'model' 'probabilistic' 'uncertainty.'\n",
      " 'uncertain' 'estimates' 'averaging' 'quantification' 'uncertainties'\n",
      " 'uncertainty,' 'principled' 'robust' 'posterior' 'parameters.']\n",
      "['nonconvex' 'problems' 'convergence' 'method' 'hessian' 'optimization'\n",
      " 'objective' 'function' 'numerical' 'solving' 'second-order' 'newton'\n",
      " 'problems.' 'minimization' 'quadratic']\n",
      "['group' 'groups' 'groups.' 'groups,' 'similar' 'grouping' 'overlapping'\n",
      " 'group.' 'form' 'individual' 'grouped' 'set' 'structure' 'group,' 'called']\n",
      "['coordinate' 'descent' 'asynchronous' 'optimization' 'block' 'convergence'\n",
      " 'problems' 'stochastic' 'parallel' 'dual' 'coordinates' 'synchronous'\n",
      " 'large-scale' 'rate' 'propose']\n",
      "['classes' 'class' 'classes.' 'class.' 'classes,' 'class,' 'classification'\n",
      " 'belonging' 'set' 'classify' 'examples' 'belong' 'define' 'belongs'\n",
      " 'distinct']\n",
      "['functions' 'function' 'functions,' 'functions.' 'boolean' 'function.'\n",
      " '$f$' 'class' 'function,' 'defined' 'monotone' 'computed' 'real-valued'\n",
      " 'classes' '$f$,']\n",
      "['problem' 'inverse' 'problems' 'problem.' 'problems.' 'solution'\n",
      " 'problem,' 'solving' 'problems,' 'solve' 'classical' 'general' 'apply'\n",
      " 'formulation' 'inversion']\n",
      "['programming' 'program' 'programs' 'language' 'code' 'execution'\n",
      " 'programs.' 'machine' 'languages' 'java' 'compiler' 'instructions'\n",
      " 'implemented' 'programs,' 'compilation']\n",
      "['learning' 'framework' 'on-line' 'framework.' 'proper' 'inspired' 'learnt'\n",
      " 'learning.' 'helps' 'addition' 'off-line' 'additionally,' 'thus,'\n",
      " 'facilitating' 'proposed.']\n",
      "['mnist' 'dataset' 'count' 'handwritten' 'counting' 'results'\n",
      " 'classification' 'dataset.' 'digits' 'demonstrate' 'digit' 'number'\n",
      " 'counts' 'experiments' 'benchmark']\n",
      "['sequence' 'sequences' 'sequences.' 'sequence.' 'generated' 'sequences,'\n",
      " 'length' 'sequence,' 'input' 'length.' 'entire' 'temporal' 'order' 'makes'\n",
      " 'long']\n",
      "['subspace' 'data' 'clustering' 'subspaces' 'low-dimensional' 'linear'\n",
      " 'union' 'subspaces.' 'subspace.' 'points' 'high-dimensional' 'lie'\n",
      " 'affinity' 'sparse' 'subspaces,']\n",
      "['boosting' 'weak' 'fusion' 'strong' 'adaboost' 'results' 'obtain' 'loss'\n",
      " 'combining' 'fused' 'perform' 'experimental' 'fusing' 'exponential'\n",
      " 'demonstrate']\n",
      "['generated' 'generation' 'generate' 'generating' 'generates'\n",
      " 'automatically' 'generation.' 'randomly' 'create' 'quality' 'generation,'\n",
      " 'produce' 'capable' 'procedural' 'high-quality']\n",
      "['ensemble' 'base' 'diversity' 'diverse' 'ensembles' 'single' 'individual'\n",
      " 'multiple' 'combining' 'set' 'classifiers' 'combine' 'ensemble.' 'sets'\n",
      " 'methods.']\n",
      "['population' 'evolutionary' 'evolution' 'genetic' 'fitness' 'evolve'\n",
      " 'search' 'computational' 'evolved' 'evolving' 'individuals' 'population.'\n",
      " 'biological' 'change' 'mutation']\n",
      "['constraints' 'constraint' 'constrained' 'constraints.' 'constraints,'\n",
      " 'subject' 'constraint.' 'constraint,' 'satisfy' 'imposed' 'impose'\n",
      " 'efficient' 'unconstrained' 'imposing' 'satisfying']\n",
      "['image' 'patches' 'images' 'state-of-the-art' 'patch' 'images.'\n",
      " 'denoising' 'image.' 'restoration' 'image,' 'patches.' 'learned'\n",
      " 'proposed' 'single' 'priors']\n",
      "['ratio' 'show' 'competitive' 'performance' 'results' 'low' 'proposed'\n",
      " 'compared' 'noise' 'signal-to-noise' 'ratios' 'achieves' 'gain' 'obtained'\n",
      " 'improves']\n",
      "['phase' 'transition' 'phase,' 'transitions' 'ising' 'phase.' 'phases'\n",
      " 'consists' 'statistical' 'order' 'case' 'find' 'model.' 'simulations'\n",
      " 'spin']\n",
      "['divergence' 'kullback-leibler' 'based' 'bregman' 'show' 'divergences'\n",
      " 'kl' 'divergence.' 'distribution' 'minimizing' 'class' 'divergence,'\n",
      " 'recently' 'distributions' 'distributions.']\n",
      "['differences' 'similar' 'find' 'identify' 'similarities' 'food' 'study'\n",
      " 'understand' 'distinct' 'compare' 'focus' 'differ' 'comparing'\n",
      " 'difference' 'correspond']\n",
      "['heuristic' 'algorithm' 'algorithms' 'heuristics' 'finding' 'efficient'\n",
      " 'based' 'show' 'provably' 'simple' 'present' 'find' 'good' 'paper'\n",
      " 'algorithms.']\n",
      "['policy' 'policies' 'reinforcement' 'learning' 'policy.' 'control'\n",
      " 'policies.' 'reward' 'imitation' 'learn' 'policy,' 'model-free'\n",
      " 'policies,' 'optimal' 'learning.']\n",
      "['recurrent' 'neural' 'long' 'lstm' 'memory' 'networks' 'rnn' 'short-term'\n",
      " 'network' 'rnns' '(lstm)' 'sequence' '(rnn)' 'dependencies' 'long-term']\n",
      "['confidence' 'intervals' 'interval' 'bootstrap' 'statistical' 'nominal'\n",
      " 'construct' 'level' 'constructing' 'numerical' 'develop' 'based'\n",
      " 'resulting' 'significance' 'coverage']\n",
      "['protocol' 'protocols' 'secure' 'communication' 'key' 'security'\n",
      " 'cryptographic' 'alice' 'learn' 'bob' 'encryption' 'secret' 'private'\n",
      " 'public' 'parties']\n",
      "['event' 'events' 'events.' 'temporal' 'events,' 'rare' 'learn'\n",
      " 'occurrence' 'time' 'occur' 'identify' 'important' 'event.' 'detecting'\n",
      " 'hawkes']\n",
      "['resolution' 'high' 'low' 'single' 'fine' 'coarse' 'high-resolution'\n",
      " 'super-resolution' 'enhancement' 'sr' 'details' 'low-resolution' 'super'\n",
      " 'resolution,' 'resolution.']\n",
      "['data' 'sets' 'set.' 'set' 'sets.' 'set,' 'sets,' 'performing' 'points'\n",
      " 'coresets' 'fraction' 'coreset' 'settings.' 'constructed' 'out,']\n",
      "['present' 'set' 'cases' 'coverage' 'application' 'paper' 'showing'\n",
      " 'presented' 'employing' 'test' 'technique' 'then,' 'required' 'determined'\n",
      " 'cases.']\n",
      "['kernel' 'kernels' 'methods' 'kernels.' 'kernel.' 'kernel-based'\n",
      " 'kernels,' 'gaussian' 'kernel,' 'mkl' 'multiple' 'popular' 'kernelized'\n",
      " 'combination' 'rbf']\n",
      "['component' 'principal' 'analysis' 'components' 'pca' 'components.'\n",
      " '(pca)' 'analysis.' 'components,' 'pca,' 'data.' 'obtain' 'pca.'\n",
      " 'component,' 'decomposition']\n",
      "['optimization' 'function' 'bayesian' 'objective' 'evaluations' 'surrogate'\n",
      " 'functions' 'global' 'optimization.' 'acquisition' 'expensive' 'black-box'\n",
      " 'expected' 'optimizing' 'functions.']\n",
      "['theory' 'mathematical' 'theory.' 'theory,' 'theoretical' 'general'\n",
      " 'theories' 'ideas' 'basic' 'explain' 'developed' 'fundamental' 'classical'\n",
      " 'rigorous' 'subject']\n",
      "['learning' 'machine' 'learning.' 'algorithms' 'learning,' 'algorithms.'\n",
      " 'applying' 'learning:' 'designing' 'correct' '(we' 'etc.,' 'together.'\n",
      " '(with' 'dimensions,']\n",
      "['precision' 'recall' 'quantization' 'low' 'accuracy' 'weights' 'quantized'\n",
      " 'precision.' 'higher' 'bits' 'bit' 'fixed-point' 'achieve' 'precision,'\n",
      " 'accuracy.']\n",
      "['test' 'tests' 'testing' 'statistics' 'tests.' 'hypothesis' 'independence'\n",
      " 'statistic' 'power' 'test.' 'discrepancy' 'based' 'tests,' 'statistical'\n",
      " 'two-sample']\n",
      "['based' 'thesis' 'results' 'machine' 'reservoir' 'presented' 'built'\n",
      " 'learning' 'work' 'framework' 'study' 'context' 'seismic' 'investigated'\n",
      " 'preliminary']\n",
      "['family' 'exponential' 'families' 'class' 'arbitrary' 'family.' 'family,'\n",
      " 'parametric' 'distributions' 'general' 'generalized' 'give' 'popular'\n",
      " 'statistics' 'broad']\n",
      "['topic' 'topics' 'latent' 'modeling' 'dirichlet' 'model' 'models'\n",
      " 'allocation' 'lda' 'document' 'documents' 'topics.' 'text' 'words' '(lda)']\n",
      "['algorithm' 'greedy' 'orthogonal' 'problem' 'algorithm,' 'pursuit'\n",
      " 'algorithms.' 'algorithm.' 'matching' 'called' 'algorithms' 'particular,'\n",
      " 'moreover,' 'results' 'prove']\n",
      "['monte' 'carlo' 'markov' 'chain' 'sampling' 'mcmc' 'posterior' 'bayesian'\n",
      " 'gibbs' 'sampler' 'inference' 'distribution' '(mcmc)' 'mixing' 'sample']\n",
      "['convergence' 'algorithm' 'converge' 'converges' 'guaranteed' 'prove'\n",
      " 'rate' 'algorithm,' 'fast' 'guarantee' 'faster' 'solution' 'convergence,'\n",
      " 'guarantees' 'convergence.']\n",
      "['sample' 'complexity' 'complexity.' 'size' 'bounds' 'logarithmic'\n",
      " 'samples' 'lower' 'complexities' 'dimension' 'unknown' 'fundamental'\n",
      " 'size.' 'dependence' 'establish']\n",
      "['threshold' 'study' 'show' 'results' 'sufficiently' 'critical'\n",
      " 'probability' 'case' 'provided' 'thresholds' 'high' 'threshold,'\n",
      " 'sensitivity' 'values' 'average']\n",
      "['generalized' 'topological' 'introduce' 'framework' 'properties'\n",
      " 'persistent' 'introduced' 'define' 'generalize' 'properties.' 'moreover,'\n",
      " 'persistence' 'hyperbolic' 'considered' 'statistical']\n",
      "['algorithm' 'algorithm,' 'algorithm.' 'algorithms,' 'algorithms.'\n",
      " 'algorithms' 'finds' 'called' 'version' 'extension' 'comparing'\n",
      " 'well-known' 'inspired' 'avoids' 'circumvent']\n",
      "['exploration' 'change' 'balance' 'exploitation' 'current' 'exploring'\n",
      " 'explore' 'trade-off' 'improve' 'introduce' 'strategy' 'changing'\n",
      " 'propose' 'exploration.' 'pure']\n",
      "['submodular' 'approximation' 'functions' 'function' 'algorithm'\n",
      " 'maximization' 'greedy' 'algorithms' 'problem' 'maximizing' 'problems'\n",
      " 'functions.' 'set' 'combinatorial' 'show']\n",
      "['structural' 'structure' 'properties' 'capture' 'including' 'structure.'\n",
      " 'introduce' 'information' 'structures' 'information.' 'effective'\n",
      " 'applied' 'structure,' 'reductions' 'obtain']\n",
      "['control' 'controlled' 'control.' 'design' 'controlling' 'current' 'based'\n",
      " 'control,' 'motor' 'direct' 'pi' 'simultaneously' 'command' 'industrial'\n",
      " 'torque']\n",
      "['neural' 'networks' 'network' 'recurrent' 'networks.' 'networks,'\n",
      " 'feed-forward' 'network.' 'feedforward' 'trained' 'network,'\n",
      " 'network-based' 'backpropagation' 'architectures' 'convolutional']\n",
      "['features' 'features.' 'learn' 'hand-crafted' 'learned' 'features,'\n",
      " 'automatically' 'extract' 'raw' 'extracted' 'traditional' 'rely'\n",
      " 'extracting' 'handcrafted' 'task.']\n",
      "['unit' 'units' 'activation' 'linear' 'hidden' 'input' 'functions'\n",
      " 'rectified' 'function' 'relu' 'units,' 'units.' 'piecewise' 'activations'\n",
      " 'function,']\n",
      "['tracking' 'appearance' 'object' 'visual' 'online' 'tracking.' 'target'\n",
      " 'tracker' 'track' 'robust' 'occlusion' 'challenging' 'state-of-the-art'\n",
      " 'correlation' 'learned']\n",
      "['distribution' 'probability' 'distribution.' 'distributions'\n",
      " 'distribution,' 'samples' 'unknown' 'drawn' 'distributions.' 'sample'\n",
      " 'discrete' 'i.i.d.' 'distributions,' 'uniform' 'close']\n",
      "['feature' 'selection' 'features' 'features.' 'subset' 'select' 'relevant'\n",
      " 'selected' 'features,' 'selection,' 'important' 'selecting' 'sets'\n",
      " 'selection.' 'classification']\n",
      "['tasks' 'task' 'learning' 'tasks.' 'tasks,' 'multitask' 'learned' 'solve'\n",
      " 'catastrophic' 'learning,' 'previously' 'task-specific' 'tackle'\n",
      " 'forgetting' 'lifelong']\n",
      "['based' 'proposed' 'extreme' 'compared' 'results' 'experimental' 'paper,'\n",
      " 'adopted' 'traditional' 'proposed.' 'datasets' 'representative' 'employed'\n",
      " 'elm' 'widely']\n",
      "['past' 'recent' 'years' 'history' 'years,' 'interest' 'current'\n",
      " 'researchers' 'historical' 'research' 'decade' 'years.' 'long' 'modern'\n",
      " 'emerged']\n",
      "['decision' 'policy' 'optimal' 'markov' 'process' 'policies' 'processes'\n",
      " 'reinforcement' 'state' 'partially' 'stochastic' 'mdp' 'observable'\n",
      " 'problem' 'iteration']\n",
      "['state' 'states' 'states.' 'state.' 'space' 'transition' 'finite' 'state,'\n",
      " 'represented' 'transitions' 'states,' 'defined' 'space.' 'steady'\n",
      " 'internal']\n",
      "['show' 'improvements' 'boundary' 'significant' 'yields' 'state-of-the-art'\n",
      " 'leads' 'results' 'propose' 'boundaries' 'results.' 'substantial'\n",
      " 'standard' 'approach' 'experiments']\n",
      "['content' 'information' 'popularity' 'based' 'contents' 'cache' 'caching'\n",
      " 'content.' 'time.' 'paper,' 'content,' 'terms' 'works' 'work,' 'desired']\n",
      "['large' 'thousands' 'millions' 'hundreds' 'scale' 'large-scale' 'scalable'\n",
      " 'massive' 'tens' 'present' 'single' 'handle' 'highly' 'scales' 'billions']\n",
      "['verification' 'systems' 'specification' 'formal' 'checking' 'system'\n",
      " 'correctness' 'specifications' 'refinement' 'reactive' 'state' 'systems.'\n",
      " 'machines' 'finite' 'safety']\n",
      "['problem' 'solution' 'problem.' 'solve' 'problems' 'solved' 'solves'\n",
      " 'solving' 'solutions' 'problem,' 'efficiently' 'required' 'efficiently.'\n",
      " 'solution.' 'optimally']\n",
      "['behavior' 'behaviors' 'behavior.' 'behavioral' 'analyze' 'behavior,'\n",
      " 'study' 'analyzing' 'complex' 'exhibit' 'lead' 'behaviors.' 'animal'\n",
      " 'understand' 'animals']\n",
      "['identification' 'identify' 'identifying' 'identified' 'important' 'set'\n",
      " 'identification.' 'task' 'potential' 'identifies' 'identification,'\n",
      " 'approach' 'unique' 'analysis.' 'develop']\n",
      "['natural' 'language' 'processing' 'processing.' 'processing,' 'nlp'\n",
      " 'tasks.' 'tasks' '(nlp)' 'tasks,' 'linguistic' 'understanding' 'language.'\n",
      " 'input.' 'translation,']\n",
      "['convex' 'convergence' 'gradient' 'rate' 'optimization' 'strongly'\n",
      " 'smooth' 'proximal' 'accelerated' 'objective' 'linear' 'stochastic'\n",
      " 'non-smooth' 'composite' 'methods']\n",
      "['lasso' 'high-dimensional' 'penalty' 'regression' 'sparse' 'screening'\n",
      " 'penalized' 'selection' 'sparsity' 'linear' 'lasso,' 'variable' 'group'\n",
      " 'regularization' 'lasso.']\n",
      "['map' 'maps' 'input' 'feature' 'paper,' 'mapping' 'map.' 'self-organizing'\n",
      " 'specifically,' 'som' 'maps.' 'maps,' 'present' 'map,' 'based']\n",
      "['recommendation' 'user' 'collaborative' 'items' 'users' 'recommender'\n",
      " 'item' 'filtering' 'ratings' 'recommendations' 'rating' 'systems'\n",
      " 'preferences' 'items.' \"user's\"]\n",
      "['form' 'show' 'recursive' 'closed' 'normal' 'simple' 'form.' 'paper'\n",
      " 'quadratic' 'standard' 'equivalent' 'forms' 'sense' 'form,' 'contrast']\n",
      "['=' '1' 'log' 'number' '2' 'prove' '1.' '2.' 'n)' 'size' '0' 'result' '2,'\n",
      " '+' '1,']\n",
      "['approach' '---' 'data' 'specific' 'performed' 'registration' 'results'\n",
      " 'algorithm.' 'real' 'consists' 'model-based' 'simulated' 'dedicated'\n",
      " 'parameters' 'time.']\n",
      "['approaches' 'existing' 'based' 'approaches.' 'methods' 'compare'\n",
      " 'approaches,' 'however,' 'comparison' 'outperform' 'and/or' 'competing'\n",
      " 'competitive' 'leveraging' 'present']\n",
      "['game' 'games' 'players' 'equilibrium' 'nash' 'player' 'play' 'games.'\n",
      " 'games,' 'game.' 'equilibria' 'game,' 'strategy' 'potential' 'playing']\n",
      "['convergence' 'rates' 'rate' 'optimal' 'minimax' 'establish' 'asymptotic'\n",
      " 'rates.' 'fast' 'derive' 'faster' 'general' 'achieves' 'statistical'\n",
      " 'achieve']\n",
      "['performance' 'improve' 'performance.' 'improved' 'significantly' 'paper,'\n",
      " 'improving' 'performance,' 'enhance' 'affect' 'improves' 'adding'\n",
      " 'enhanced' 'enhancing' 'improvement']\n",
      "['human' 'humans' 'cognitive' 'perception' 'understanding' 'human-machine'\n",
      " 'humans.' 'understand' 'capabilities' 'systems' 'humans,' 'people'\n",
      " 'perceptual' 'machines' 'perceived']\n",
      "['ranking' 'rank' 'list' 'top' 'ranked' 'relevance' 'rankings' 'lists'\n",
      " 'propose' 'ranking.' 'pairwise' 'top-k' 'ranks' 'ranking,' 'bipartite']\n",
      "['implementation' 'library' 'implemented' 'package' 'software' 'machine'\n",
      " 'interface' 'open-source' 'implementations' 'python' 'easily' 'toolbox'\n",
      " 'matlab' 'c++' 'describe']\n",
      "['programming' 'linear' 'relaxation' 'problem' 'quadratic' 'integer'\n",
      " 'semidefinite' 'program' 'solving' 'sdp' 'optimal' 'optimization' 'lp'\n",
      " 'formulation' 'solved']\n",
      "['network' 'networks' 'network.' 'networks.' 'network,' 'structure'\n",
      " 'networks,' 'sizes' \"network's\" 'topology' 'structure,' 'interconnected'\n",
      " 'edges.' 'subnetworks' 'expose']\n",
      "['path' 'statistics' 'paths' 'shortest' 'statistics.' 'summary' 'addition'\n",
      " 'path.' 'entire' 'important' 'algorithm.' 'paths.' 'full' 'developed'\n",
      " 'compute']\n",
      "['show' 'fact' 'that,' 'is,' 'widely' 'so-called' 'furthermore,' 'thus,'\n",
      " 'particular,' 'general,' 'motivated' 'trivial' 'well-known' 'fact,'\n",
      " 'this,']\n",
      "['type' 'types' 'types.' 'types,' 'existing' 'ii' 'specific' 'including'\n",
      " 'type.' 'important' 'type,' 'examined' 'motivated' 'free' 'recognized']\n",
      "['localization' 'based' 'position' 'window' 'positions' 'fingerprint'\n",
      " 'proposed' 'sliding' 'positioning' 'indoor' 'achieve' 'real' 'accurate'\n",
      " 'signal' 'strength']\n",
      "['learning' 'learning,' 'learning.' 'learn' 'curriculum' 'children'\n",
      " 'greatly' 'deal' 'principle' 'child' 'gradually' 'self-paced' 'parent'\n",
      " 'difficulty' 'introduce']\n",
      "['directed' 'graph' 'edge' 'graphs' 'structure' 'acyclic' 'edges' 'markov'\n",
      " 'equivalence' 'graphs,' 'graphs.' 'represent' 'dag' 'graphical' 'chain']\n",
      "['density' 'estimation' 'probability' 'function' 'nonparametric' 'estimate'\n",
      " 'densities' 'distribution' 'estimating' 'bandwidth' 'estimation.' 'kernel'\n",
      " 'estimates' 'conditional' 'estimation,']\n",
      "['data' 'data.' 'data,' 'deal' 'noisy' 'analysis' 'practical' 'analysis,'\n",
      " 'normal' 'analysis.' 'however,' 'cleaning' 'observed' 'simulated'\n",
      " 'validated']\n",
      "['classifier' 'classifiers' 'classification' 'classifiers.' 'classifier.'\n",
      " 'classifiers,' 'classifier,' 'accuracy' 'training' 'binary' 'train'\n",
      " 'classification.' 'one-class' 'trained' 'supervised']\n",
      "['network' 'networks' 'link' 'links' 'networks.' 'networks,' 'topology'\n",
      " 'social' 'network.' 'connectivity' 'network,' 'links.' 'connected'\n",
      " 'complex' 'topologies']\n",
      "['image' 'images' 'images.' 'images,' 'visual' 'image.' 'photo' 'aesthetic'\n",
      " 'photos' 'image,' 'dataset' 'perceptual' 'visually' 'natural' 'trained']\n",
      "['overcome' 'however,' 'limitations' 'limitation' 'due' 'existing' 'suffer'\n",
      " 'approaches' 'current' 'major' 'lack' 'address' 'traditional' 'overcomes'\n",
      " 'limitations.']\n",
      "['performance' 'state-of-the-art' 'achieves' 'compared' 'benchmark'\n",
      " 'competitive' 'superior' 'performances' 'methods.' 'comparable'\n",
      " 'datasets.' 'datasets' 'methods,' 'experiments' 'moreover,']\n",
      "['language' 'languages' 'english' 'languages.' 'morphological'\n",
      " 'multilingual' 'parallel' 'corpora' 'language.' 'machine' 'translation'\n",
      " 'arabic' 'corpus' 'linguistic' 'languages,']\n",
      "['health' 'medical' 'clinical' 'patient' 'patients' 'risk' 'electronic'\n",
      " 'disease' 'records' 'survival' 'care' 'healthcare' 'personalized'\n",
      " 'hospital' 'ehr']\n",
      "['common' 'show' 'approach' 'practice' 'present' 'sketch' 'results'\n",
      " 'original' 'typically' 'sketching' 'smaller' 'techniques' 'sketches'\n",
      " 'work' 'practice.']\n",
      "['adversarial' 'examples' 'robustness' 'perturbations' 'adversary'\n",
      " 'perturbation' 'input' 'examples.' 'small' 'show' 'robust' 'vulnerable'\n",
      " 'attacks' 'inputs' 'perturbed']\n",
      "['autoencoder' 'unsupervised' 'deep' 'autoencoders' 'denoising'\n",
      " 'variational' 'generative' 'stacked' 'learn' 'show' 'representation'\n",
      " 'auto-encoder' 'representations' 'latent' 'trained']\n",
      "['nearest' 'neighbor' 'neighbors' 'based' 'data' 'k-nearest' 'neighborhood'\n",
      " 'performance' 'paper,' 'knn' 'approximate' 'popular' 'neighbour' 'propose'\n",
      " 'widely']\n",
      "['feature' 'features' 'extraction' 'extract' 'extracted' 'classification'\n",
      " 'features.' 'extracting' 'extraction.' 'extraction,' 'extractor'\n",
      " 'extracts' 'features,' 'classification.' 'suitable']\n",
      "['results' 'method' 'experimental' 'state-of-the-art' 'methods.' 'show'\n",
      " 'outperforms' 'significantly' 'propose' 'paper,' 'comparing' 'compared'\n",
      " 'achieves' 'demonstrate' 'methods,']\n",
      "['motion' 'trajectory' 'trajectories' 'approach' 'moving' 'movement'\n",
      " 'movements' 'trajectories.' 'motions' 'gait' 'dynamic' 'capture'\n",
      " 'dynamics' 'forces' 'velocity']\n",
      "['sensor' 'sensors' 'data' 'measurements' 'monitoring' 'environmental'\n",
      " 'wireless' 'collected' 'sensors.' 'real-time' 'sensing' 'due'\n",
      " 'measurement' 'system' 'environment']\n",
      "['relationships' 'relationship' 'model' 'learn' 'modeling' 'capture'\n",
      " 'complex' 'represent' 'relationships.' 'captures' 'capturing' 'encode'\n",
      " 'modeled' 'rich' 'attempts']\n",
      "['learning' 'machine' 'techniques' 'modern' 'community.' 'automating'\n",
      " 'practitioners' 'improving' 'rapidly' 'on,' 'plethora' 'tree-based'\n",
      " 'exploiting' 'generation' 'comparison,']\n",
      "['residual' 'deep' 'networks' 'network' 'connections' 'layers'\n",
      " 'architecture' 'intermediate' 'networks.' 'depth' 'networks,' 'training'\n",
      " 'skip' 'deeper' 'architectures']\n",
      "['representation' 'representation.' 'represent' 'compact' 'representation,'\n",
      " 'representations' 'representing' 'represented' 'traditional' 'encoded'\n",
      " 'encode' 'learn' 'represents' 'representations.' 'symbolic']\n",
      "['transform' 'frequency' 'fourier' 'wavelet' 'domain' 'coefficients'\n",
      " 'multiscale' 'fast' 'analysis' 'transforms' 'signal' 'domain.' 'basis'\n",
      " 'scattering' 'frequencies']\n",
      "['temporal' 'spatial' 'capture' 'information' 'spatio-temporal'\n",
      " 'spatiotemporal' 'spatially' 'modeling' 'dependencies' 'multiple' 'time.'\n",
      " 'incorporate' 'space' 'domain.' 'information.']\n",
      "['internet' 'growth' 'rapid' 'iot' 'development' 'current' 'research'\n",
      " 'emerging' 'things' 'technologies' 'challenges' 'technology' 'growing'\n",
      " 'area' 'providing']\n",
      "['points' 'data' 'point' 'points.' 'set' 'points,' 'ball' 'radius'\n",
      " 'moreover,' 'dpp' 'determinantal' 'finding' 'number' 'defined' 'dpps']\n",
      "['dictionary' 'sparse' 'learning' 'dictionaries' 'representation' 'coding'\n",
      " 'learned' 'dictionary.' 'atoms' 'sparsity' 'dictionary,' 'linear' 'signal'\n",
      " 'overcomplete' 'coefficients']\n",
      "['translation' 'machine' 'neural' 'nmt' 'source' 'system' 'bleu' 'language'\n",
      " 'translation.' 'statistical' 'quality' 'mt' 'target' 'sentence' 'smt']\n",
      "['software' 'development' 'engineering' 'project' 'effort' 'research'\n",
      " 'process' 'requirements' 'developers' 'software.' 'industrial' 'projects'\n",
      " 'practices' 'include' 'developing']\n",
      "['video' 'videos' 'frames' 'temporal' 'frame' 'motion' 'videos.' 'video.'\n",
      " 'spatio-temporal' 'action' 'videos,' 'frames.' 'recognition' 'appearance'\n",
      " 'challenging']\n",
      "['external' 'encoding' 'internal' 'information' 'approach' 'encode'\n",
      " 'demonstrate' 'encoded' 'propose' 'build' 'form' 'example,' 'builds'\n",
      " 'previous' 'capability']\n",
      "['reduced' 'reduce' 'pruning' 'redundant' 'size' 'accuracy.' 'redundancy'\n",
      " 'reducing' 'removing' 'reduction' 'significant' 'technique' 'eliminate'\n",
      " 'maintaining' 'number']\n",
      "['task' 'tasks' 'task.' 'task,' 'learn' 'perform' 'challenging' 'tasks.'\n",
      " 'tasks,' 'accomplish' 'performing' 'hand.' 'subtasks' 'crucial'\n",
      " 'achieving']\n",
      "['depth' 'scene' 'images' 'scenes' 'camera' 'dataset' 'deep'\n",
      " 'convolutional' 'rgb-d' 'rgb' 'stereo' 'image' 'images.' 'monocular'\n",
      " 'scenes.']\n",
      "['composition' 'discourse' 'compositional' 'coherent' 'ability'\n",
      " 'distributional' 'previous' 'markers' 'describe' 'represented' 'argue'\n",
      " 'compose' 'coherence' 'argument' 'representations']\n",
      "['set' 'sets' 'set.' 'set,' 'sets.' 'sets,' 'intersection' 'call' 'cover'\n",
      " 'construct' 'belong' 'practice,' 'consists' 'closed' 'measure']\n",
      "['continuous' 'discrete' 'lipschitz' 'demonstrate' 'discretization' 'space'\n",
      " 'spaces' 'spaces.' 'time,' 'naturally' 'domains,' 'domains.'\n",
      " 'differentiable' 'discretized' 'finite']\n",
      "['consistent' 'consistency' 'show' 'problem' 'results' 'prove' 'dl'\n",
      " 'achieved' 'universally' 'statistical' 'consistency.' 'showing' 'unique'\n",
      " 'consistent.' 'introduce']\n",
      "['(e.g.' '(i.e.' 'tags' 'approach' 'important' 'tag' 'tagging' 'results'\n",
      " 'previous' 'show' 'time,' 'develop' 'etc.)' 'work' 'specific']\n",
      "['information' 'entropy' 'mutual' 'maximum' 'information-theoretic'\n",
      " 'measure' 'theoretic' 'called' 'shannon' 'information,' 'entropy.'\n",
      " 'entropy,' 'principle' 'terms' 'bottleneck']\n",
      "['convolutional' 'deep' 'network' 'pooling' 'layers' 'convolution' 'neural'\n",
      " 'networks' 'layer' 'feature' 'architecture' 'state-of-the-art' 'filters'\n",
      " 'layers.' 'layers,']\n",
      "['challenges' 'address' 'challenge' 'challenges.' 'significant' 'major'\n",
      " 'poses' 'overcome' 'unique' 'challenges,' 'complex' 'issues' 'deal'\n",
      " 'common' 'practical']\n",
      "['effect' 'impact' 'study' 'performance' 'performance.' 'effects'\n",
      " 'significant' 'evaluate' 'investigate' 'observe' 'analyze' 'types'\n",
      " 'quantify' 'compare' 'examine']\n",
      "['problems' 'problems.' 'problems,' 'solve' 'solving' 'involving' 'solved'\n",
      " 'related' 'arise' 'involve' 'arising' 'obtaining' 'encountered'\n",
      " 'algorithmic' 'require']\n",
      "['point' 'fixed' 'starting' 'view' 'point.' 'points' 'view,' 'respect'\n",
      " 'view.' 'points.' 'interior' 'interesting' 'clouds' 'point,'\n",
      " 'furthermore,']\n",
      "['quality' 'assessment' 'high' 'quality.' 'improve' 'assess' 'good'\n",
      " 'quality,' 'improving' 'evaluation' 'assessing' 'impact' 'nature' 'serve'\n",
      " 'assessment.']\n",
      "['style' 'fashion' 'paper,' 'show' 'propose' 'large' 'styles' 'writing'\n",
      " 'demonstrate' 'explore' 'compatibility' 'generate' 'capture' 'clothing'\n",
      " 'experiments']\n",
      "['present' 'time-series' 'collection' 'goals' 'approach' 'goal' 'complex'\n",
      " 'introduce' 'diverse' 'automatically' 'domains' 'capable' 'guide' 'builds'\n",
      " 'unfortunately,']\n",
      "['al.' 'algorithm' 'work' 'introduced' 'results' 'showed' 'recent'\n",
      " 'general' 'recently,' 'show' 'particular,' 'result' 'proved' 'studied'\n",
      " 'extend']\n",
      "['covariance' 'matrix' 'gaussian' 'matrix.' 'matrices' 'estimation'\n",
      " 'inverse' 'precision' 'estimating' 'matrix,' 'matrices.'\n",
      " 'high-dimensional' 'sparse' 'estimator' 'graphical']\n",
      "['dynamics' 'dynamical' 'systems' 'dynamics.' 'system' 'systems.'\n",
      " 'dynamics,' 'switching' 'systems,' 'chaotic' 'underlying' 'system.' 'time'\n",
      " \"system's\" 'state']\n",
      "['network' 'neural' 'deep' 'convolutional' 'architecture' 'trained'\n",
      " 'network.' 'network,' 'train' 'end-to-end' 'recurrent' 'state-of-the-art'\n",
      " 'siamese' '(cnn)' 'learns']\n",
      "['quantum' 'classical' 'annealing' 'circuit' 'circuits' 'computing'\n",
      " 'computational' 'computation.' 'simulated' 'computation' 'problems'\n",
      " 'states' 'machine' 'give' 'measurement']\n",
      "['relations' 'relation' 'relations.' 'extraction' 'knowledge' 'relations,'\n",
      " 'types' 'existing' 'information' 'pairs' 'learns' 'entities' 'extraction.'\n",
      " 'model' 'extract']\n",
      "['structured' 'learning' 'prediction' 'output' 'propose' 'learn'\n",
      " 'unstructured' 'structures' 'exploit' 'structure' 'outputs' 'loss' 'apply'\n",
      " 'structural' 'problem,']\n",
      "['domain' 'adaptation' 'target' 'source' 'domains' 'domain.' 'domains.'\n",
      " 'domain,' 'unsupervised' 'labeled' 'domains,' 'learn' 'shift'\n",
      " 'cross-domain' 'transfer']\n",
      "['response' 'responses' 'model' 'responses.' 'response.' 'impulse'\n",
      " 'stimuli' 'stimulus' 'response,' 'responses,' 'respond' 'modeling'\n",
      " 'subject' 'exhibit' 'information']\n",
      "['optimization' 'problems' 'problems.' 'combinatorial' 'algorithms'\n",
      " 'problem' 'problems,' 'solutions' 'solving' 'problem,' 'solve'\n",
      " 'well-known' 'problem.' 'optimization.' 'algorithms.']\n",
      "['market' 'financial' 'price' 'stock' 'pricing' 'trading' 'prices' 'demand'\n",
      " 'portfolio' 'markets' 'economic' 'market.' 'dynamic' 'returns'\n",
      " 'investment']\n",
      "['neural' 'neurons' 'synaptic' 'spiking' 'neuron' 'learning' 'spike'\n",
      " 'biological' 'neurons.' 'neuromorphic' 'networks' 'plasticity'\n",
      " 'biologically' 'synapses' 'plausible']\n",
      "['modeling' 'model' 'parametric' 'fairness' 'non-parametric' 'modeling.'\n",
      " 'models.' 'modeling,' 'flexible' 'fair' 'typically' 'modeled' 'terms'\n",
      " 'models,' 'incorporating']\n",
      "['person' 're-identification' 'variations' 'camera' 'state-of-the-art'\n",
      " 'appearance' 'challenging' 'large' 'surveillance' 'visual'\n",
      " 'discriminative' 're-id' 'images' 'pedestrian' 'proposed']\n",
      "['technique' 'techniques' 'technique.' 'technique,' 'based' 'applied'\n",
      " 'apply' 'developed' 'techniques.' 'paper' 'effective' 'present' 'describe'\n",
      " 'also,' 'finding']\n",
      "['approach' 'data-driven' 'based' 'data.' 'purely' 'makes' 'dominant'\n",
      " 'model-based' 'characteristics' 'step' 'learn' 'paper,' 'vice' 'versa.'\n",
      " 'combination']\n",
      "['simple' 'perform' 'standard' 'performs' 'find' 'however,' 'poorly'\n",
      " 'investigate' 'compare' 'provided' 'well,' 'remarkably' 'well.'\n",
      " 'intuition' 'worse']\n",
      "['manifold' 'riemannian' 'geometry' 'space' 'manifold.' 'manifolds'\n",
      " 'geometric' 'euclidean' 'lie' 'space.' 'manifolds.' 'underlying'\n",
      " 'low-dimensional' 'manifold,' 'data']\n",
      "['facial' 'expression' 'expressions' 'face' 'features' 'gabor' 'automatic'\n",
      " 'landmark' 'landmarks' 'database' 'recognition' 'expressions.' 'pain'\n",
      " 'action' 'expressions,']\n",
      "['location' 'based' 'locations' 'present' 'information' 'paper,'\n",
      " 'investigate' 'determine' 'apply' 'automatically' 'incorporate'\n",
      " 'information.' 'location.' 'moreover,' 'significantly']\n",
      "['annotation' 'supervised' 'annotated' 'weakly' 'training' 'annotations'\n",
      " 'supervision' 'weak' 'trained' 'labels' 'manually' 'train' 'large'\n",
      " 'require' 'human']\n",
      "['similarity' 'pairs' 'similar' 'pair' 'measure' 'based' 'similarities'\n",
      " 'pairwise' 'similarity.' 'metric' 'pairs.' 'measures' 'measuring' 'cosine'\n",
      " 'similarity,']\n",
      "['tensor' 'decomposition' 'tensors' 'product' 'decompositions' 'rank'\n",
      " 'higher-order' 'factorization' 'decomposition.' 'multilinear' 'orthogonal'\n",
      " 'low-rank' 'decomposition,' 'tensors.' 'efficient']\n",
      "['database' 'databases' 'data' 'database.' 'large' 'xml' 'database,'\n",
      " 'schema' 'tables' 'relational' 'table' 'databases.' 'describe' 'sql'\n",
      " 'called']\n",
      "['learn' 'ability' 'skills' 'build' 'experience' 'approach' 'skill'\n",
      " 'complex' 'maintain' 'acquire' 'acquisition' 'specific' 'acquired' 'tile'\n",
      " 'allowing']\n",
      "['model' 'model,' 'model.' \"model's\" 'probe' 'incorporates' 'learns'\n",
      " 'purpose' 'meaningful' 'pairs' 'naturally' 'sense' 'framework.' 'assumes'\n",
      " 'behaves']\n",
      "['resource' 'resources' 'allocation' 'limited' 'resources.' 'resources,'\n",
      " 'budget' 'usage' 'amount' 'workflow' 'allocate' 'allocating' 'utilization'\n",
      " 'constrained' 'solution']\n",
      "['data' 'sets' 'sets.' 'sets,' 'large' 'real' 'uci' 'massive' 'publicly'\n",
      " 'co-clustering' 'compare' 'and/or' 'separately' 'finding' 'sets:']\n",
      "['generative' 'adversarial' 'generator' 'training' 'networks' 'generate'\n",
      " 'gan' 'generated' 'discriminator' 'gans' 'samples' 'generating'\n",
      " 'realistic' '(gans)' 'conditional']\n",
      "['individual' 'level' 'develop' 'perform' 'specific' 'individuals' 'and/or'\n",
      " 'aggregated' 'show' 'set' 'level.' 'types' 'therefore,' 'however,' '(or']\n",
      "['data' 'incremental' 'streaming' 'stream' 'online' 'streams'\n",
      " 'incrementally' 'real-time' 'data.' 'streams.' 'update' 'processing'\n",
      " 'continuously' 'updated' 'incoming']\n",
      "['correlation' 'correlated' 'dependence' 'correlations' 'based'\n",
      " 'coefficient' 'copula' 'measure' 'variables' 'statistical' 'strongly'\n",
      " 'presence' 'terms' 'maximal' 'highly']\n",
      "['conditional' 'random' 'fields' 'field' 'markov' 'inference' 'models'\n",
      " 'crf' 'pairwise' 'potentials' 'structured' 'model' 'efficient' 'potential'\n",
      " 'demonstrate']\n",
      "['case' 'study' 'studies' 'i)' 'ii)' 'paper' 'study.' 'feasibility'\n",
      " 'provided' 'study,' 'main' 'iii)' 'achieve' 'implications' 'pilot']\n",
      "['image' 'model' 'description' 'descriptions' 'visual' 'generate'\n",
      " 'captioning' 'textual' 'language' 'images' 'generating' 'generation'\n",
      " 'datasets' 'natural' 'dataset']\n",
      "['pairwise' 'aggregation' 'comparisons' 'comparison' 'relative'\n",
      " 'preferences' 'preference' 'problem' 'items' 'set' 'pairs' 'aggregate'\n",
      " 'comparisons.' 'pair' 'underlying']\n",
      "['time' 'algorithm' 'running' '\\\\log' 'runs' 'n)$' 'linear' 'time,'\n",
      " 'constant' '$n$' 'time.' 'algorithms' 'give' 'previous' 'number']\n",
      "['generalize' 'arbitrary' 'show' 'previously' 'learn' 'unseen'\n",
      " 'generalizes' 'allowing' 'present' 'previous' 'introduce' 'enables'\n",
      " 'ability' 'generalizing' 'well.']\n",
      "['online' 'ad' 'advertising' 'user' 'click' 'display' 'budget' 'hoc'\n",
      " 'conversion' 'ads' 'real-time' 'paper,' 'effective' 'maximize' 'bid']\n",
      "['term' 'terms' 'short' 'long' 'based' 'standard' 'results' 'terms.'\n",
      " 'expressed' 'furthermore,' 'terms,' 'fall' 'utilize' 'conjunction'\n",
      " 'manner.']\n",
      "['detection' 'detect' 'anomaly' 'detecting' 'detection.' 'detection,'\n",
      " 'anomalies' 'anomalous' 'detectors' 'detector' 'normal' 'detected'\n",
      " 'abnormal' 'detects' 'change']\n",
      "['saliency' 'salient' 'features' 'high-level' 'low-level'\n",
      " 'state-of-the-art' 'demonstrate' 'proposed' 'map' 'maps' 'results'\n",
      " 'regions' 'propose' 'paper,' 'challenging']\n",
      "['time' 'series' 'series.' 'dynamic' 'series,' 'warping' 'autoregressive'\n",
      " 'multivariate' 'varying' 'temporal' 'time-series' 'dtw' 'var' 'real'\n",
      " 'segments']\n",
      "['test' 'training' 'set' 'data.' 'set.' 'train' 'time.' 'time,' 'trained'\n",
      " 'unseen' 'apply' 'cases.' 'applied' 'subset' 'set,']\n",
      "['regions' 'region' 'regions.' 'interest' 'approach' 'dense' 'entire'\n",
      " 'region.' 'regions,' 'local' 'extract' 'identify' 'small' 'detect'\n",
      " 'locally']\n",
      "['theory' 'information' 'potential' 'kinds' 'sp' 'article' 'conceptual'\n",
      " 'natural' 'system' 'concept' 'concepts' 'multiple' 'computer'\n",
      " 'unsupervised' 'pattern']\n",
      "['utility' 'expected' 'rational' 'maximize' 'function' 'bounded' 'optimal'\n",
      " 'present' 'demonstrate' 'functions' 'model,' 'theory' 'derive' 'subject'\n",
      " 'key']\n",
      "['curve' 'performance' 'area' 'learning' 'characteristic' 'curves' 'based'\n",
      " 'auc' 'operating' 'roc' 'machine' 'directly' 'evaluated' 'work,'\n",
      " 'indicator']\n",
      "['text' 'document' 'documents' 'texts' 'text.' 'corpus' 'textual'\n",
      " 'documents.' 'text,' 'extracting' 'unstructured' 'corpus.' 'word' 'words'\n",
      " 'corpora']\n",
      "['data' 'urban' 'mobility' 'city' 'travel' 'public' 'analysis' 'patterns'\n",
      " 'collected' 'gps' 'geographic' 'human' 'crime' 'stress' 'indicators']\n",
      "['community' 'communities' 'detection' 'stochastic' 'block' 'networks'\n",
      " 'overlapping' 'network' 'communities.' 'networks,' 'number' 'networks.'\n",
      " 'structure' 'communities,' 'clustering']\n",
      "['dialogue' 'dialog' 'systems' 'natural' 'language' 'system' 'task'\n",
      " 'systems.' 'generation' 'act' 'conversational' 'human' 'understanding'\n",
      " 'spoken' 'previous']\n",
      "['matrix' 'low-rank' 'rank' 'completion' 'norm' 'nuclear' 'low' 'entries'\n",
      " 'matrices' 'minimization' 'recovery' 'matrix,' 'recover' 'matrix.'\n",
      " 'problem']\n",
      "['significant' 'performance' 'improvements' 'gains' 'improvement'\n",
      " 'demonstrate' 'statistically' 'lead' 'gain' 'yield' 'results' 'leads'\n",
      " 'substantial' 'improved' 'combined']\n",
      "['regret' 'bandit' 'multi-armed' 'reward' 'algorithm' 'arm' 'arms' 'online'\n",
      " 'stochastic' 'problem' 'expected' 'bound' 'setting' 'optimal' 'bandits']\n",
      "['score' 'scores' 'scoring' 'based' 'f1' 'score.' 'scores.' 'leverage'\n",
      " 'average' 'final' 'scores,' 'evaluate' 'score,' 'derived' 'results,']\n",
      "['diffusion' 'information' 'model' 'network' 'cascade' 'spread' 'process'\n",
      " 'cascades' 'underlying' 'adoption' 'observed' 'spreading' 'adopt' 'work,'\n",
      " 'develop']\n",
      "['artificial' 'intelligence' 'ai' 'intelligent' 'intelligence.' 'systems'\n",
      " 'machine' 'human' 'intelligence,' 'immune' 'nature' 'general' 'called'\n",
      " '(ai)' 'swarm']\n",
      "['recovery' 'recover' 'problem' 'exact' 'recovering' 'conditions'\n",
      " 'recovers' 'underlying' 'guarantees' 'true' 'algorithm' 'recovered'\n",
      " 'provably' 'probability' 'high']\n",
      "['theoretical' 'provide' 'results' 'numerical' 'analysis' 'empirical'\n",
      " 'practical' 'illustrate' 'justification' 'analysis.' 'validate'\n",
      " 'simulations' 'findings.' 'results,' 'complement']\n",
      "['bound' 'lower' 'upper' 'bounds' 'bound.' 'prove' 'bound,' 'give'\n",
      " 'bounded' 'tight' 'logarithmic' 'obtain' 'result' 'optimal' 'matches']\n",
      "['convex' 'optimization' 'non-convex' 'problems' 'problem' 'minimization'\n",
      " 'relaxation' 'problem.' 'optimization.' 'problems.' 'solving' 'solve'\n",
      " 'hull' 'optimization,' 'relaxations']\n",
      "['representations' 'representation' 'learn' 'learned' 'representations.'\n",
      " 'representations,' 'learns' 'tasks' 'capture' 'demonstrate' 'learning'\n",
      " 'representation.' 'evaluate' 'learnt' 'unsupervised']\n",
      "['production' 'paper' 'eye' 'imbalanced' 'manufacturing' 'application'\n",
      " 'cycles' 'based' 'imbalance' 'cycle' 'gaze' 'machine' 'techniques'\n",
      " 'industrial' 'leading']\n",
      "['service' 'customer' 'business' 'customers' 'spam' 'email' 'requests'\n",
      " 'services' 'online' 'users' 'characteristics' 'request' 'phishing'\n",
      " 'customers.' 'emails']\n",
      "['hidden' 'markov' 'model' 'models' 'chain' 'hmm' 'states' 'transition'\n",
      " 'chains' 'hmms' 'discrete' 'probabilities' 'viterbi' '(hmm)' 'factorial']\n",
      "['data' 'real' 'synthetic' 'data.' 'simulated' 'data,' 'experiments'\n",
      " 'sets.' 'generated' 'relying' 'method' 'illustrate' 'robust' 'validate'\n",
      " 'synthetically']\n",
      "['smooth' 'smoothness' 'methods' 'show' 'resulting' 'function' 'present'\n",
      " 'obtain' 'locally' 'develop' 'poisson' 'apply' 'particular,' 'classical'\n",
      " 'varying']\n",
      "['security' 'attack' 'attacks' 'information' 'attacker' 'attacks.'\n",
      " 'malicious' 'systems' 'attacks,' 'vulnerabilities' 'threat' 'vulnerable'\n",
      " 'secure' 'cyber' 'protect']\n",
      "['solution' 'solutions' 'optimal' 'problem' 'problem.' 'optimization'\n",
      " 'solutions.' 'objectives' 'objective' 'find' 'multi-objective' 'pareto'\n",
      " 'obtained' 'problems' 'solution.']\n",
      "['remote' 'sensing' 'cover' 'results' 'satellite' 'high' 'based' 'water'\n",
      " 'aerial' 'land' 'spatial' 'great' 'imagery' 'surface' 'accurate']\n",
      "['embedding' 'space' 'low-dimensional' 'space.' 'embedded' 'embeddings'\n",
      " 'embed' 'mapping' 'high-dimensional' 'demonstrate' 'embedding.'\n",
      " 'representation' 'triplet' 'vector' 'space,']\n",
      "['reconstruction' 'proposed' 'reconstruct' 'propose' 'approach' 'based'\n",
      " 'reconstructed' 'demonstrate' 'quality' 'reconstructing' 'reconstruction.'\n",
      " 'artifacts' 'iterative' 'methods.' 'highly']\n",
      "['dual' 'optimization' 'problem' 'solving' 'problems' 'problems.'\n",
      " 'problem.' 'primal' 'problem,' 'solution' 'develop' 'primal-dual'\n",
      " 'duality' 'solve' 'efficient']\n",
      "['matching' 'correspondence' 'template' 'match' 'problem' 'matching,'\n",
      " 'matches' 'templates' 'paper,' 'correspondences' 'matching.' 'finally,'\n",
      " 'matched' 'introduce' 'pairs']\n",
      "['model' 'neural' 'decoder' 'encoder' 'decoding' 'sequence'\n",
      " 'encoder-decoder' 'trained' 'encoding' 'input' 'models' 'recurrent'\n",
      " 'network' 'sequence-to-sequence' 'generates']\n",
      "['cost' 'costs' 'cost.' 'costs.' 'optimal' 'minimize' 'computational'\n",
      " 'cost-sensitive' 'cost,' 'minimizing' 'total' 'trade-off' 'computation'\n",
      " 'reducing' 'budget']\n",
      "['face' 'recognition' 'images' 'faces' 'facial' 'deep' 'verification'\n",
      " 'challenging' 'identity' 'pose' 'variations' 'recognition.' 'recognition,'\n",
      " 'wild' 'unconstrained']\n",
      "['solver' 'solvers' 'solving' 'problem' 'constraint' 'set' 'problems' 'sat'\n",
      " 'boolean' 'problems.' 'instances' 'clause' 'search' 'present'\n",
      " 'satisfiability']\n",
      "['molecular' 'drug' 'based' 'chemical' 'atomic' 'potential' 'molecules'\n",
      " 'computational' 'biological' 'free' 'reaction' 'predict' 'properties'\n",
      " 'drugs' 'small']\n",
      "['medical' 'imaging' 'image' 'images' 'ct' 'mri' 'segmentation' 'cardiac'\n",
      " 'x-ray' 'mr' 'method' 'accurate' 'scan' 'high' 'automatic']\n",
      "['feature' 'features' 'learning' 'features.' 'representation' 'learn'\n",
      " 'propose' 'learned' 'engineering' 'effective' 'feature,' 'feature.'\n",
      " 'features,' 'key' 'space.']\n",
      "['likelihood' 'marginal' 'model' 'distribution' 'bayesian' 'log'\n",
      " 'probabilistic' 'quantile' 'standard' 'conditional' 'joint' 'parameters'\n",
      " 'model.' 'estimating' 'estimate']\n",
      "['clustering' 'cluster' 'clusters' 'k-means' 'clustering.' 'clusters.'\n",
      " 'clustering,' '$k$-means' 'clusters,' 'unsupervised' 'clustered' 'centers'\n",
      " 'hierarchical' 'cluster.' 'agglomerative']\n",
      "['proposed' 'based' 'results' 'method' 'skin' 'detection' 'trained'\n",
      " 'lesion' 'analysis' 'tested' 'evaluated' 'achieved' 'dr' 'automatic'\n",
      " 'test']\n",
      "['platform' 'system' 'development' 'tools' 'designed' 'platforms'\n",
      " 'developed' 'integrated' 'engine' 'integration' 'design' 'support'\n",
      " 'real-time' 'platform.' 'prototype']\n",
      "['active' 'learning' 'passive' 'learning.' 'learning,' 'actively' 'goal'\n",
      " 'informative' 'selects' 'selecting' 'label' 'setting,' 'reducing' 'select'\n",
      " 'selected']\n",
      "['independent' 'analysis' 'interest.' 'result' 'component' 'dependent'\n",
      " 'independently' 'distributed' 'ica' 'identically' 'shown' 'observations'\n",
      " 'relies' 'conditionally' 'assumed']\n",
      "['create' 'build' 'creating' 'created' 'ability' 'focus' 'them.' 'make'\n",
      " 'creation' 'built' 'part' 'utilizing' 'making' 'components' 'main']\n",
      "['model' 'parameters' 'model,' 'model.' 'parameters,' 'parameters.' 'learn'\n",
      " 'infer' 'fewer' 'probable' 'learned' 'capturing' 'baselines.'\n",
      " 'facilitates' 'abilities']\n",
      "['level' 'levels' 'high' 'higher' 'abstraction' 'low' 'level.' 'level,'\n",
      " 'high-level' 'levels.' 'abstractions' 'low-level' 'higher-level'\n",
      " 'multi-level' 'levels,']\n",
      "['automated' 'automatic' 'automatically' 'manual' 'human' 'manually'\n",
      " 'system' 'fully' 'task' 'require' 'process' 'automate' 'labelling'\n",
      " 'time-consuming' 'labelled']\n",
      "['noise' 'noisy' 'noise.' 'noise,' 'presence' 'robust' 'gaussian'\n",
      " 'corrupted' 'additive' 'denoising' 'clean' 'white' 'robustness'\n",
      " 'noiseless' 'assume']\n",
      "['effective' 'however,' 'proven' 'paper,' 'simple' 'improve' 'credit'\n",
      " 'shown' 'extremely' 'powerful' 'difficult' 'important' 'due' 'evaluate'\n",
      " 'highly']\n",
      "['reduction' 'dimensionality' 'dimension' 'high-dimensional' 'dimensions'\n",
      " 'high' 'intrinsic' 'curse' 'reduction.' 'space' 'reduced' 'dimensional'\n",
      " 'reduction,' 'reducing' 'dimensionality.']\n",
      "['local' 'global' 'optimization' 'non-convex' 'optimum' 'converges'\n",
      " 'converge' 'minima' 'saddle' 'objective' 'landscape' 'points'\n",
      " 'convergence' 'optima' 'guaranteed']\n",
      "['pose' 'human' 'body' 'hand' 'estimation' '3d' 'poses' 'joint' 'single'\n",
      " 'skeleton' 'depth' 'approaches' 'learned' 'directly' 'challenging']\n",
      "['results' 'state-of-the-art' 'propose' 'experimental' 'learning' 'paper,'\n",
      " 'exploits' 'effectively' 'show' 'achieve' 'recent' 'proposed' 'leverage'\n",
      " 'compared' 'cascade']\n",
      "['news' 'reading' 'article' 'articles' 'machine' 'book' 'based'\n",
      " 'comprehension' 'make' 'read' 'existing' 'fake' 'automatically'\n",
      " 'understand' 'wikipedia']\n",
      "['accuracy' 'higher' 'significantly' 'compared' 'achieves' 'achieve'\n",
      " 'achieved' 'lower' 'improved' 'conventional' 'smaller' 'accuracies'\n",
      " 'comparable' 'similar' 'accuracy.']\n",
      "['index' 'based' 'symmetric' 'show' 'results' 'asymmetric' 'set' 'paper'\n",
      " 'indices' 'sets' 'defined' 'validity' 'work,' 'index,' 'efficient']\n",
      "['simulation' 'configuration' 'configurations' 'simulations' 'simulator'\n",
      " 'paper' 'simulate' 'resulting' 'simulation,' 'simulated' 'implemented'\n",
      " 'enables' 'configurations.' 'simulations.' 'complex']\n",
      "['tree' 'decision' 'trees' 'trees.' 'tree.' 'spanning' 'trees,' 'tree,'\n",
      " 'structure' 'split' 'leaf' 'boosted' 'tree-structured' 'tree-based' 'node']\n",
      "['neural' 'network' 'networks' 'artificial' 'perceptron' 'multi-layer'\n",
      " 'backpropagation' 'trained' 'training' 'multilayer' 'ann' 'nn' 'networks.'\n",
      " 'mlp' 'feedforward']\n",
      "['agents' 'agent' 'learning' 'learn' 'multi-agent' 'agents.' 'agents,'\n",
      " 'beliefs' 'private' \"agent's\" 'actions' 'social' \"agents'\" 'agent.'\n",
      " 'agent,']\n",
      "['{\\\\em' '(in' '(the' 'problem' 'arbitrary' '(which' 'set' '(or' '(and'\n",
      " 'form' 'small' 'general' 'yields' '(a' 'example,']\n",
      "['layer' 'layers' 'hidden' 'network' 'deep' 'output' 'layer.' 'training'\n",
      " 'neural' 'input' 'layer,' 'layers.' 'weights' 'top' 'fully-connected']\n",
      "['binary' 'multiclass' 'classification' 'present' 'number' 'demonstrate'\n",
      " 'output' 'classification.' 'results' 'multilabel' 'furthermore,'\n",
      " 'real-valued' 'finally,' 'efficient' 'problems']\n",
      "['popular' 'show' 'propose' 'paper,' 'however,' 'ordinal' 'increasingly'\n",
      " 'important' 'particular,' 'performance.' 'transaction' 'moreover,' 'make'\n",
      " 'transactions' 'commonly']\n",
      "['message' 'passing' 'messages' 'large' 'approximate' 'algorithm'\n",
      " 'algorithm.' 'simple' 'factor' 'problem' 'limit' 'generalized' 'messages.'\n",
      " 'study' 'called']\n",
      "['alignment' 'based' 'propose' 'show' 'experiments' 'approach' 'alignments'\n",
      " 'aligned' 'paper,' 'outperform' 'match' 'align' 'alignment,' 'alignment.'\n",
      " 'e.g.']\n",
      "['1)' '2)' '3)' 'learning' 'paper,' 'i.e.,' 'achieve' 'introduce' 'main'\n",
      " 'simultaneously' 'challenging' '4)' 'address' 'major' 'obtain']\n",
      "['sound' 'audio' 'features' 'acoustic' 'species' 'sounds' 'raw' 'extract'\n",
      " 'detection' 'recordings' 'signals' 'auditory' 'environmental' 'underwater'\n",
      " 'evaluated']\n",
      "['detection' 'malware' 'detect' 'machine' 'malicious' 'based' 'intrusion'\n",
      " 'learning' 'techniques' 'identify' 'android' 'detecting' 'system'\n",
      " 'detection.' 'detection,']\n",
      "['relevant' 'order' 'relevance' 'information' 'common' 'situation'\n",
      " 'specific' 'situations' 'identify' 'paper' 'irrelevant' 'lead' 'providing'\n",
      " 'guide' 'essential']\n",
      "['deep' 'neural' 'networks' 'convolutional' 'networks.' 'networks,'\n",
      " 'network' 'training' 'architectures' 'shallow' 'nets' 'train' 'network.'\n",
      " 'trained' 'state-of-the-art']\n",
      "['spectral' 'graph' 'matrix' 'laplacian' 'clustering' 'eigenvectors'\n",
      " 'eigenvalues' 'based' 'eigenvalue' 'eigenvector' 'leading' 'spectrum'\n",
      " 'adjacency' 'symmetric' 'particular,']\n",
      "['label' 'labels' 'labels.' 'labeling' 'labeled' 'multi-label' 'labels,'\n",
      " 'classification' 'training' 'noisy' 'class' 'datasets' 'classifier'\n",
      " 'label.' 'labeling.']\n",
      "['mobile' 'devices' 'device' 'users' 'app' 'devices.' 'apps' 'smartphone'\n",
      " 'applications' 'smartphones' 'android' 'smart' 'phone' 'devices,'\n",
      " 'machine']\n",
      "['data' 'data.' 'data,' 'raw' 'measured' 'preprocessing' 'driven'\n",
      " 'abundance' 'availability' 'multi-dimensional' 'analyzing' 'analysis,'\n",
      " 'pre-processing' 'points,' 'processed']\n",
      "['support' 'vector' 'svm' 'machine' 'classification' '(svm)' 'machines'\n",
      " 'svms' 'classifier' 'classifiers' 'svm.' 'hyperplane' '(svms)'\n",
      " 'classification.' 'vectors']\n",
      "['paper' 'presents' 'article' 'discussed' 'presented' 'black' 'presented.'\n",
      " 'discusses' 'box' 'application' 'describes' 'discussed.' 'implementation'\n",
      " 'providing' 'related']\n",
      "['computer' 'vision' 'vision.' 'image' 'vision,' 'tasks' 'applications'\n",
      " 'recognition,' 'graphics' 'fundamental' 'tasks.' 'processing'\n",
      " 'applications.' 'detection,' 'success']\n",
      "['optimization' 'performance' 'optimizing' 'optimized' 'hyperparameter'\n",
      " 'optimize' 'hyperparameters' 'parameters' 'experiments' 'tuning'\n",
      " 'optimization.' 'practical' 'hyper-parameters' 'directly' 'tuned']\n",
      "['true' 'show' 'terms' 'close' 'underlying' 'measured' 'that,'\n",
      " 'arbitrarily' 'conditions,' 'observe' 'chosen' 'sense' 'minimal' 'maximal'\n",
      " 'leads']\n",
      "['multivariate' 'data' 'data.' 'mixed' 'data,' 'structure' 'univariate'\n",
      " 'real' 'simulated' 'illustrate' 'derived' 'membership' 'develop' 'propose'\n",
      " 'capture']\n",
      "['optimal' 'problem' 'optimality' 'asymptotically' 'solution' 'finding'\n",
      " 'suboptimal' 'close' 'tradeoff' 'optimal.' 'optimal,' 'solution.'\n",
      " 'optimally' 'sub-optimal' 'sense']\n",
      "['forward' 'validation' 'cross' 'backward' 'performing' 'back' 'requires'\n",
      " 'reverse' 'put' 'feed' 'perform' 'pass' 'die' 'directly' 'validate']\n",
      "['final' 'based' 'results' 'show' 'consensus' 'reach' 'truncated'\n",
      " 'experimental' 'single' 'result.' 'obtained' 'finally' 'separate'\n",
      " 'results.' 'result']\n",
      "['procedure' 'procedures' 'procedure.' 'propose' 'procedure,' 'procedures.'\n",
      " 'obtained' 'proposed' 'called' 'procedures,' 'simulation' 'real'\n",
      " 'directly' 'illustrate' 'introduce']\n",
      "['stage' 'stages' 'based' 'early' 'propose' 'stage,' 'learning' 'stage.'\n",
      " 'two-stage' 'consists' 'paper,' 'cascade' 'stages.' 'cascaded'\n",
      " 'multi-stage']\n",
      "['elements' 'element' 'paper' 'key' 'set' 'novelty' 'lies' 'form'\n",
      " 'elements.' 'e.g.,' 'main' 'similar' 'study' 'order' 'solution']\n",
      "['unsupervised' 'supervised' 'learning' 'learning.' 'learning,' 'labelled'\n",
      " 'unlabelled' 'manner.' 'semi-supervised' 'tasks,' 'data.'\n",
      " 'classification,' 'methods.' 'fully' 'successfully']\n",
      "['nodes' 'node' 'network' 'networks' 'nodes.' 'networks.' 'nodes,'\n",
      " 'network.' 'edges' 'networks,' 'network,' 'node.' 'centrality' 'topology'\n",
      " 'node,']\n",
      "['object' 'detection' 'bounding' 'proposals' 'detector' 'proposal'\n",
      " 'detection.' 'pascal' 'detectors' 'objects' 'voc' 'state-of-the-art'\n",
      " 'localization' 'box' 'detection,']\n",
      "['maximum' 'likelihood' 'estimation' 'posteriori' 'estimate' 'parameter'\n",
      " 'parameters' 'estimates' 'statistical' '(map)' 'estimation.' 'estimator'\n",
      " 'mle' 'estimation,' 'models.']\n",
      "['improvement' 'significant' 'compared' 'relative' 'baseline' 'performance'\n",
      " 'improvements' 'shows' 'additional' 'achieves' 'experiments' 'previous'\n",
      " 'improve' 'achieve' 'task']\n",
      "['forecasting' 'time' 'forecast' 'weather' 'series' 'climate' 'prediction'\n",
      " 'forecasts' 'data' 'temperature' 'solar' 'study' 'methodology'\n",
      " 'short-term' 'wind']\n",
      "['variational' 'inference' 'bayesian' 'posterior' 'approximate'\n",
      " 'approximation' 'stochastic' 'inference.' 'models.' 'approximations'\n",
      " 'inference,' 'latent' 'distributions' 'bayes' 'distribution']\n",
      "['retrieval' 'information' 'relevant' 'document' 'query' 'documents'\n",
      " 'relevance' 'search' 'retrieval,' 'retrieve' 'ir' 'retrieval.'\n",
      " 'experiments' 'retrieved' 'indexing']\n",
      "['action' 'actions' 'human' 'actions.' 'learn' 'learns' 'actions,'\n",
      " 'action.' 'current' 'observing' 'introduce' 'action,' 'challenging'\n",
      " 'observe' 'humans']\n",
      "['analysis' 'analysis.' 'analysis,' 'analyses' 'analyze' 'sensitivity'\n",
      " 'techniques' 'present' 'exploratory' 'analyzing' 'analyzed' 'perform'\n",
      " 'detailed' 'performed' 'addition']\n",
      "['deep' 'neural' 'networks' 'network' 'dnn' 'training' 'dnns' 'tasks'\n",
      " '(dnn)' '(dnns)' 'however,' 'train' 'perform' 'trained' 'work']\n",
      "['weights' 'weighted' 'weight' 'weighting' 'sum' 'weights.' 'weights,'\n",
      " 'computed' 'single' 'relative' 'unweighted' 'similar' 'sums' 'assign'\n",
      " 'assigned']\n",
      "['subset' 'set' 'subsets' '{\\\\it' 'chosen' 'selected' 'small' 'problem'\n",
      " 'randomly' 'select' 'optimal' 'goal' 'yields' 'collection' 'selecting']\n",
      "['aspects' 'aspect' 'important' 'work' 'analyze' 'study' 'provide' 'focus'\n",
      " 'understanding' 'specific' 'explore' 'strengths' 'analysis' 'perspective'\n",
      " 'interesting']\n",
      "['kernel' 'space' 'hilbert' 'reproducing' 'spaces' 'function' 'spaces.'\n",
      " 'space.' 'functions' 'kernels' 'rkhs' 'spaces,' 'space,' 'finite'\n",
      " 'classical']\n",
      "['regression' 'logistic' 'regression,' 'linear' 'regression.' 'statistical'\n",
      " 'hypergraph' 'multinomial' 'including' 'ridge' 'simple' 'parameters.'\n",
      " 'popular' 'applied' 'fit']\n",
      "['web' 'web.' 'metadata' 'pages' 'sites' 'page' 'services' 'access'\n",
      " 'linked' 'site' 'rdf' 'users' 'website' 'resources' 'information']\n",
      "['process' 'stationary' 'time' 'process.' 'non-stationary' 'stochastic'\n",
      " 'intensity' 'processes' 'ergodic' 'observed' 'processes.' 'point'\n",
      " 'process,' 'observation' 'mixing']\n",
      "['real-world' 'data' 'synthetic' 'data.' 'demonstrate' 'propose' 'data,'\n",
      " 'datasets' 'datasets.' 'experiments' 'develop' 'handle' 'efficacy'\n",
      " 'handling' 'illustrate']\n",
      "['quantitative' 'qualitative' 'results' 'analysis' 'provide' 'present'\n",
      " 'qualitatively' 'quantitatively' 'evaluations' 'show' 'effectively'\n",
      " 'prior' 'evaluate' 'relevant' 'demonstrate']\n",
      "['turing' 'machines' 'machine' 'universal' 'computation' 'machines.'\n",
      " 'computable' 'complexity' 'machines,' 'computational' 'halting' 'machine.'\n",
      " 'algorithmic' 'machine,' 'numbers']\n",
      "['probability' 'probabilities' 'probabilistic' 'conditional' 'distribution'\n",
      " 'probabilities.' 'probabilities,' 'estimated' 'measure' 'probability.'\n",
      " 'estimate' 'calculated' 'compute' 'assign' 'depends']\n",
      "['search' 'space' 'search.' 'engine' 'searching' 'exhaustive' 'search,'\n",
      " 'engines' 'searches' 'engine.' 'greedy' 'results.' 'heuristic' 'found'\n",
      " 'space.']\n",
      "['classification' 'multi-class' 'multi-label' 'classification.' 'class'\n",
      " 'classification,' 'binary' 'classifier' 'proposed' 'datasets'\n",
      " 'performance' 'classifiers' 'classes' 'problems.' 'methods']\n",
      "['stochastic' 'gradient' 'variance' 'convergence' 'deterministic'\n",
      " 'optimization' 'gradients' 'reduction' 'rate' 'mini-batch' 'analyze'\n",
      " 'gradient-based' 'reduced' 'descent.' 'problems,']\n",
      "['net' 'scalable' 'demonstrate' 'scalability' 'elastic' 'propose'\n",
      " 'large-scale' 'due' 'efficient' 'paper,' 'efficiency' 'experiments'\n",
      " 'combines' 'maintaining' 'nets']\n",
      "['results' 'compared' 'based' 'performed' 'showed' 'method' 'obtained'\n",
      " 'conducted' 'results:' 'achieved' 'performance' 'outperformed' 'methods:'\n",
      " 'respectively.' 'tested']\n",
      "['batch' 'normalization' 'learning' 'show' 'propose' 'paper,' 'shift'\n",
      " 'make' 'compared' 'bn' 'makes' 'commonly' 'improve' 'batches' 'recent']\n",
      "['estimate' 'estimates' 'estimating' 'estimated' 'method' 'calibration'\n",
      " 'accurate' 'accuracy' 'accurately' 'true' 'estimation' 'methods' 'precise'\n",
      " 'calibrated' 'applied']\n",
      "['functional' 'analysis' 'induced' 'paper' 'study' 'form' 'properties'\n",
      " 'obtained' 'nature' 'provide' 'applied' 'underlying' 'based' 'functionals'\n",
      " 'existence']\n",
      "['deep' 'training' 'networks' 'neural' 'convolutional' 'network'\n",
      " 'classification' 'trained' 'imagenet' 'state-of-the-art' 'image'\n",
      " 'pre-trained' 'train' 'cifar-10' 'convnet']\n",
      "['--' 'require' 'work' 'simple' 'provide' 'typically' 'settings' 'works'\n",
      " 'means' 'desirable' 'involve' 'type' 'e.g.' 'assumptions' 'and/or']\n",
      "['connection' 'connections' 'show' 'study' 'equivalent' 'equivalence'\n",
      " 'establish' 'particular,' 'finally,' 'discuss' 'showing' 'properties'\n",
      " 'perspective' 'interesting' 'draw']\n",
      "['provide' 'characterization' 'terms' 'characterize' 'complete' 'give'\n",
      " 'classical' 'study' 'characterized' 'precise' 'giving' 'particular,'\n",
      " 'general' 'finally,' 'characterizing']\n",
      "['guarantees' 'theoretical' 'provide' 'algorithms' 'guarantees.'\n",
      " 'guarantee' 'strong' 'empirical' 'practical' 'provable' 'worst-case'\n",
      " 'prove' 'practice' 'showing' 'enjoys']\n",
      "['virtual' 'machines' 'cloud' 'resource' 'vm' 'physical' 'migration'\n",
      " 'virtualization' 'workload' 'machine' 'performance' 'vms' 'placement'\n",
      " 'running' 'resources']\n",
      "['theorem' 'prove' 'result' 'proof' 'uniform' 'existence' 'limit' 'central'\n",
      " 'proved' 'conjecture' 'give' 'implies' 'property' 'class' 'version']\n",
      "['distance' 'distances' 'euclidean' 'measure' 'dissimilarity' 'pairwise'\n",
      " 'space' 'distance,' 'distance.' 'similarity' 'set' 'normalized' 'respect'\n",
      " 'distances.' 'multidimensional']\n",
      "['notion' 'general' 'notions' 'introduce' 'define' 'framework' 'theory'\n",
      " 'natural' 'extend' 'captures' 'properties' 'study' 'respect' 'applies'\n",
      " 'construct']\n",
      "['based' 'approach' 'signature' 'present' 'common' 'signatures' 'approach,'\n",
      " 'work' 'techniques' 'technique' 'proposed' 'distinguish' 'set' 'dynamic'\n",
      " 'application']\n",
      "['requirements' 'technical' 'design' 'study' 'paper' 'implementation'\n",
      " 'requirement' 'practical' 'integration' 'existing' 'report' 'attempt'\n",
      " 'required' 'innovation' 'purpose']\n",
      "['generalization' 'learning' 'ability' 'good' 'show' 'learning.' 'improve'\n",
      " 'capability' 'learning,' 'generalize' 'generalization.' 'training'\n",
      " 'robustness' 'paper,' 'algorithms,']\n",
      "['feedback' 'learning' 'present' 'feedback.' 'provided' 'feedback,' 'loop'\n",
      " 'provide' 'design' 'back' 'providing' 'current' 'paper' 'improve'\n",
      " 'allowing']\n",
      "['evaluation' 'metrics' 'performance' 'evaluating' 'evaluate' 'evaluated'\n",
      " 'evaluation.' 'automatic' 'metrics.' 'quality' 'comparing' 'evaluation,'\n",
      " 'methodology' 'metric' 'metrics,']\n",
      "['review' 'research' 'survey' 'comprehensive' 'literature' 'techniques'\n",
      " 'provide' 'overview' 'future' 'recent' 'applications' 'article' 'issues'\n",
      " 'field' 'discuss']\n",
      "['multimodal' 'modalities' 'multi-modal' 'multiple' 'representation'\n",
      " 'modality' 'cross-modal' 'multimedia' 'common' 'fusion' 'modalities.'\n",
      " 'shared' 'methods' 'learn' 'propose']\n",
      "['power' 'expressive' 'show' 'law' 'representational' 'simple' 'power.'\n",
      " 'efficiency' 'powerful' 'increase' 'computational' 'limits' 'capable'\n",
      " 'greater' 'full']\n",
      "['descriptors' 'image' 'local' 'features' 'descriptor' 'histogram'\n",
      " 'feature' 'state-of-the-art' 'representation' 'fisher' 'histograms'\n",
      " 'descriptors.' 'classification' 'spatial' 'oriented']\n",
      "['proposed' 'method' 'based' 'texture' 'performed' 'experiments' 'propose'\n",
      " 'compared' 'paper,' 'similar' 'obtained' 'method.' 'co-occurrence'\n",
      " 'textures' 'methods.']\n",
      "['knowledge' 'fuzzy' 'base' 'process' 'domain' 'learning' 'acquired'\n",
      " 'bases' 'acquisition' 'neuro-fuzzy' 'system' 'based' 'rules' 'knowledge.'\n",
      " 'logic']\n",
      "['system' 'paper' 'digital' 'developed' 'system,' 'prototype' 'system.'\n",
      " 'implemented' 'presents' 'describes' 'designed' 'implementation'\n",
      " 'integrated' 'prototypes' 'initial']\n",
      "['process' 'bayesian' 'nonparametric' 'dirichlet' 'model' 'hierarchical'\n",
      " 'inference' 'mixture' 'prior' 'number' 'infinite' 'models' 'poisson'\n",
      " 'beta' 'gibbs']\n",
      "['results' 'found' 'compared' 'obtained' 'reported' 'tested' 'literature'\n",
      " 'considered' 'applied' 'addition,' 'investigated' 'performed' 'techniques'\n",
      " 'previously' 'multi']\n",
      "['robust' 'robustness' 'outliers' 'outlier' 'outliers.' 'presence'\n",
      " 'sensitive' 'outliers,' 'noise' 'corrupted' 'robustly' 'contaminated'\n",
      " 'errors' 'develop' 'noisy']\n",
      "['$n$' '$k$' 'number' 'size' '$m$' '$d$' '$p$' 'dimension' '+' 'complexity'\n",
      " '\\\\log' '$n$.' 'optimal' '$q$' 'prove']\n",
      "['training' 'dropout' 'show' 'regularization' 'overfitting' 'effective'\n",
      " 'avoid' 'overfitting.' 'generalization' 'introduce' 'technique' 'similar'\n",
      " 'prevent' 'dropout,' 'weight']\n",
      "['traffic' 'network' 'routing' 'packet' 'route' 'real-time' 'network.'\n",
      " 'flows' 'application' 'paper,' 'congestion' 'forwarding' 'transportation'\n",
      " 'road' 'delay']\n",
      "['sequential' 'based' 'propose' 'existing' 'sequentially' 'shown'\n",
      " 'performance' 'show' 'demonstrate' 'improved' 'addition' 'particular,'\n",
      " 'efficient' 'dynamically' 'previous']\n",
      "['crowd' 'crowdsourcing' 'workers' 'tasks' 'task' 'reliability' 'worker'\n",
      " 'crowdsourced' 'mechanical' 'assignment' 'amazon' 'quality' 'human'\n",
      " 'workers.' 'multiple']\n",
      "['=' '\\\\in' '$x$' '$n$' '+' '\\\\times' '$n' '$a$' '\\\\leq' 'n$' '>' 'random'\n",
      " '\\\\geq' '<' '$s$']\n",
      "['model' 'models' 'fit' 'fitting' 'model.' 'data.' 'model,' 'parameters'\n",
      " 'models,' 'fits' 'fitted' 'models.' 'goodness' 'call' 'flexible']\n",
      "['universal' 'string' 'algorithmic' 'theory' 'computable' 'complexity'\n",
      " 'probability' 'give' 'strings' 'defined' 'kolmogorov' 'finite' 'induction'\n",
      " 'sequence' 'randomness']\n",
      "['experiments' 'experiment' 'experimental' 'results' 'report'\n",
      " 'experiments.' 'performed' 'study' 'present' 'controlled' 'found'\n",
      " 'subjects' 'conducted' 'experiments,' 'experiment.']\n",
      "['latent' 'model' 'variable' 'variables' 'models' 'variables.' 'inference'\n",
      " 'observed' 'probabilistic' 'variables,' 'generative' 'models,' 'structure'\n",
      " 'hidden' 'model,']\n",
      "['linear' 'nonlinear' 'highly' 'derive' 'results' 'algebra' 'piecewise'\n",
      " 'particular,' 'requiring' 'methods,' 'illustrate' 'numerical' 'functions,'\n",
      " 'furthermore,' 'nonlinearity']\n",
      "['risk' 'empirical' 'bounds' 'minimization' 'concentration' 'inequalities'\n",
      " 'generalization' 'excess' 'inequality' 'derive' 'bound' 'oracle' 'risk.'\n",
      " 'loss' 'uniform']\n",
      "['server' 'client' 'format' 'time' 'windows' 'implementation' 'file'\n",
      " 'repair' 'bug' 'based' 'servers' 'specific' 'clients' 'reports' 'server.']\n",
      "['attributes' 'attribute' 'attributes.' 'learn' 'attributes,' 'propose'\n",
      " 'approach' 'existing' 'datasets' 'challenging' 'experimental' 'discover'\n",
      " 'learns' 'observe' 'datasets.']\n",
      "['basis' 'function' 'functions' 'expansion' 'coefficients' 'radial'\n",
      " 'functions.' 'terms' 'derivatives' 'rbf' 'defined' 'basis.' 'function.'\n",
      " 'coefficients.' 'expansions']\n",
      "['eeg' 'signals' 'subjects' 'brain' 'recorded' 'bci' 'signals.' 'potential'\n",
      " '(eeg)' 'interface' 'physiological' 'recording' 'recordings' 'motor'\n",
      " 'brain-computer']\n",
      "['(b)' '(a)' 'provide' '(c)' 'show' 'present' '(as' 'results' 'means'\n",
      " 'larger' 'large' 'standard' 'strong' 'possibly' 'obtain']\n",
      "['convolutional' 'cnn' 'neural' 'networks' 'cnns' 'deep' 'network' '(cnn)'\n",
      " 'image' '(cnns)' 'trained' 'state-of-the-art' 'pre-trained' 'architecture'\n",
      " 'cnns.']\n",
      "['influence' 'study' 'paper,' 'based' 'find' 'important' 'investigate'\n",
      " 'analyze' 'identify' 'seed' 'maximization' 'influential' 'design'\n",
      " 'finding' 'influences']\n",
      "['restricted' 'boltzmann' 'machines' 'machine' 'hidden' 'deep' 'generative'\n",
      " 'model' 'visible' 'contrastive' 'rbm' 'belief' 'units' 'models'\n",
      " 'learning.']\n",
      "['categories' 'category' 'fine-grained' 'learning' 'categorization'\n",
      " 'categories.' 'soft' 'existing' 'specific' 'categories,' 'classifying'\n",
      " 'challenging' 'propose' 'category,' 'classification']\n",
      "['set' 'summarization' 'informative' 'introduce' 'produce' 'diverse'\n",
      " 'large' 'summarize' 'summary' 'enable' 'summaries' 'evaluate' 'important'\n",
      " 'create' 'story']\n",
      "['properties' 'property' 'properties.' 'desirable' 'properties,'\n",
      " 'important' 'theoretical' 'interesting' 'including' 'furthermore,'\n",
      " 'appealing' 'possess' 'establish' 'attractive' 'satisfy']\n",
      "['channel' 'transmission' 'channels' 'interference' 'wireless'\n",
      " 'information' 'power' 'receiver' 'communication' 'transmit' 'rate'\n",
      " 'transmitter' 'channel.' 'capacity' 'channels.']\n",
      "['order' 'paper' 'carried' 'work' 'aim' 'deal' 'suitable' 'that,'\n",
      " 'context,' 'ensure' 'aims' 'considered' 'introduces' 'means' 'consists']\n",
      "['positive' 'negative' 'show' 'definite' 'set' 'semidefinite' 'paper'\n",
      " 'examples' 'example,' 'semi-definite' '(i.e.,' 'motivate' 'i.e.,'\n",
      " 'particular,' 'that,']\n",
      "['address' 'problem,' 'propose' 'problem' 'demonstrate' 'however,'\n",
      " 'challenging' 'issue,' 'effectiveness' 'tackle' 'effective' 'effectively'\n",
      " 'experiments' 'exploiting' 'specifically,']\n",
      "['recognition' 'pattern' 'recognition.' 'accuracy' 'recognition,' 'object'\n",
      " 'gesture' 'recognize' 'feature' 'recognizing' 'hand' 'gestures' 'tasks.'\n",
      " 'achieved' 'recognized']\n",
      "['query' 'queries' 'queries.' 'oracle' 'membership' 'queries,' 'show'\n",
      " 'querying' 'study' 'access' 'answer' 'answers' 'database' 'query.'\n",
      " 'sparql']\n",
      "['control' 'controller' 'system' 'controllers' 'adaptive' 'dynamics'\n",
      " 'simulation' 'desired' 'state' 'nonlinear' 'system.' 'stability' 'systems'\n",
      " 'controller.' 'dynamics.']\n",
      "['algorithms' 'efficient' 'present' 'give' 'algorithmic' 'applications'\n",
      " 'algorithms.' 'problems' 'algorithms,' 'general' 'motivated' 'showing'\n",
      " 'provide' 'fundamental' 'giving']\n",
      "['false' 'rate' 'positive' 'true' 'rates' 'discovery' 'high' 'real' 'alarm'\n",
      " 'rate.' 'low' 'positives' 'detect' 'spurious' 'rates.']\n",
      "['complex' 'simple' 'sophisticated' 'order' 'real' 'complex-valued'\n",
      " 'increasingly' 'simpler' 'however,' 'dealing' 'derive' 'powerful'\n",
      " 'real-valued' 'widely' 'paper,']\n",
      "['inference' 'probabilistic' 'models' 'model' 'inference.' 'inference,'\n",
      " 'infer' 'bayesian' 'models.' 'perform' 'generative' 'models,' 'graphical'\n",
      " 'model.' 'inferring']\n",
      "['future' 'discuss' 'research' 'directions' 'research.' 'conclude'\n",
      " 'finally,' 'discussion' 'current' 'potential' 'taxonomy' 'highlight'\n",
      " 'promising' 'open' 'limitations']\n",
      "['majority' 'voting' 'vast' 'weighted' 'political' 'compare' 'proxy'\n",
      " 'shows' 'good' 'evaluate' 'vote' 'suggest' 'relies' 'votes' 'combination']\n",
      "['treatment' 'effects' 'outcome' 'effect' 'outcomes' 'data' 'covariates'\n",
      " 'estimating' 'observational' 'trial' 'individual' 'effects.' 'covariate'\n",
      " 'treated' 'treatments']\n",
      "['proof' 'proofs' 'logic' 'theorem' 'formal' 'interactive' 'mathematical'\n",
      " 'prove' 'first-order' 'statements' 'classical' 'axioms' 'automated'\n",
      " 'proving' 'theory']\n",
      "['parallel' 'distributed' 'implementation' 'computing' 'cluster'\n",
      " 'processing' 'memory' 'mapreduce' 'speedup' 'parallelization' 'processors'\n",
      " 'execution' 'parallelism' 'multi-core' 'machines.']\n",
      "['regular' 'present' 'selective' 'called' 'however,' 'capable' 'perform'\n",
      " 'form' 'represent' 'mesh' 'performing' 'irregular' 'conventional'\n",
      " 'comparison' 'formed']\n",
      "['online' 'algorithm' 'algorithms' 'regret' 'offline' 'learning' 'batch'\n",
      " 'competitive' 'setting' 'algorithm.' 'setting.' 'setting,' 'algorithms.'\n",
      " 'analyze' 'online,']\n",
      "['existing' 'unlike' 'approach' 'contrast' 'propose' 'require'\n",
      " 'approaches,' 'directly' 'methods,' 'approaches' 'previous' 'makes'\n",
      " 'traditional' 'easily' 'conventional']\n",
      "['instances' 'instance' 'learning' 'multiple' 'instances.' 'problem'\n",
      " 'instances,' 'bag' 'propose' 'mil' 'bags' 'multi-instance' 'instance,'\n",
      " 'address' 'instance.']\n",
      "['physical' 'physics' 'discuss' 'critical' 'argue' 'phenomena'\n",
      " 'simulations' 'systems' 'complex' 'biological' 'energy' 'laws'\n",
      " 'quantities' 'physics.' 'ideas']\n",
      "['genetic' 'association' 'associations' 'studies' 'data' 'disease'\n",
      " 'effects' 'applied' 'variants' 'simulation' 'important' 'common' 'genomic'\n",
      " 'multiple' 'statistical']\n",
      "['random' 'walk' 'show' 'randomly' 'independent' 'walks' 'properties'\n",
      " 'probability' 'that,' 'study' 'construction' 'fixed' 'pair' 'motivated'\n",
      " 'empirically']\n",
      "['designed' 'specifically' 'based' 'carefully' 'perform' 'work' 'paper'\n",
      " 'specially' 'providing' 'general' 'aim' 'types' 'proposed' 'obtaining'\n",
      " 'tailored']\n",
      "['power' 'grid' 'system' 'frequency' 'smart' 'wind' 'grids' 'generation'\n",
      " 'operational' 'voltage' 'distribution' 'topology' 'measurements'\n",
      " 'synchronous' 'real-time']\n",
      "['image' 'color' 'images' 'background' 'pixel' 'hyperspectral' 'pixels'\n",
      " 'images.' 'image.' 'foreground' 'spatial' 'scene' 'method' 'colour'\n",
      " 'images,']\n",
      "['flow' 'optical' 'based' 'approach' 'work' 'demonstrate' 'current' 'flows'\n",
      " 'due' 'work,' 'flow.' 'typically' 'build' 'flow,' 'competitive']\n",
      "['conditions' 'sufficient' 'provide' 'conditions.' '$' 'conditions,'\n",
      " 'derive' 'mild' 'condition' 'guarantee' 'give' 'establish' '(or' 'weaker'\n",
      " 'cases,']\n",
      "['abstract' 'semantics' 'machine' 'calculus' 'higher-order' 'machines'\n",
      " 'form' 'terms' 'reduction' 'operational' 'machine,' 'lambda'\n",
      " 'implementation' 'machine.' 'proof']\n",
      "['sampling' 'sampled' 'importance' 'sampling.' 'sampling,' 'samples'\n",
      " 'uniform' 'random' 'distribution' 'thompson' 'gibbs' 'non-uniform'\n",
      " 'distribution.' 'leverage' 'sample']\n",
      "['compression' 'compressed' 'large' 'technique' 'show' 'based' 'size'\n",
      " 'compress' 'achieve' 'lossy' 'compression,' 'reduce' 'smaller'\n",
      " 'compression.' 'however,']\n",
      "['semantic' 'semantics' 'ontology' 'concepts' 'semantically' 'information'\n",
      " 'knowledge' 'meaning' 'representation' 'rich' 'capture' 'distributional'\n",
      " 'ontologies' 'semantics.' 'enables']\n",
      "['deep' 'learning' 'learning.' 'learning,' 'tasks,' 'recently,'\n",
      " 'architectures' 'successful' 'guide' 'success' 'architecture' 'utilize'\n",
      " 'comprehensive' 'boost' 'caffe']\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file=open('./pickles/topics_pruned.pickle', 'wb'), obj = topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file=open('./pickles/paper_dist_pruned.pickle', 'wb'), obj = data_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Post-Preprocessing Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1, Topic-wise normalise (Val - Mean)/Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_norm = data_in[:]\n",
    "data_norm = np.subtract(data_norm, np.mean(data_norm, axis = 0))/np.var(data_norm, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2, Max-Min Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_maxmin = data_in[:]\n",
    "data_maxmin = np.subtract(data_maxmin, np.min(data_maxmin, axis = 0))/(np.max(data_maxmin, axis = 0) - np.min(data_maxmin, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct User Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile('([^\\s\\w]|_)+')\n",
    "user_map = {}\n",
    "users_raw = data_original['authors'].values\n",
    "users_cleaned = [] #List of authors for each paper\n",
    "for idx, authors in enumerate(users_raw):\n",
    "    authors = authors.split(',')\n",
    "    clean_authors = []\n",
    "    for author in authors:\n",
    "        author = pattern.sub('', author)\n",
    "        author = author.strip()\n",
    "        clean_authors.append(author)\n",
    "        author = author.lower()\n",
    "        if author in user_map:\n",
    "            user_map[author].append(idx)\n",
    "        else:\n",
    "            user_map[author] = [idx]\n",
    "    users_cleaned.append(clean_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file = open('./pickles/user_mappings.pickle', 'wb'), obj=user_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17060]\n"
     ]
    }
   ],
   "source": [
    "print(user_map['aniruddh raghu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_user_var(user_map_in, data_in_to): \n",
    "    user_research = np.zeros((len(user_map_in.keys()), np.shape(data_in_to)[1]))\n",
    "    user_id_map = {} #hash of author names to author index in superlist (not related to users_cleaned above)\n",
    "    user_id_map_reverse = {} #hash of author index to author names\n",
    "    i = 0\n",
    "    for author in user_map_in.keys():\n",
    "        blank = np.zeros((np.shape(data_in_to)[1]))\n",
    "        user_id_map[author] = i\n",
    "        user_id_map_reverse[i] = author\n",
    "        for paper in user_map_in[author]:\n",
    "            blank = np.add(blank, data_in_to[paper])\n",
    "        user_research[i] = blank\n",
    "        i+=1\n",
    "    return ((user_id_map, user_id_map_reverse) , user_research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def paper_author_id_mappings(paper_to_author, author_to_id):\n",
    "        paper_to_id = []\n",
    "        for paper in paper_to_author:\n",
    "            paper_ids = []\n",
    "            for author in paper:\n",
    "                paper_ids.append(author_to_id[author.lower()])\n",
    "            paper_to_id.append(paper_ids)\n",
    "        return paper_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "papers = data_original['title'].values\n",
    "user_map_name = {}\n",
    "for key in user_map.keys():\n",
    "    lst = [papers[p_id] for p_id in user_map[key]]\n",
    "    user_map_name[key] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute user arrays\n",
    "user_id_map, user_research = build_user_var(user_map, data_in)\n",
    "papauth_id = paper_author_id_mappings(users_cleaned, user_id_map[0])\n",
    "\n",
    "#user_map - Author name -> paper IDs\n",
    "#user_map_name - Author name -> paper names\n",
    "#user_id_map[0] - Author name -> ID\n",
    "#user_id_map[1] - ID -> Author name\n",
    "#user_research - A summed list of topic  \n",
    "#papauth_id - paper ID to author IDs\n",
    "#users_cleaned - paper ID to author name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file = open('./pickles/auth_paper_title.pickle', 'wb'), obj = user_map_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file=open('./pickles/user_research_data.pickle', 'wb'), obj = user_research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file = open('./pickles/user_id_maps.pickle', 'wb'), obj = user_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file = open('./pickles/paper_auth_id.pickle', 'wb'), obj = papauth_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(file = open('./pickles/paper_auth_name.pickle', 'wb'), obj = users_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id_map = pickle.load(file = open('./pickles/user_id_maps.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_research = pickle.load(file=open('./pickles/user_research_data.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbrs_dep = NearestNeighbors(n_neighbors=10, algorithm='auto').fit(user_research) #Experience Dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_for_author(author, id_map, user_profile, neighbour):\n",
    "    distances, indices = neighbour.kneighbors(user_profile[id_map[0][author.lower()]].reshape(1, -1))\n",
    "    for idx, i in enumerate(indices):\n",
    "        for j in i:\n",
    "            print(id_map[1][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "david sontag\n",
      "edward choi\n",
      "david c kale\n",
      "walter f stewart\n",
      "scott hu\n",
      "jinsung yoon\n",
      "suchi saria\n",
      "mohammad taha bahadori\n",
      "andy schuetz\n",
      "peter szolovits\n"
     ]
    }
   ],
   "source": [
    "compute_for_author('David Sontag', user_id_map, user_research, nbrs_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yann lecun\n",
      "joan bruna\n",
      "michael mathieu\n",
      "arthur szlam\n",
      "andrew zisserman\n",
      "rob fergus\n",
      "roberto cipolla\n",
      "eugenio culurciello\n",
      "edouard oyallon\n",
      "amnon shashua\n"
     ]
    }
   ],
   "source": [
    "compute_for_author('Yann lecun', user_id_map, user_research, nbrs_dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbrs_papers = NearestNeighbors(n_neighbors=10, algorithm='auto').fit(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_for_paper(search_term, data_proc, data_orig, paper_author_map, id_map, neighbour):\n",
    "    res = [i for i in enumerate(data_orig['title'].values) if search_term.lower() in i[1].lower()]\n",
    "    for result in res:\n",
    "        print('Results for:', result[1], ' by:', paper_author_map[result[0]])\n",
    "        print('--------')\n",
    "        distances, indices = neighbour.kneighbors(data_proc[result[0]].reshape(1, -1))\n",
    "        for i in indices:\n",
    "            for j in i:\n",
    "                print(data_orig.iloc[j, :]['title'])\n",
    "        print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for: Continuous State-Space Models for Optimal Sepsis Treatment - a Deep\n",
      "  Reinforcement Learning Approach  by: ['Aniruddh Raghu', 'Matthieu Komorowski', 'Leo Anthony Celi', 'Peter Szolovits', 'Marzyeh Ghassemi']\n",
      "--------\n",
      "Continuous State-Space Models for Optimal Sepsis Treatment - a Deep\n",
      "  Reinforcement Learning Approach\n",
      "A Reinforcement Learning Approach to Weaning of Mechanical Ventilation\n",
      "  in Intensive Care Units\n",
      "A Naive Bayes machine learning approach to risk prediction using\n",
      "  censored, time-to-event data\n",
      "Sparse Multi-Output Gaussian Processes for Medical Time Series\n",
      "  Prediction\n",
      "DeepSurv: Personalized Treatment Recommender System Using A Cox\n",
      "  Proportional Hazards Deep Neural Network\n",
      "Identifying Diabetic Patients with High Risk of Readmission\n",
      "Personalized Risk Scoring for Critical Care Patients using Mixtures of\n",
      "  Gaussian Process Experts\n",
      "DeepCare: A Deep Dynamic Memory Model for Predictive Medicine\n",
      "Personalized Risk Scoring for Critical Care Prognosis using Mixtures of\n",
      "  Gaussian Processes\n",
      "Building Classifiers to Predict the Start of Glucose-Lowering\n",
      "  Pharmacotherapy Using Belgian Health Expenditure Data\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "compute_for_paper('Continuous State-Space Models for Optimal Sepsis Treatment', data_in, data_original, users_cleaned ,user_id_map, nbrs_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for: Wasserstein GAN  by: ['Martin Arjovsky', 'Soumith Chintala', 'Lon Bottou']\n",
      "--------\n",
      "Wasserstein GAN\n",
      "Improved Training of Wasserstein GANs\n",
      "Generative Models and Model Criticism via Optimized Maximum Mean\n",
      "  Discrepancy\n",
      "Annealed Generative Adversarial Networks\n",
      "Generating images with recurrent adversarial networks\n",
      "Submodular Mini-Batch Training in Generative Moment Matching Networks\n",
      "Learning a regression function via Tikhonov regularization\n",
      "Differential Contrastive Divergence\n",
      "A Machine-Learning Framework for Design for Manufacturability\n",
      "Comments on `High-dimensional simultaneous inference with the bootstrap'\n",
      "--------\n",
      "Results for: Improved Training of Wasserstein GANs  by: ['Ishaan Gulrajani', 'Faruk Ahmed', 'Martin Arjovsky', 'Vincent Dumoulin', 'Aaron Courville']\n",
      "--------\n",
      "Improved Training of Wasserstein GANs\n",
      "Gradient descent GAN optimization is locally stable\n",
      "Generating images with recurrent adversarial networks\n",
      "Adversarial Ranking for Language Generation\n",
      "Probabilistic Generative Adversarial Networks\n",
      "BEGAN: Boundary Equilibrium Generative Adversarial Networks\n",
      "Stabilizing Training of Generative Adversarial Networks through\n",
      "  Regularization\n",
      "Generative Adversarial Network based on Resnet for Conditional Image\n",
      "  Restoration\n",
      "Gang of GANs: Generative Adversarial Networks with Maximum Margin\n",
      "  Ranking\n",
      "Fisher GAN\n",
      "--------\n",
      "Results for: Face Super-Resolution Through Wasserstein GANs  by: ['Zhimin Chen', 'Yuguang Tong']\n",
      "--------\n",
      "Face Super-Resolution Through Wasserstein GANs\n",
      "Comparison of Maximum Likelihood and GAN-based training of Real NVPs\n",
      "Generating images with recurrent adversarial networks\n",
      "Improved Training of Wasserstein GANs\n",
      "Adversarial Feature Matching for Text Generation\n",
      "Gradient descent GAN optimization is locally stable\n",
      "Probabilistic Generative Adversarial Networks\n",
      "DeLiGAN : Generative Adversarial Networks for Diverse and Limited Data\n",
      "Stabilizing Training of Generative Adversarial Networks through\n",
      "  Regularization\n",
      "Adversarial Ranking for Language Generation\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "compute_for_paper('Wasserstein GAN', data_in, data_original, users_cleaned ,user_id_map, nbrs_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-581c7bb161f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mk_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mk_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0massignments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 x_squared_norms=x_squared_norms, random_state=random_state)\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialization complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     centers, labels, n_iter = k_means_elkan(X, n_clusters, centers, tol=tol,\n\u001b[0;32m--> 400\u001b[0;31m                                             max_iter=max_iter, verbose=verbose)\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0minertia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/cluster/_k_means_elkan.pyx\u001b[0m in \u001b[0;36msklearn.cluster._k_means_elkan.k_means_elkan\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, order)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \"\"\"\n\u001b[1;32m    152\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 1500\n",
    "k_m = KMeans(n_clusters=num_clusters, max_iter = 1000)\n",
    "k_m.fit(data_in)\n",
    "centers = k_m.cluster_centers_\n",
    "assignments = k_m.labels_\n",
    "sns.distplot(assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reverse_assignments = [0]*num_clusters\n",
    "for i in assignments:\n",
    "    reverse_assignments[i] += 1\n",
    "reverse_assignments = np.array(reverse_assignments)\n",
    "print('Mean papers per cluster:', np.mean(reverse_assignments), '| Variance of papers per cluster: ', np.var(reverse_assignments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_means_save = (centers, assignments, reverse_assignments)\n",
    "pickle.dump(file = open('./pickles/kmeans_save.pickle', 'wb'), obj=k_means_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers, assignments, reverse_assignments = pickle.load(file = open('./pickles/kmeans_save.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assignments_dict = {}\n",
    "reverse_assignments_dict = {}\n",
    "for idx in range(len(assignments)):\n",
    "    assignments_dict[idx] = assignments[idx]\n",
    "    if assignments[idx] in reverse_assignments_dict:\n",
    "        reverse_assignments_dict[assignments[idx]].append(idx)\n",
    "    else:\n",
    "        reverse_assignments_dict[assignments[idx]] = [idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_for_cluster(search_term, dict_in, reverse_dict_in, data_orig, cluster_limit = 10):\n",
    "    res = [i for i in enumerate(data_orig['title'].values) if search_term.lower() in i[1].lower()]\n",
    "    prev_clusters = set()\n",
    "    for result in res[:cluster_limit]:\n",
    "        print('Results for:', result[1])\n",
    "        print('--------')\n",
    "        clust = dict_in[result[0]]\n",
    "        if clust not in prev_clusters:\n",
    "            prev_clusters.add(clust)\n",
    "            for idxes in reverse_dict_in[clust]:\n",
    "                print(data_orig.iloc[idxes, :]['title'])\n",
    "        else:\n",
    "            print('Cluster already printed')\n",
    "        print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for: Churn analysis using deep convolutional neural networks and autoencoders\n",
      "--------\n",
      "Churn analysis using deep convolutional neural networks and autoencoders\n",
      "Morpheo: Traceable Machine Learning on Hidden data\n",
      "Revealed Preference at Scale: Learning Personalized Preferences from\n",
      "  Assortment Choices\n",
      "Contextual Markov Decision Processes\n",
      "Learning with Changing Features\n",
      "A Deep Causal Inference Approach to Measuring the Effects of Forming\n",
      "  Group Loans in Online Non-profit Microfinance Platform\n",
      "GaDei: On Scale-up Training As A Service For Deep Learning\n",
      "Large-Scale Detection of Non-Technical Losses in Imbalanced Data Sets\n",
      "Predicting Near-Future Churners and Win-Backs in the Telecommunications\n",
      "  Industry\n",
      "An expert system for detecting automobile insurance fraud using social\n",
      "  network analysis\n",
      "On Detecting Messaging Abuse in Short Text Messages using Linguistic and\n",
      "  Behavioral patterns\n",
      "Exploiting Big Data in Logistics Risk Assessment via Bayesian\n",
      "  Nonparametrics\n",
      "Model-based Dashboards for Customer Analytics\n",
      "Dfinition d'une pice test pour la caractrisation d'une machine\n",
      "  UGV\n",
      "Online Learning of Aggregate Knowledge about Non-linear Preferences\n",
      "  Applied to Negotiating Prices and Bundles\n",
      "A data mining approach using transaction patterns for card fraud\n",
      "  detection\n",
      "Service Composition Design Pattern for Autonomic Computing Systems using\n",
      "  Association Rule based Learning and Service-Oriented Architecture\n",
      "Autonomous CRM Control via CLV Approximation with Deep Reinforcement\n",
      "  Learning in Discrete and Continuous Action Space\n",
      "Deep Learning based Large Scale Visual Recommendation and Search for\n",
      "  E-Commerce\n",
      "Impact of Detour-Aware Policies on Maximizing Profit in Ridesharing\n",
      "Data Mining Approach for Analyzing Call Center Performance\n",
      "Assessment of Customer Credit through Combined Clustering of Artificial\n",
      "  Neural Networks, Genetics Algorithm and Bayesian Probabilities\n",
      "An Integrated Classification Model for Financial Data Mining\n",
      "Large Scale Business Discovery from Street Level Imagery\n",
      "Store Location Selection via Mining Search Query Logs of Baidu Maps\n",
      "Opaque Response Generation Enabling Automatic Creation of Virtual\n",
      "  Services for Service Virtualisation\n",
      "Replicating and Scaling up Qualitative Analysis using Crowdsourcing: A\n",
      "  Github-based Case Study\n",
      "--------\n",
      "Results for: An Introduction to Convolutional Neural Networks\n",
      "--------\n",
      "An Introduction to Convolutional Neural Networks\n",
      "Learning to Select Pre-Trained Deep Representations with Bayesian\n",
      "  Evidence Framework\n",
      "Deep Deconvolutional Networks for Scene Parsing\n",
      "SVM and ELM: Who Wins? Object Recognition with Deep Convolutional\n",
      "  Features from ImageNet\n",
      "Sparse Factorization Layers for Neural Networks with Limited Supervision\n",
      "Metaheuristic Algorithms for Convolution Neural Network\n",
      "Classifying and Segmenting Microscopy Images Using Convolutional\n",
      "  Multiple Instance Learning\n",
      "Explaining Predictions of Non-Linear Classifiers in NLP\n",
      "Predicting Shot Making in Basketball Learnt from Adversarial Multiagent\n",
      "  Trajectories\n",
      "A Generalization of Convolutional Neural Networks to Graph-Structured\n",
      "  Data\n",
      "Towards Understanding the Invertibility of Convolutional Neural Networks\n",
      "Harmonic Networks: Deep Translation and Rotation Equivariance\n",
      "Towards Evolutional Compression\n",
      "CNN Architectures for Large-Scale Audio Classification\n",
      "Handwritten Bangla Digit Recognition Using Deep Learning\n",
      "A Novel Hybrid CNN-AIS Visual Pattern Recognition Engine\n",
      "A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional\n",
      "  Neural Networks for Sentence Classification\n",
      "Localization of JPEG double compression through multi-domain\n",
      "  convolutional neural networks\n",
      "Learning Fine-grained Features via a CNN Tree for Large-scale\n",
      "  Classification\n",
      "Grouped Convolutional Neural Networks for Multivariate Time Series\n",
      "BranchConnect: Large-Scale Visual Recognition with Learned Branch\n",
      "  Connections\n",
      "Evaluation of Deep Convolutional Nets for Document Image Classification\n",
      "  and Retrieval\n",
      "Scene Parsing with Integration of Parametric and Non-parametric Models\n",
      "Learning rotation invariant convolutional filters for texture\n",
      "  classification\n",
      "Latent Model Ensemble with Auto-localization\n",
      "Integrating Deep Features for Material Recognition\n",
      "An End-to-End Compression Framework Based on Convolutional Neural\n",
      "  Networks\n",
      "Training Group Orthogonal Neural Networks with Privileged Information\n",
      "Multi-Level and Multi-Scale Feature Aggregation Using Pre-trained\n",
      "  Convolutional Neural Networks for Music Auto-tagging\n",
      "Generative Modeling of Convolutional Neural Networks\n",
      "Using Filter Banks in Convolutional Neural Networks for Texture\n",
      "  Classification\n",
      "Geodesic convolutional neural networks on Riemannian manifolds\n",
      "Spectral Networks and Locally Connected Networks on Graphs\n",
      "Learn Convolutional Neural Network for Face Anti-Spoofing\n",
      "The Role of Typicality in Object Classification: Improving The\n",
      "  Generalization Capacity of Convolutional Neural Networks\n",
      "Convolutional Tables Ensemble: classification in microseconds\n",
      "Deep Learning for Logo Recognition\n",
      "Improving Robustness of Feature Representations to Image Deformations\n",
      "  using Powered Convolution in CNNs\n",
      "Mining Object Parts from CNNs via Active Question-Answering\n",
      "Cross-convolutional-layer Pooling for Image Recognition\n",
      "Convolutional Neural Network-based Place Recognition\n",
      "Understanding image representations by measuring their equivariance and\n",
      "  equivalence\n",
      "Compressing Deep Convolutional Networks using Vector Quantization\n",
      "Understanding Intra-Class Knowledge Inside CNN\n",
      "Real-time Sign Language Fingerspelling Recognition using Convolutional\n",
      "  Neural Networks from Depth map\n",
      "Fast Algorithms for Convolutional Neural Networks\n",
      "Aspect-based Opinion Summarization with Convolutional Neural Networks\n",
      "Unified Depth Prediction and Intrinsic Image Decomposition from a Single\n",
      "  Image via Joint Convolutional Neural Fields\n",
      "Fusing Deep Convolutional Networks for Large Scale Visual Concept\n",
      "  Classification\n",
      "A 4D Light-Field Dataset and CNN Architectures for Material Recognition\n",
      "Character-level and Multi-channel Convolutional Neural Networks for\n",
      "  Large-scale Authorship Attribution\n",
      "DeepGaze II: Reading fixations from deep features trained on object\n",
      "  recognition\n",
      "Learning Deep NBNN Representations for Robust Place Categorization\n",
      "Deep Feature Consistent Deep Image Transformations: Downscaling,\n",
      "  Decolorization and HDR Tone Mapping\n",
      "An Empirical Evaluation of Current Convolutional Architectures' Ability\n",
      "  to Manage Nuisance Location and Scale Variability\n",
      "Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient\n",
      "  Convolutional Neural Networks\n",
      "On Random Weights for Texture Generation in One Layer Neural Networks\n",
      "Center-Focusing Multi-task CNN with Injected Features for Classification\n",
      "  of Glioma Nuclear Images\n",
      "Gabor Filter Assisted Energy Efficient Fast Learning Convolutional\n",
      "  Neural Networks\n",
      "Hybrid CNN and Dictionary-Based Models for Scene Recognition and Domain\n",
      "  Adaptation\n",
      "--------\n",
      "Results for: Star-galaxy Classification Using Deep Convolutional Neural Networks\n",
      "--------\n",
      "Machine Learning Etudes in Astrophysics: Selection Functions for Mock\n",
      "  Cluster Catalogs\n",
      "Star-galaxy Classification Using Deep Convolutional Neural Networks\n",
      "Machine Learning Classification of SDSS Transient Survey Images\n",
      "Machine Learning for Galaxy Morphology Classification\n",
      "Computational Intelligence Challenges and Applications on Large-Scale\n",
      "  Astronomical Time Series Databases\n",
      "Active Learning to Overcome Sample Selection Bias: Application to\n",
      "  Photometric Variable Star Classification\n",
      "Construction of a Calibrated Probabilistic Classification Catalog:\n",
      "  Application to 50k Variable Sources in the All-Sky Automated Survey\n",
      "Robust Machine Learning Applied to Terascale Astronomical Datasets\n",
      "Astroinformatics of galaxies and quasars: a new general method for\n",
      "  photometric redshifts estimation\n",
      "Using Machine Learning for Discovery in Synoptic Survey Imaging\n",
      "Generative Adversarial Networks recover features in astrophysical images\n",
      "  of galaxies beyond the deconvolution limit\n",
      "Automated Classification of Periodic Variable Stars detected by the\n",
      "  Wide-field Infrared Survey Explorer\n",
      "Semi-supervised Learning for Photometric Supernova Classification\n",
      "Applying Data Mining and Machine Learning Techniques to Submarine\n",
      "  Intelligence Analysis\n",
      "Fast, Linear Time Hierarchical Clustering using the Baire Metric\n",
      "Phylogenetic Tools in Astrophysics\n",
      "Rotation-invariant convolutional neural networks for galaxy morphology\n",
      "  prediction\n",
      "Astroinformatics: A 21st Century Approach to Astronomy\n",
      "A GMBCG Galaxy Cluster Catalog of 55,424 Rich Clusters from SDSS DR7\n",
      "Real-Time Data Mining of Massive Data Streams from Synoptic Sky Surveys\n",
      "Single parameter galaxy classification: The Principal Curve through the\n",
      "  multi-dimensional space of galaxy properties\n",
      "Mapping the Similarities of Spectra: Global and Locally-biased\n",
      "  Approaches to SDSS Galaxy Data\n",
      "A probabilistic approach to emission-line galaxy classification\n",
      "Clustering with phylogenetic tools in astrophysics\n",
      "Simulating the universe on an intercontinental grid of supercomputers\n",
      "Multivariate Approaches to Classification in Extragalactic Astronomy\n",
      "Generation of a Supervised Classification Algorithm for Time-Series\n",
      "  Variable Stars with an Application to the LINEAR Dataset\n",
      "On the estimation of stellar parameters with uncertainty prediction from\n",
      "  Generative Artificial Neural Networks: application to Gaia RVS simulated\n",
      "  spectra\n",
      "--------\n",
      "Results for: Rapid Classification of Crisis-Related Data on Social Networks using\n",
      "  Convolutional Neural Networks\n",
      "--------\n",
      "Actively Learning to Attract Followers on Twitter\n",
      "AI-Powered Social Bots\n",
      "Cyberbullying Identification Using Participant-Vocabulary Consistency\n",
      "Rapid Classification of Crisis-Related Data on Social Networks using\n",
      "  Convolutional Neural Networks\n",
      "Detecting Events and Patterns in Large-Scale User Generated Textual\n",
      "  Streams with Statistical Learning Methods\n",
      "Social Media-based Substance Use Prediction\n",
      "Spatio-Temporal Modeling of Users' Check-ins in Location-Based Social\n",
      "  Networks\n",
      "Determining the Veracity of Rumours on Twitter\n",
      "RedQueen: An Online Algorithm for Smart Broadcasting in Social Networks\n",
      "Predicting online extremism, content adopters, and interaction\n",
      "  reciprocity\n",
      "Antisocial Behavior in Online Discussion Communities\n",
      "Detecting Real-World Influence Through Twitter\n",
      "Towards the Modeling of Behavioral Trajectories of Users in Online\n",
      "  Social Media\n",
      "The nature and origin of heavy tails in retweet activity\n",
      "Early Detection of Promoted Campaigns on Social Media\n",
      "The Bursty Dynamics of the Twitter Information Network\n",
      "The Predictive Power of Social Media: On the Predictability of U.S.\n",
      "  Presidential Elections using Twitter\n",
      "Be In The Know: Connecting News Articles to Relevant Twitter\n",
      "  Conversations\n",
      "Broker Bots: Analyzing automated activity during High Impact Events on\n",
      "  Twitter\n",
      "Analysing How People Orient to and Spread Rumours in Social Media by\n",
      "  Looking at Conversational Threads\n",
      "Why is it Difficult to Detect Sudden and Unexpected Epidemic Outbreaks\n",
      "  in Twitter?\n",
      "Exploring Students Blended Learning Through Social Media\n",
      "Online learning for Social Spammer Detection on Twitter\n",
      "ENWalk: Learning Network Features for Spam Detection in Twitter\n",
      "Reinforcement Learning with External Knowledge and Two-Stage Q-functions\n",
      "  for Predicting Popular Reddit Threads\n",
      "Learning multi-faceted representations of individuals from heterogeneous\n",
      "  evidence using neural networks\n",
      "Applications of Online Deep Learning for Crisis Response Using Social\n",
      "  Media Information\n",
      "LA-LDA: A Limited Attention Topic Model for Social Recommendation\n",
      "What the Language You Tweet Says About Your Occupation\n",
      "Generating ordered list of Recommended Items: a Hybrid Recommender\n",
      "  System of Microblog\n",
      "Twitter Hash Tag Recommendation\n",
      "Learning from the News: Predicting Entity Popularity on Twitter\n",
      "User Effort and Network Structure Mediate Access to Information in\n",
      "  Networks\n",
      "Learning Reporting Dynamics during Breaking News for Rumour Detection in\n",
      "  Social Media\n",
      "Interpretation of Semantic Tweet Representations\n",
      "Item Silk Road: Recommending Items from Information Domains to Social\n",
      "  Users\n",
      "Explore what-if scenarios with SONG: Social Network Write Generator\n",
      "A Link-based Approach to Entity Resolution in Social Networks\n",
      "Clustering memes in social media streams\n",
      "Dynamic Multi-Relational Chinese Restaurant Process for Analyzing\n",
      "  Influences on Users in Social Media\n",
      "Towards Bottom-Up Analysis of Social Food\n",
      "Temporal Effects on Hashtag Reuse in Twitter: A Cognitive-Inspired\n",
      "  Hashtag Recommendation Approach\n",
      "Automated Hate Speech Detection and the Problem of Offensive Language\n",
      "Social Bots: Human-Like by Means of Human Control?\n",
      "Inferring the Origin Locations of Tweets with Quantitative Confidence\n",
      "User-level Weibo Recommendation incorporating Social Influence based on\n",
      "  Semi-Supervised Algorithm\n",
      "Quantifying the Effect of Sentiment on Information Diffusion in Social\n",
      "  Media\n",
      "A Continuous-time Mutually-Exciting Point Process Framework for\n",
      "  Prioritizing Events in Social Media\n",
      "Privacy Leakage through Innocent Content Sharing in Online Social\n",
      "  Networks\n",
      "How I Stopped Worrying about the Twitter Archive at the Library of\n",
      "  Congress and Learned to Build a Little One for Myself\n",
      "Efficient Detection of Points of Interest from Georeferenced Visual\n",
      "  Content\n",
      "ET-LDA: Joint Topic Modeling For Aligning, Analyzing and Sensemaking of\n",
      "  Public Events and Their Twitter Feeds\n",
      "'Dark Germany': Hidden Patterns of Participation in Online Far-Right\n",
      "  Protests Against Refugee Housing\n",
      "--------\n",
      "Results for: Segmental Convolutional Neural Networks for Detection of Cardiac\n",
      "  Abnormality With Noisy Heart Sound Recordings\n",
      "--------\n",
      "Segmental Convolutional Neural Networks for Detection of Cardiac\n",
      "  Abnormality With Noisy Heart Sound Recordings\n",
      "Automatic large-scale classification of bird sounds is strongly improved\n",
      "  by unsupervised feature learning\n",
      "Online algorithms for Nonnegative Matrix Factorization with the\n",
      "  Itakura-Saito divergence\n",
      "Nonnegative Tensor Factorization for Directional Blind Audio Source\n",
      "  Separation\n",
      "Convolutional Recurrent Neural Networks for Bird Audio Detection\n",
      "Bioacoustic Signal Classification Based on Continuous Region Processing,\n",
      "  Grid Masking and Artificial Neural Network\n",
      "Comparative study on supervised learning methods for identifying\n",
      "  phytoplankton species\n",
      "A Comparison of deep learning methods for environmental sound\n",
      "Detecting bird sound in unknown acoustic background using crowdsourced\n",
      "  training data\n",
      "Phase 3: DCL System Using Deep Learning Approaches for Land-based or\n",
      "  Ship-based Real-Time Recognition and Localization of Marine Mammals -\n",
      "  Bioacoustic Applicaitons\n",
      "An Approach for Self-Training Audio Event Detectors Using Web Data\n",
      "Bi-class classification of humpback whale sound units against complex\n",
      "  background noise with Deep Convolution Neural Network\n",
      "Deep Multi-Species Embedding\n",
      "North Atlantic Right Whale Contact Call Detection\n",
      "The bag-of-frames approach: a not so sufficient model for urban\n",
      "  soundscapes\n",
      "An evaluation framework for event detection using a morphological model\n",
      "  of acoustic scenes\n",
      "Co-Localization of Audio Sources in Images Using Binaural Features and\n",
      "  Locally-Linear Regression\n",
      "Kernel convolution model for decoding sounds from time-varying neural\n",
      "  responses\n",
      "Efficient coding of spectrotemporal binaural sounds leads to emergence\n",
      "  of the auditory space representation\n",
      "Hearing in a shoe-box : binaural source position and wall absorption\n",
      "  estimation using virtually supervised learning\n",
      "VAST : The Virtual Acoustic Space Traveler Dataset\n",
      "Unsupervised Feature Learning Based on Deep Models for Environmental\n",
      "  Audio Tagging\n",
      "An Active Machine Hearing System for Auditory Stream Segregation\n",
      "Convolutional Gated Recurrent Neural Network Incorporating Spatial\n",
      "  Features for Audio Tagging\n",
      "Environmental Sounds Spectrogram Classification using Log-Gabor Filters\n",
      "  and Multiclass Support Vector Machines\n",
      "Detecting Road Surface Wetness from Audio: A Deep Learning Approach\n",
      "Individual identity in songbirds: signal representations and metric\n",
      "  learning for locating the information in complex corvid calls\n",
      "Deep learning for detection of bird vocalisations\n",
      "Automatic Organisation, Segmentation, and Filtering of User-Generated\n",
      "  Audio Content\n",
      "Stacked Convolutional and Recurrent Neural Networks for Bird Audio\n",
      "  Detection\n",
      "Detection of north atlantic right whale upcalls using local binary\n",
      "  patterns in a two-stage strategy\n",
      "FPGA Implementation of the CAR Model of the Cochlea\n",
      "Natural statistics of binaural sounds\n",
      "Perceptual analyses of action-related impact sounds\n",
      "Histogram of gradients of Time-Frequency Representations for Audio scene\n",
      "  detection\n",
      "Visually Indicated Sounds\n",
      "Phase 1: DCL System Research Using Advanced Approaches for Land-based or\n",
      "  Ship-based Real-Time Recognition and Localization of Marine Mammals - HPC\n",
      "  System Implementation\n",
      "Discovering Sound Concepts and Acoustic Relations In Text\n",
      "Sound Event Detection in Multichannel Audio Using Spatial and Harmonic\n",
      "  Features\n",
      "Fully DNN-based Multi-label regression for audio tagging\n",
      "Empirical Study of Drone Sound Detection in Real-Life Environment with\n",
      "  Deep Neural Networks\n",
      "--------\n",
      "Results for: Protein-Ligand Scoring with Convolutional Neural Networks\n",
      "--------\n",
      "By-passing the Kohn-Sham equations with machine learning\n",
      "Graph Convolutional Networks for Molecules\n",
      "Low Data Drug Discovery with One-shot Learning\n",
      "Ultra-Fast Reactive Transport Simulations When Chemical Reactions Meet\n",
      "  Machine Learning: Chemical Equilibrium\n",
      "ROCS-Derived Features for Virtual Screening\n",
      "Protein-Ligand Scoring with Convolutional Neural Networks\n",
      "Toxicity Prediction using Deep Learning\n",
      "Link Mining for Kernel-based Compound-Protein Interaction Predictions\n",
      "  Using a Chemogenomics Approach\n",
      "Chemception: A Deep Neural Network with Minimal Chemistry Knowledge\n",
      "  Matches the Performance of Expert-developed QSAR/QSPR Models\n",
      "ANI-1: A data set of 20M off-equilibrium DFT calculations for organic\n",
      "  molecules\n",
      "Drug response prediction by inferring pathway-response associations with\n",
      "  Kernelized Bayesian Matrix Factorization\n",
      "Machine learning prediction of cancer cell sensitivity to drugs based on\n",
      "  genomic and chemical properties\n",
      "Bayesian Inference for NMR Spectroscopy with Applications to Chemical\n",
      "  Quantification\n",
      "Highly Scalable Tensor Factorization for Prediction of Drug-Protein\n",
      "  Interaction Type\n",
      "Direct Mapping Hidden Excited State Interaction Patterns from ab initio\n",
      "  Dynamics and Its Implications on Force Field Development\n",
      "Parallel and Distributed Thompson Sampling for Large-scale Accelerated\n",
      "  Exploration of Chemical Space\n",
      "Detect adverse drug reactions for drug Atorvastatin\n",
      "Pre-processing in AI based Prediction of QSARs\n",
      "Ensembling classification models based on phalanxes of variables with\n",
      "  applications in drug discovery\n",
      "Identification of structural features in chemicals associated with\n",
      "  cancer drug response: A systematic data-driven analysis\n",
      "Variational Koopman models: slow collective variables and molecular\n",
      "  kinetics from short off-equilibrium simulations\n",
      "Learning Two-input Linear and Nonlinear Analog Functions with a Simple\n",
      "  Chemical System\n",
      "Steps and bumps: precision extraction of discrete states of molecular\n",
      "  machines using physically-based, high-throughput time series analysis\n",
      "Representation learning of drug and disease terms for drug repositioning\n",
      "Chemlambda, universality and self-multiplication\n",
      "A Novel Semi-Supervised Algorithm for Rare Prescription Side Effect\n",
      "  Discovery\n",
      "A Sparse SCF algorithm and its parallel implementation: Application to\n",
      "  DFTB\n",
      "Handling non-compositionality in multilingual CNLs\n",
      "Distributed Control of Microscopic Robots in Biomedical Applications\n",
      "Active Self-Assembly of Algorithmic Shapes and Patterns in\n",
      "  Polylogarithmic Time\n",
      "Reconstruction of Arbitrary Biochemical Reaction Networks: A Compressive\n",
      "  Sensing Approach\n",
      "Parameter optimization in differential geometry based solvation models\n",
      "Feature selection in detection of adverse drug reactions from the Health\n",
      "  Improvement Network (THIN) database\n",
      "Automatic Inference of Graph Transformation Rules Using the Cyclic\n",
      "  Nature of Chemical Reactions\n",
      "Signalling Paediatric Side Effects using an Ensemble of Simple Study\n",
      "  Designs\n",
      "Heter-LP: A heterogeneous label propagation algorithm and its\n",
      "  application in drug repositioning\n",
      "--------\n",
      "Results for: Predicting Alzheimer's disease: a neuroimaging study with 3D\n",
      "  convolutional neural networks\n",
      "--------\n",
      "Learning to learn by gradient descent by gradient descent\n",
      "Unsupervised Learning by Predicting Noise\n",
      "Stable Architectures for Deep Neural Networks\n",
      "Meta-Learning with Temporal Convolutions\n",
      "Predicting Alzheimer's disease: a neuroimaging study with 3D\n",
      "  convolutional neural networks\n",
      "Deep Learning in the Automotive Industry: Applications and Tools\n",
      "Exact solutions to the nonlinear dynamics of learning in deep linear\n",
      "  neural networks\n",
      "Search Intelligence: Deep Learning For Dominant Category Prediction\n",
      "Evolutionary Synthesis of Deep Neural Networks via Synaptic\n",
      "  Cluster-driven Genetic Encoding\n",
      "On the Expressive Power of Deep Learning: A Tensor Analysis\n",
      "Scalable and Sustainable Deep Learning via Randomized Hashing\n",
      "Controlling Exploration Improves Training for Deep Neural Networks\n",
      "Adding Gradient Noise Improves Learning for Very Deep Networks\n",
      "Real-time optimal control via Deep Neural Networks: study on landing\n",
      "  problems\n",
      "Generative Mixture of Networks\n",
      "On Loss Functions for Deep Neural Networks in Classification\n",
      "Geometric deep learning: going beyond Euclidean data\n",
      "Collaborative creativity with Monte-Carlo Tree Search and Convolutional\n",
      "  Neural Networks\n",
      "Recklessly Approximate Sparse Coding\n",
      "Degrees of Freedom in Deep Neural Networks\n",
      "Scalable Adaptive Stochastic Optimization Using Random Projections\n",
      "Deep Unfolding: Model-Based Inspiration of Novel Deep Architectures\n",
      "Fast, simple and accurate handwritten digit classification by training\n",
      "  shallow neural network classifiers with the 'extreme learning machine'\n",
      "  algorithm\n",
      "Learned D-AMP: Principled Neural-Network-based Compressive Image\n",
      "  Recovery\n",
      "High-Resolution Breast Cancer Screening with Multi-View Deep\n",
      "  Convolutional Neural Networks\n",
      "Astronomical image reconstruction with convolutional neural networks\n",
      "Evolution in Groups: A deeper look at synaptic cluster driven evolution\n",
      "  of deep neural networks\n",
      "Convergent Learning: Do different neural networks learn the same\n",
      "  representations?\n",
      "Deep Learning with Eigenvalue Decay Regularizer\n",
      "Sequence-to-point learning with neural networks for nonintrusive load\n",
      "  monitoring\n",
      "Direct Load Control of Thermostatically Controlled Loads Based on Sparse\n",
      "  Observations Using Deep Reinforcement Learning\n",
      "Deep Transfer Learning: A new deep learning glitch classification method\n",
      "  for advanced LIGO\n",
      "Graph Neural Networks and Boolean Satisfiability\n",
      "Enhanced Higgs to $^+^-$ Searches with Deep Learning\n",
      "Deep Convolutional Networks on Graph-Structured Data\n",
      "Boosting the accuracy of multi-spectral image pan-sharpening by learning\n",
      "  a deep residual network\n",
      "High-Performance Neural Networks for Visual Object Classification\n",
      "Joint Deep Learning for Car Detection\n",
      "On non-iterative training of a neural classifier\n",
      "Enabling Efficient Question Answer Retrieval via Hyperbolic Neural\n",
      "  Networks\n",
      "DeepIoT: Compressing Deep Neural Network Structures for Sensing Systems\n",
      "  with a Compressor-Critic Framework\n",
      "Deep video gesture recognition using illumination invariants\n",
      "Context Aware Document Embedding\n",
      "Enlightening Deep Neural Networks with Knowledge of Confounding Factors\n",
      "Intelligent Systems: Architectures and Perspectives\n",
      "Deep Clustered Convolutional Kernels\n",
      "Training Deep Neural Networks via Direct Loss Minimization\n",
      "A Reconfigurable Low Power High Throughput Architecture for Deep Network\n",
      "  Training\n",
      "Overcoming Challenges in Fixed Point Training of Deep Convolutional\n",
      "  Networks\n",
      "Deep counter networks for asynchronous event-based processing\n",
      "Quantized neural network design under weight capacity constraint\n",
      "A Powerful Generative Model Using Random Weights for the Deep Image\n",
      "  Representation\n",
      "--------\n",
      "Results for: Learning Convolutional Neural Networks for Graphs\n",
      "--------\n",
      "Can GAN Learn Topological Features of a Graph?\n",
      "Learning Convolutional Neural Networks for Graphs\n",
      "Learning Graphs with Monotone Topology Properties and Multiple Connected\n",
      "  Components\n",
      "Subgraph Matching Kernels for Attributed Graphs\n",
      "Graph Kernels via Functional Embedding\n",
      "Transductive Classification Methods for Mixed Graphs\n",
      "Learning Nonparametric Forest Graphical Models with Prior Information\n",
      "Semi-Supervised Classification with Graph Convolutional Networks\n",
      "Deep Learning with Dynamic Computation Graphs\n",
      "Graph Convolutional Matrix Completion\n",
      "Graph Classification via Deep Learning with Virtual Nodes\n",
      "Joint Embedding of Graphs\n",
      "Moment based estimation of stochastic Kronecker graph parameters\n",
      "Optimizing an Organized Modularity Measure for Topographic Graph\n",
      "  Clustering: a Deterministic Annealing Approach\n",
      "PageRank in undirected random graphs\n",
      "PageRank in Undirected Random Graphs\n",
      "Graph Kernels\n",
      "Propagation Kernels\n",
      "Global Weisfeiler-Lehman Graph Kernels\n",
      "Discriminative Feature Selection for Uncertain Graph Classification\n",
      "Finding Dense Clusters via \"Low Rank + Sparse\" Decomposition\n",
      "Nonparametric Link Prediction in Large Scale Dynamic Networks\n",
      "Graph Cuts with Interacting Edge Costs - Examples, Approximations, and\n",
      "  Algorithms\n",
      "Community Detection in Random Networks\n",
      "Many-to-Many Graph Matching: a Continuous Relaxation Approach\n",
      "Metric recovery from directed unweighted graphs\n",
      "The Multiscale Laplacian Graph Kernel\n",
      "Edge-exchangeable graphs and sparsity\n",
      "Information Recovery in Shuffled Graphs via Graph Matching\n",
      "Scalable motif-aware graph clustering\n",
      "On the Consistency of the Likelihood Maximization Vertex Nomination\n",
      "  Scheme: Bridging the Gap Between Maximum Likelihood Estimation and Graph\n",
      "  Matching\n",
      "Graphons, mergeons, and so on!\n",
      "Peacock Bundles: Bundle Coloring for Graphs with Globality-Locality\n",
      "  Trade-off\n",
      "Edge-exchangeable graphs and sparsity (NIPS 2016)\n",
      "Vertex Nomination Via Local Neighborhood Matching\n",
      "Seeded graph matching for correlated Erds-Rnyi graphs\n",
      "Vertex nomination schemes for membership prediction\n",
      "HARP: Hierarchical Representation Learning for Networks\n",
      "The Infinity Mirror Test for Analyzing the Robustness of Graph\n",
      "  Generators\n",
      "A Continuous Refinement Strategy for the Multilevel Computation of\n",
      "  Vertex Separators\n",
      "Improved Quantum Algorithm for Triangle Finding via Combinatorial\n",
      "  Arguments\n",
      "Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on\n",
      "  Graphs\n",
      "Graph Field Automata\n",
      "Subgraph Similarity Search in Large Graphs\n",
      "Non-Confluent NLC Graph Grammar Inference by Compressing Disjoint\n",
      "  Subgraphs\n",
      "The Link Prediction Problem in Bipartite Networks\n",
      "Extending local features with contextual information in graph kernels\n",
      "Ricci-Ollivier Curvature of the Rooted Phylogenetic\n",
      "  Subtree-Prune-Regraft Graph\n",
      "--------\n",
      "Results for: Automatic Sleep Stage Scoring with Single-Channel EEG Using\n",
      "  Convolutional Neural Networks\n",
      "--------\n",
      "Deep Multiple Kernel Learning\n",
      "Fast Cross-Validation for Incremental Learning\n",
      "Approximate cross-validation formula for Bayesian linear regression\n",
      "Automatic Sleep Stage Scoring with Single-Channel EEG Using\n",
      "  Convolutional Neural Networks\n",
      "Cross-Validation with Confidence\n",
      "Influence of Resampling on Accuracy of Imbalanced Classification\n",
      "Sleep Analytics and Online Selective Anomaly Detection\n",
      "Catching Up Faster by Switching Sooner: A Prequential Solution to the\n",
      "  AIC-BIC Dilemma\n",
      "Cross-Validation for Unsupervised Learning\n",
      "Sleep Apnea Detection Based on Thoracic and Abdominal Movement Signals\n",
      "  of Wearable Piezo-Electric Bands\n",
      "SLEEPNET: Automated Sleep Staging System via Deep Learning\n",
      "SensibleSleep: A Bayesian Model for Learning Sleep Patterns from\n",
      "  Smartphone Events\n",
      "Combining Generative and Discriminative Neural Networks for Sleep Stages\n",
      "  Classification\n",
      "--------\n",
      "Results for: Classification of Alzheimer's Disease using fMRI Data and Deep Learning\n",
      "  Convolutional Neural Networks\n",
      "--------\n",
      "Deep learning trends for focal brain pathology segmentation in MRI\n",
      "Classification of Alzheimer's Disease using fMRI Data and Deep Learning\n",
      "  Convolutional Neural Networks\n",
      "Predicting brain age with deep learning from raw imaging data results in\n",
      "  a reliable and heritable biomarker\n",
      "Mitochondria-based Renal Cell Carcinoma Subtyping: Learning from Deep\n",
      "  vs. Flat Feature Representations\n",
      "Predicting Cognitive Decline with Deep Learning of Brain Metabolism and\n",
      "  Amyloid Imaging\n",
      "Semantic Segmentation of Colon Glands with Deep Convolutional Neural\n",
      "  Networks and Total Variation Segmentation\n",
      "Deep Convolutional Neural Networks for Microscopy-Based Point of Care\n",
      "  Diagnostics\n",
      "Multi-source Transfer Learning with Convolutional Neural Networks for\n",
      "  Lung Pattern Analysis\n",
      "Comparison of machine learning methods for classifying mediastinal lymph\n",
      "  node metastasis of non-small cell lung cancer from 18F-FDG PET/CT images\n",
      "Predicting 1p19q Chromosomal Deletion of Low-Grade Gliomas from MR\n",
      "  Images using Deep Learning\n",
      "A Multi-Scale CNN and Curriculum Learning Strategy for Mammogram\n",
      "  Classification\n",
      "Representation-Aggregation Networks for Segmentation of Multi-Gigapixel\n",
      "  Histology Images\n",
      "Transitioning between Convolutional and Fully Connected Layers in Neural\n",
      "  Networks\n",
      "Patch-based Carcinoma Detection on Confocal Laser Endomicroscopy Images\n",
      "  - A Cross-Site Robustness Assessment\n",
      "Automatic labeling of molecular biomarkers of whole slide\n",
      "  immunohistochemistry images using fully convolutional networks\n",
      "Automating Carotid Intima-Media Thickness Video Interpretation with\n",
      "  Convolutional Neural Networks\n",
      "Comparison of Different Methods for Tissue Segmentation in\n",
      "  Histopathological Whole-Slide Images\n",
      "Context-aware stacked convolutional neural networks for classification\n",
      "  of breast carcinomas in whole-slide histopathology images\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "display_for_cluster('Convolutional Neural Networks', assignments_dict, reverse_assignments_dict, data_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe and Efficient Screening For Sparse Support Vector Machine\n",
      "Taking Advantage of Sparsity in Multi-Task Learning\n",
      "Safe Screening With Variational Inequalities and Its Application to\n",
      "  LASSO\n",
      "An Efficient Approach to Sparse Linear Discriminant Analysis\n",
      "A Component Lasso\n",
      "Nonparametric Independence Screening in Sparse Ultra-High Dimensional\n",
      "  Additive Models\n",
      "Efficient Feature Screening for Lasso-Type Problems via Hybrid\n",
      "  Safe-Strong Rules\n",
      "Localized Lasso for High-Dimensional Regression\n",
      "Multi-stage Convex Relaxation for Feature Selection\n",
      "Quantile universal threshold: model selection at the detection edge for\n",
      "  high-dimensional linear regression\n",
      "Exploring Sparsity in Multi-class Linear Discriminant Analysis\n",
      "Elastic Net Procedure for Partially Linear Models\n",
      "Structured variable selection in support vector machines\n",
      "Compound Poisson Processes, Latent Shrinkage Priors and Bayesian\n",
      "  Nonconvex Penalization\n",
      "Selective Factor Extraction in High Dimensions\n",
      "Lasso and equivalent quadratic penalized models\n",
      "Sparse Partially Linear Additive Models\n",
      "Slection de variables par le GLM-Lasso pour la prdiction du risque\n",
      "  palustre\n",
      "Simultaneous Safe Screening of Features and Samples in Doubly Sparse\n",
      "  Modeling\n",
      "GAP Safe Screening Rules for Sparse-Group-Lasso\n",
      "Efficient Clustering of Correlated Variables and Variable Selection in\n",
      "  High-Dimensional Linear Models\n",
      "Sure independence screening in generalized linear models with\n",
      "  NP-dimensionality\n",
      "Sparse Matrix Inversion with Scaled Lasso\n",
      "Dynamic Screening: Accelerating First-Order Algorithms for the Lasso and\n",
      "  Group-Lasso\n",
      "Efficient Smoothed Concomitant Lasso Estimation for High Dimensional\n",
      "  Regression\n",
      "Variable Selection in High Dimensions with Random Designs and Orthogonal\n",
      "  Matching Pursuit\n",
      "The Lasso under Heteroscedasticity\n",
      "Adaptive Penalized Estimation of Directed Acyclic Graphs From\n",
      "  Categorical Data\n",
      "Ultrahigh dimensional variable selection: beyond the linear model\n",
      "Regularized Partial Least Squares with an Application to NMR\n",
      "  Spectroscopy\n",
      "Regression shrinkage and grouping of highly correlated predictors with\n",
      "  HORSES\n",
      "On pattern recovery of the fused Lasso\n",
      "Combined l_1 and greedy l_0 penalized least squares for linear model\n",
      "  selection\n",
      "L0 Sparse Inverse Covariance Estimation\n",
      "High-dimensional Ordinary Least-squares Projection for Screening\n",
      "  Variables\n",
      "Streaming regularization parameter selection via stochastic gradient\n",
      "  descent\n",
      "Estimating Structured Vector Autoregressive Model\n",
      "Interaction pursuit in high-dimensional multi-response regression via\n",
      "  distance correlation\n",
      "Algorithms for Fitting the Constrained Lasso\n",
      "Nonparametric Regression with Adaptive Truncation via a Convex\n",
      "  Hierarchical Penalty\n",
      "High-dimensional classification by sparse logistic regression\n",
      "Modelling Interactions in High-dimensional Data with Backtracking\n",
      "Risk-consistency of cross-validation with lasso-type procedures\n",
      "On the Sensitivity of the Lasso to the Number of Predictor Variables\n",
      "Inference in High Dimensions with the Penalized Score Test\n",
      "Strong oracle optimality of folded concave penalized estimation\n",
      "High dimensional thresholded regression and shrinkage effect\n",
      "Heteroscedastic Concomitant Lasso for sparse multimodal electromagnetic\n",
      "  brain imaging\n",
      "The Trimmed Lasso: Sparsity and Robustness\n",
      "The sparsity and bias of the Lasso selection in high-dimensional linear\n",
      "  regression\n",
      "Combinatorial Selection and Least Absolute Shrinkage via the CLASH\n",
      "  Algorithm\n",
      "Split Bregman method for large scale fused Lasso\n",
      "Feature Screening via Distance Correlation Learning\n"
     ]
    }
   ],
   "source": [
    "for idx, k in enumerate(assignments):\n",
    "    if k == 890:\n",
    "        print(data_original.iloc[idx, :]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM/EM \n",
    "##### N_components = 300: Doesn't work - posteriors are all 1. Eventually converged to K-Means equivalent solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "e_m = GaussianMixture(n_components = 300, max_iter = 130, verbose = 2)\n",
    "e_m.fit(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posterior = e_m.predict_proba(data_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build paper graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build author graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bokeh as bk\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from bokeh.models import ColumnDataSource\n",
    "import bokeh.plotting \n",
    "from bokeh.models.graphs import from_networkx, NodesAndLinkedEdges, EdgesAndLinkedNodes, StaticLayoutProvider\n",
    "from bokeh.palettes import Spectral4, Spectral8, Paired8\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_cleaned = pickle.load(file = open('./pickles/paper_auth_name.pickle', 'rb'))\n",
    "users_id_map = pickle.load(file = open('./pickles/user_id_maps.pickle', 'rb'))\n",
    "user_map = pickle.load(file = open('./pickles/user_mappings.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def author_graph(author, user_papers_map, papers_user_map, user_id_map, limit = 1000, depth = 5, cap_per_paper = 3):\n",
    "    auths = {}\n",
    "    if author.lower() in user_id_map[0]:\n",
    "        to_do_q = []\n",
    "        author_papers = user_papers_map[author.lower()]\n",
    "        to_do_q.extend(zip(author_papers, [user_id_map[0][author.lower()]] * len(author_papers)))\n",
    "        to_do_q.append('--')\n",
    "        cur_depth = 0\n",
    "        auths[user_id_map[0][author.lower()]] = (-1, user_id_map[0][author.lower()], cur_depth)\n",
    "        done = set()\n",
    "        while ((len(auths.keys()) < limit or len(to_do_q) == 0) and cur_depth <= depth):\n",
    "            pop_paper = to_do_q[0]\n",
    "            del[to_do_q[0]]\n",
    "            if pop_paper in done: continue\n",
    "            if pop_paper == '--':\n",
    "                pop_paper = to_do_q[0]\n",
    "                del[to_do_q[0]]\n",
    "                to_do_q.append('--')\n",
    "                cur_depth += 1\n",
    "                print('Current depth:', cur_depth)\n",
    "            else:\n",
    "                done.add(pop_paper)\n",
    "            colleagues = papers_user_map[pop_paper[0]]\n",
    "            if len(colleagues) > cap_per_paper: colleagues = colleagues[:cap_per_paper]\n",
    "            for colleague in colleagues:\n",
    "                if not user_id_map[0][colleague.lower()] in auths:\n",
    "                    auths[user_id_map[0][colleague.lower()]] =  (pop_paper[0], pop_paper[1], cur_depth + 1)\n",
    "                colleague_papers = user_papers_map[colleague.lower()]\n",
    "                to_do_q.extend(zip(colleague_papers, [user_id_map[0][colleague.lower()]] * len(colleague_papers)))\n",
    "        if cur_depth > depth: print('Max depth reached')\n",
    "        if len(auths.keys()) >= limit: print('Max limit reached')\n",
    "        return auths\n",
    "    else:\n",
    "        print('Author', author, 'not found')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current depth: 1\n",
      "Max limit reached\n"
     ]
    }
   ],
   "source": [
    "auths = author_graph('David Sontag', user_map, users_cleaned, user_id_map, 100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Render Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"069ba258-5e1a-4b7d-b352-ea082375165e\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"069ba258-5e1a-4b7d-b352-ea082375165e\");\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"069ba258-5e1a-4b7d-b352-ea082375165e\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '069ba258-5e1a-4b7d-b352-ea082375165e' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.7.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"069ba258-5e1a-4b7d-b352-ea082375165e\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"069ba258-5e1a-4b7d-b352-ea082375165e\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bokeh.plotting.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.models.tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keys = list(auths.keys())\n",
    "colours = [0]*len(keys)\n",
    "names = [user_id_map[1][idx].title() for idx in keys]\n",
    "papers = [0]*len(keys)\n",
    "search = \"\"\n",
    "G = networkx.DiGraph()\n",
    "G.add_nodes_from(keys)\n",
    "root_node = 0\n",
    "for idx, key in enumerate(keys):\n",
    "    tag = auths[key]\n",
    "    if not tag[0] == -1:\n",
    "        G.add_edge(tag[1], key)\n",
    "        papers[idx] = data_original.iloc[tag[0], :]['title']\n",
    "    else:\n",
    "        root_node = key\n",
    "        papers[idx] = 'Input search query'\n",
    "        search = names[idx]\n",
    "    colours[idx] = Paired8[tag[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name: fill_color [renderer: GlyphRenderer(id='e082f21b-2906-4253-afd9-3f5fbd8f9f0c', ...)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <div class=\"bk-plotdiv\" id=\"cee3d2ac-7743-4729-9e9f-316e4825005f\"></div>\n",
       "    </div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(root) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    var force = false;\n",
       "  \n",
       "    if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "      root._bokeh_onload_callbacks = [];\n",
       "      root._bokeh_is_loading = undefined;\n",
       "    }\n",
       "  \n",
       "  \n",
       "    \n",
       "    if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "      root._bokeh_timeout = Date.now() + 0;\n",
       "      root._bokeh_failed_load = false;\n",
       "    }\n",
       "  \n",
       "    var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "       \"<div style='background-color: #fdd'>\\n\"+\n",
       "       \"<p>\\n\"+\n",
       "       \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "       \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "       \"</p>\\n\"+\n",
       "       \"<ul>\\n\"+\n",
       "       \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "       \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "       \"</ul>\\n\"+\n",
       "       \"<code>\\n\"+\n",
       "       \"from bokeh.resources import INLINE\\n\"+\n",
       "       \"output_notebook(resources=INLINE)\\n\"+\n",
       "       \"</code>\\n\"+\n",
       "       \"</div>\"}};\n",
       "  \n",
       "    function display_loaded() {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        var el = document.getElementById(\"cee3d2ac-7743-4729-9e9f-316e4825005f\");\n",
       "        if (el != null) {\n",
       "          el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "        }\n",
       "      } else if (Date.now() < root._bokeh_timeout) {\n",
       "        setTimeout(display_loaded, 100)\n",
       "      }\n",
       "    }\n",
       "  \n",
       "  \n",
       "    function run_callbacks() {\n",
       "      try {\n",
       "        root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      }\n",
       "      finally {\n",
       "        delete root._bokeh_onload_callbacks\n",
       "      }\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      root._bokeh_onload_callbacks.push(callback);\n",
       "      if (root._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      root._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          root._bokeh_is_loading--;\n",
       "          if (root._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"cee3d2ac-7743-4729-9e9f-316e4825005f\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'cee3d2ac-7743-4729-9e9f-316e4825005f' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        (function() {\n",
       "          var fn = function() {\n",
       "            var docs_json = {\"47c6125d-7131-4053-a4f4-3d7d6216fb4a\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"25695367-f64a-4608-a7c7-234c6b6e535b\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null,\"end\":337.37,\"start\":11.544},\"id\":\"466fe1e4-249a-495d-8bad-bf2ad423e850\",\"type\":\"Range1d\"},{\"attributes\":{\"callback\":null},\"id\":\"c3606026-ef7b-4f09-8dee-516ea86eac3e\",\"type\":\"TapTool\"},{\"attributes\":{},\"id\":\"51755805-6c92-4fa3-ad32-35c4fc8f644c\",\"type\":\"LinearScale\"},{\"attributes\":{\"plot\":null,\"text\":\"Network Graph for David Sontag\"},\"id\":\"aa7b43b7-0bb5-41cf-8fd6-b23e14d843ac\",\"type\":\"Title\"},{\"attributes\":{\"below\":[{\"id\":\"f4ef85c7-7592-4e23-8a42-c8d473392cbb\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"48de0be8-d456-4755-af59-1ce6d4354b20\",\"type\":\"LinearAxis\"}],\"plot_height\":1000,\"plot_width\":1000,\"renderers\":[{\"id\":\"f4ef85c7-7592-4e23-8a42-c8d473392cbb\",\"type\":\"LinearAxis\"},{\"id\":\"656fdd42-bac7-485f-a24f-f82d794a44ce\",\"type\":\"Grid\"},{\"id\":\"48de0be8-d456-4755-af59-1ce6d4354b20\",\"type\":\"LinearAxis\"},{\"id\":\"b6b4e4c0-13fa-4981-a054-7e1703792ebd\",\"type\":\"Grid\"},{\"id\":\"2354db6c-9ad5-49f2-8e33-a14cce8520e6\",\"type\":\"GraphRenderer\"}],\"title\":{\"id\":\"aa7b43b7-0bb5-41cf-8fd6-b23e14d843ac\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"0726de25-debb-424f-abff-c07c5ede92cb\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"466fe1e4-249a-495d-8bad-bf2ad423e850\",\"type\":\"Range1d\"},\"x_scale\":{\"id\":\"51755805-6c92-4fa3-ad32-35c4fc8f644c\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"154f15b1-3b79-40e0-bf66-ea1a250dfbd3\",\"type\":\"Range1d\"},\"y_scale\":{\"id\":\"02417edc-092b-4651-8d66-1f81752b2f24\",\"type\":\"LinearScale\"}},\"id\":\"823695bc-c18a-4a59-bd66-27619ad03bbc\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_color\":{\"field\":\"fill_color\"},\"size\":{\"units\":\"screen\",\"value\":15}},\"id\":\"8307c243-b7ce-486c-abfb-ea5335e5ac96\",\"type\":\"Circle\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"4b733b23-32b5-4b11-bea9-62f01aee20b2\",\"type\":\"HoverTool\"},{\"id\":\"b99729fa-1071-4ada-af87-d9268f7a801d\",\"type\":\"PanTool\"},{\"id\":\"96bd2e61-7f1b-455b-ad0c-0f6d1b630de9\",\"type\":\"WheelZoomTool\"},{\"id\":\"c3606026-ef7b-4f09-8dee-516ea86eac3e\",\"type\":\"TapTool\"},{\"id\":\"25695367-f64a-4608-a7c7-234c6b6e535b\",\"type\":\"ResetTool\"}]},\"id\":\"0726de25-debb-424f-abff-c07c5ede92cb\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"02417edc-092b-4651-8d66-1f81752b2f24\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"end\":325.83,\"start\":-2.0},\"id\":\"154f15b1-3b79-40e0-bf66-ea1a250dfbd3\",\"type\":\"Range1d\"},{\"attributes\":{\"plot\":{\"id\":\"823695bc-c18a-4a59-bd66-27619ad03bbc\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"8af1306f-4334-4fb0-b4fb-17393959be46\",\"type\":\"BasicTicker\"},\"visible\":false},\"id\":\"656fdd42-bac7-485f-a24f-f82d794a44ce\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"cc5fb8f6-bcc4-43a6-b6d7-92d348da0390\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"823695bc-c18a-4a59-bd66-27619ad03bbc\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"8af1306f-4334-4fb0-b4fb-17393959be46\",\"type\":\"BasicTicker\"},\"visible\":false},\"id\":\"f4ef85c7-7592-4e23-8a42-c8d473392cbb\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"8af1306f-4334-4fb0-b4fb-17393959be46\",\"type\":\"BasicTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"26702a3b-0d9a-46d9-9f7b-d3027abdce6f\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"823695bc-c18a-4a59-bd66-27619ad03bbc\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"f6ab31d1-d3b9-4e9f-8520-99c3f9cb0544\",\"type\":\"BasicTicker\"},\"visible\":false},\"id\":\"48de0be8-d456-4755-af59-1ce6d4354b20\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"Author\",\"@author\"],[\"Source\",\"@source\"]]},\"id\":\"4b733b23-32b5-4b11-bea9-62f01aee20b2\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"f6ab31d1-d3b9-4e9f-8520-99c3f9cb0544\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"823695bc-c18a-4a59-bd66-27619ad03bbc\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"f6ab31d1-d3b9-4e9f-8520-99c3f9cb0544\",\"type\":\"BasicTicker\"},\"visible\":false},\"id\":\"b6b4e4c0-13fa-4981-a054-7e1703792ebd\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1c8e1a9c-f06f-4384-ab28-c6668b576491\",\"type\":\"ColumnDataSource\"}},\"id\":\"7bb78a4c-8cb0-4acf-8da4-c07bc1f3b4f6\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"b99729fa-1071-4ada-af87-d9268f7a801d\",\"type\":\"PanTool\"},{\"attributes\":{\"edge_renderer\":{\"id\":\"ec348c3c-5e10-45f4-89b0-9e771ea9a42a\",\"type\":\"GlyphRenderer\"},\"inspection_policy\":{\"id\":\"fbbb373e-3dd3-45d4-a1a9-ce818d8cac12\",\"type\":\"NodesOnly\"},\"layout_provider\":{\"id\":\"734979ff-ccba-4585-bb6e-4a33884e646d\",\"type\":\"StaticLayoutProvider\"},\"node_renderer\":{\"id\":\"e082f21b-2906-4253-afd9-3f5fbd8f9f0c\",\"type\":\"GlyphRenderer\"},\"selection_policy\":{\"id\":\"f6d5d3f8-3e16-47ac-aed0-79111dc22e46\",\"type\":\"NodesAndLinkedEdges\"}},\"id\":\"2354db6c-9ad5-49f2-8e33-a14cce8520e6\",\"type\":\"GraphRenderer\"},{\"attributes\":{\"data_source\":{\"id\":\"1c8e1a9c-f06f-4384-ab28-c6668b576491\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"37c43452-2069-4e54-9c6f-5ff0adeccdbe\",\"type\":\"MultiLine\"},\"hover_glyph\":null,\"muted_glyph\":null,\"selection_glyph\":{\"id\":\"1910b07b-7c4c-4dea-82ef-3b2b462f544f\",\"type\":\"MultiLine\"},\"view\":{\"id\":\"7bb78a4c-8cb0-4acf-8da4-c07bc1f3b4f6\",\"type\":\"CDSView\"}},\"id\":\"ec348c3c-5e10-45f4-89b0-9e771ea9a42a\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"index\"],\"data\":{\"author\":[\"David Sontag\",\"Yoni Halpern\",\"Steven Horng\",\"Fredrik D Johansson\",\"Uri Shalit\",\"Yonatan Halpern\",\"Narges Razavian\",\"Jake Marcus\",\"Eliot Brenner\",\"Shalmali Joshi\",\"Suriya Gunasekar\",\"Yacine Jernite\",\"Samuel R Bowman\",\"Ankit Vani\",\"Rahul G Krishnan\",\"Anna Choromanska\",\"Amir Globerson\",\"Tim Roughgarden\",\"Ofer Meshi\",\"Mehrdad Mahdavi\",\"Adrian Weller\",\"Zhengping Che\",\"Sanjay Purushotham\",\"Kyunghyun Cho\",\"Christos Louizos\",\"Joris Mooij\",\"Do Kook Choe\",\"Yitao Li\",\"Sanjeev Arora\",\"Rong Ge\",\"Simon Lacostejulien\",\"Hung Hai Bui\",\"Tuyen N Huynh\",\"Yoon Kim\",\"Emilio Jorge\",\"Mikael K\\u00e5geb\\u00e4ck\",\"Linus Hermansson\",\"Osamu Watanabe\",\"Gal Chechik\",\"Vincent Dorie\",\"Jennifer Hill\",\"Blake Woodworth\",\"Srinadh Bhojanapalli\",\"Pradeep Ravikumar\",\"Joydeep Ghosh\",\"Makoto Yamada\",\"Dawei Yin\",\"Oluwasanmi Koyejo\",\"Arindam Banerjee\",\"Joyce C Ho\",\"Mesrob I Ohannessian\",\"Edouard Grave\",\"Armand Joulin\",\"Gabor Angeli\",\"Christopher Potts\",\"Sebastian Brarda\",\"Philip Yeres\",\"Adina Williams\",\"Nikita Nangia\",\"Christopher D Manning\",\"Luke Vilnis\",\"Oriol Vinyals\",\"Angeliki Lazaridou\",\"Yichen Gong\",\"Mariusz Bojarski\",\"Krzysztof Choromanski\",\"Aleksandr Y Aravkin\",\"Tony Jebara\",\"Sixin Zhang\",\"Yann Lecun\",\"Pratik Chaudhari\",\"Stefano Soatto\",\"Apoorv Agarwal\",\"John Langford\",\"Mikael Henaff\",\"Michael Mathieu\",\"Koby Crammer\",\"Naftali Tishby\",\"Uri Heinemann\",\"Elad Eban\",\"Gal Elidan\",\"Alon Brutzkus\",\"Yoav Wald\",\"Tommi S Jaakkola\",\"Nir Rosenfeld\",\"Yuval Atzmon\",\"Jonathan Berant\",\"Vahid Kezami\",\"Aharon Birnbaum\",\"Shai Shalevshwartz\",\"Roi Livni\",\"Daniel Carmon\",\"Ido Ginodi\",\"Ariel Jaimovich\",\"Talya Meltzer\",\"Yair Weiss\",\"Rishi Gupta\",\"Okke Schrijvers\",\"Jamie Morgenstern\",\"Vasilis Syrgkanis\",\"Eva Tardos\"],\"fill_color\":[\"#a6cee3\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#1f78b4\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\",\"#b2df8a\"],\"index\":[2444,2442,2443,2459,2460,2856,4171,4172,4600,5509,4342,5981,5982,5987,6365,6368,5272,8567,9921,2833,110,2879,2880,1272,2754,2156,15164,15165,266,2703,3931,14944,14945,16581,27594,27595,44743,14771,4111,18864,18865,4343,4344,4389,2708,6124,9633,7078,3638,23361,4162,4586,532,9161,12904,16838,16839,21629,21630,1264,6209,1042,5236,41034,7558,3396,2767,1805,773,774,4530,4533,37453,27,12064,11449,5271,2637,6065,9922,3594,10285,10498,2408,27052,28984,8140,28985,30603,1187,9114,31659,32328,27515,18145,12079,26830,27326,6755,6005,25268],\"source\":[\"Input search query\",\"Anchored Discrete Factor Analysis\",\"Anchored Discrete Factor Analysis\",\"Learning Representations for Counterfactual Inference\",\"Learning Representations for Counterfactual Inference\",\"Unsupervised Learning of Noisy-Or Bayesian Networks\",\"Multi-task Prediction of Disease Onsets from Longitudinal Lab Tests\",\"Multi-task Prediction of Disease Onsets from Longitudinal Lab Tests\",\"SparsityBoost: A New Scoring Function for Learning Bayesian Network\\n  Structure\",\"Identifiable Phenotyping using Constrained Non-Negative Matrix\\n  Factorization\",\"Identifiable Phenotyping using Constrained Non-Negative Matrix\\n  Factorization\",\"Discourse-Based Objectives for Fast Unsupervised Sentence Representation\\n  Learning\",\"Discourse-Based Objectives for Fast Unsupervised Sentence Representation\\n  Learning\",\"Grounded Recurrent Neural Networks\",\"Structured Inference Networks for Nonlinear State Space Models\",\"Simultaneous Learning of Trees and Representations for Extreme\\n  Classification and Density Estimation\",\"Tight Error Bounds for Structured Prediction\",\"Tight Error Bounds for Structured Prediction\",\"Train and Test Tightness of LP Relaxations in Structured Prediction\",\"Train and Test Tightness of LP Relaxations in Structured Prediction\",\"Train and Test Tightness of LP Relaxations in Structured Prediction\",\"Recurrent Neural Networks for Multivariate Time Series with Missing\\n  Values\",\"Recurrent Neural Networks for Multivariate Time Series with Missing\\n  Values\",\"Recurrent Neural Networks for Multivariate Time Series with Missing\\n  Values\",\"Causal Effect Inference with Deep Latent-Variable Models\",\"Causal Effect Inference with Deep Latent-Variable Models\",\"Efficiently Searching for Frustrated Cycles in MAP Inference\",\"Efficiently Searching for Frustrated Cycles in MAP Inference\",\"A Practical Algorithm for Topic Modeling with Provable Guarantees\",\"A Practical Algorithm for Topic Modeling with Provable Guarantees\",\"Barrier Frank-Wolfe for Marginal Inference\",\"Lifted Tree-Reweighted Variational Inference\",\"Lifted Tree-Reweighted Variational Inference\",\"Character-Aware Neural Language Models\",\"Learning to Play Guess Who? and Inventing a Grounded Language as a\\n  Consequence\",\"Learning to Play Guess Who? and Inventing a Grounded Language as a\\n  Consequence\",\"Generalized Shortest Path Kernel on Graphs\",\"Generalized Shortest Path Kernel on Graphs\",\"Efficient coordinate-descent for orthogonal matrices through Givens\\n  rotations\",\"Automated versus do-it-yourself methods for causal inference: Lessons\\n  learned from a data analysis competition\",\"Automated versus do-it-yourself methods for causal inference: Lessons\\n  learned from a data analysis competition\",\"Implicit Regularization in Matrix Factorization\",\"Implicit Regularization in Matrix Factorization\",\"Exponential Family Matrix Completion under Structural Constraints\",\"Exponential Family Matrix Completion under Structural Constraints\",\"Consistent Collective Matrix Completion under Joint Low Rank Structure\",\"Consistent Collective Matrix Completion under Joint Low Rank Structure\",\"Preference Completion from Partial Rankings\",\"Unified View of Matrix Completion under General Structural Constraints\",\"Phenotyping using Structured Collective Matrix Factorization of\\n  Multi--source EHR Data\",\"Learning Non-Discriminatory Predictors\",\"Variable Computation in Recurrent Neural Networks\",\"Variable Computation in Recurrent Neural Networks\",\"A large annotated corpus for learning natural language inference\",\"A large annotated corpus for learning natural language inference\",\"Sequential Attention: A Context-Aware Alignment Function for Machine\\n  Reading\",\"Sequential Attention: A Context-Aware Alignment Function for Machine\\n  Reading\",\"A Broad-Coverage Challenge Corpus for Sentence Understanding through\\n  Inference\",\"A Broad-Coverage Challenge Corpus for Sentence Understanding through\\n  Inference\",\"Recursive Neural Networks Can Learn Logical Semantics\",\"Generating Sentences from a Continuous Space\",\"Generating Sentences from a Continuous Space\",\"The RepEval 2017 Shared Task: Multi-Genre Natural Language Inference\\n  with Sentence Representations\",\"Ruminating Reader: Reasoning with Gated Multi-Hop Attention\",\"Structured adaptive and random spinners for fast machine learning\\n  computations\",\"Structured adaptive and random spinners for fast machine learning\\n  computations\",\"Semistochastic Quadratic Bound Methods\",\"Semistochastic Quadratic Bound Methods\",\"Deep learning with Elastic Averaging SGD\",\"Deep learning with Elastic Averaging SGD\",\"Entropy-SGD: Biasing Gradient Descent Into Wide Valleys\",\"Entropy-SGD: Biasing Gradient Descent Into Wide Valleys\",\"Notes on using Determinantal Point Processes for Clustering with\\n  Applications to Text Clustering\",\"Logarithmic Time Online Multiclass prediction\",\"The Loss Surfaces of Multilayer Networks\",\"The Loss Surfaces of Multilayer Networks\",\"Discriminative Learning via Semidefinite Probabilistic Models\",\"The Minimum Information Principle for Discriminative Learning\",\"What Cannot be Learned with Bethe Approximations\",\"Learning Max-Margin Tree Predictors\",\"Learning Max-Margin Tree Predictors\",\"Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs\",\"Robust Conditional Probabilities\",\"Convergent Propagation Algorithms via Oriented Trees\",\"Semi-Supervised Learning with Competitive Infection Models\",\"Learning to generalize to new compositions in image understanding\",\"Learning to generalize to new compositions in image understanding\",\"Learning to generalize to new compositions in image understanding\",\"Learning the Experts for Online Sequence Prediction\",\"Learning the Experts for Online Sequence Prediction\",\"Learning Infinite-Layer Networks: Without the Kernel Trick\",\"Learning Infinite-Layer Networks: Without the Kernel Trick\",\"Gaussian Robust Classification\",\"Convexifying the Bethe Free Energy\",\"Convergent message passing algorithms - a unifying view\",\"Convergent message passing algorithms - a unifying view\",\"A PAC Approach to Application-Specific Algorithm Selection\",\"Ironing in the Dark\",\"The Pseudo-Dimension of Near-Optimal Auctions\",\"The Price of Anarchy in Auctions\",\"The Price of Anarchy in Auctions\"]}},\"id\":\"fb5d5ff8-a09b-4ce6-b431-6fb0901584ab\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"data_source\":{\"id\":\"fb5d5ff8-a09b-4ce6-b431-6fb0901584ab\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"8307c243-b7ce-486c-abfb-ea5335e5ac96\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"selection_glyph\":{\"id\":\"33bb1821-4c20-47d1-92e1-acbe9c50e1d9\",\"type\":\"Circle\"},\"view\":{\"id\":\"93f02e84-d24d-4a17-a515-cfe48350ca41\",\"type\":\"CDSView\"}},\"id\":\"e082f21b-2906-4253-afd9-3f5fbd8f9f0c\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"fb5d5ff8-a09b-4ce6-b431-6fb0901584ab\",\"type\":\"ColumnDataSource\"}},\"id\":\"93f02e84-d24d-4a17-a515-cfe48350ca41\",\"type\":\"CDSView\"},{\"attributes\":{\"fill_color\":{\"value\":\"#abdda4\"},\"size\":{\"units\":\"screen\",\"value\":15}},\"id\":\"33bb1821-4c20-47d1-92e1-acbe9c50e1d9\",\"type\":\"Circle\"},{\"attributes\":{\"line_color\":{\"value\":\"#fdae61\"},\"line_width\":{\"value\":5}},\"id\":\"1910b07b-7c4c-4dea-82ef-3b2b462f544f\",\"type\":\"MultiLine\"},{\"attributes\":{\"line_alpha\":{\"value\":0.8},\"line_color\":{\"value\":\"#CCCCCC\"},\"line_width\":{\"value\":5}},\"id\":\"37c43452-2069-4e54-9c6f-5ff0adeccdbe\",\"type\":\"MultiLine\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"start\",\"end\"],\"data\":{\"end\":[2442,2443,2459,2460,2856,4171,4172,4600,5509,4342,5981,5982,5987,6365,6368,5272,8567,9921,2833,110,2879,2880,1272,2754,2156,15164,15165,266,2703,3931,14944,14945,16581,27594,27595,44743,14771,4111,18864,18865,4343,4344,4389,2708,6124,9633,7078,3638,23361,4162,4586,532,9161,12904,16838,16839,21629,21630,1264,6209,1042,5236,41034,7558,3396,2767,1805,773,774,4530,4533,37453,27,12064,11449,5271,2637,6065,9922,3594,10285,10498,2408,27052,28984,8140,28985,30603,1187,9114,31659,32328,27515,18145,12079,26830,27326,6755,6005,25268],\"start\":[2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2459,2459,2459,2459,2460,2460,2460,4342,4342,4342,4342,4342,4342,4342,4342,4342,4342,5981,5981,5982,5982,5982,5982,5982,5982,5982,5982,5982,5982,5982,6368,6368,6368,6368,6368,6368,6368,6368,6368,6368,6368,6368,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,5272,8567,8567,8567,8567,8567]}},\"id\":\"1c8e1a9c-f06f-4384-ab28-c6668b576491\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"graph_layout\":{\"10285\":[66.926,67.279],\"1042\":[73.637,263.74],\"10498\":[73.637,60.093],\"110\":[218.97,104.55],\"11449\":[38.208,118.35],\"1187\":[131.9,24.663],\"12064\":[35.555,127.82],\"12079\":[190.19,18.671],\"1264\":[88.45,276.66],\"1272\":[229.73,114.6],\"12904\":[131.9,299.17],\"14771\":[309.42,214.74],\"14944\":[246.41,149.68],\"14945\":[247.08,154.55],\"15164\":[238.22,126.63],\"15165\":[240.48,130.99],\"16581\":[247.42,159.46],\"16838\":[122.63,295.88],\"16839\":[113.61,291.96],\"1805\":[35.555,196.01],\"18145\":[180.38,18.0],\"18864\":[300.98,232.49],\"18865\":[295.87,240.89],\"2156\":[235.67,122.43],\"21629\":[104.88,287.44],\"21630\":[96.483,282.33],\"23361\":[180.38,305.83],\"2408\":[80.823,53.381],\"2442\":[247.42,164.37],\"2443\":[247.08,169.28],\"2444\":[175.46,161.92],\"2459\":[244.79,181.34],\"2460\":[238.22,197.2],\"25268\":[237.31,31.873],\"2637\":[45.418,100.07],\"266\":[242.44,135.5],\"26830\":[199.93,20.01],\"27\":[33.554,137.45],\"2703\":[244.09,140.14],\"27052\":[88.45,47.176],\"2708\":[228.29,295.88],\"27326\":[209.55,22.01],\"27515\":[170.54,18.0],\"2754\":[232.83,118.41],\"27594\":[317.37,186.38],\"27595\":[315.37,196.01],\"2767\":[38.208,205.48],\"2833\":[214.95,101.71],\"2856\":[232.83,205.42],\"2879\":[222.78,107.65],\"2880\":[226.37,111.0],\"28984\":[96.483,41.506],\"28985\":[113.61,31.873],\"30603\":[122.63,27.956],\"31659\":[150.99,20.01],\"32328\":[160.73,18.671],\"3396\":[41.5,214.74],\"3594\":[60.721,74.906],\"3638\":[190.19,305.16],\"37453\":[32.215,147.19],\"3931\":[245.41,144.87],\"41034\":[60.721,248.93],\"4111\":[305.5,223.76],\"4162\":[170.54,305.83],\"4171\":[229.73,209.23],\"4172\":[226.37,212.83],\"4342\":[194.89,231.25],\"4343\":[254.44,282.33],\"4344\":[246.04,287.44],\"4389\":[237.31,291.96],\"44743\":[312.71,205.48],\"4530\":[31.544,166.83],\"4533\":[31.544,157.0],\"4586\":[160.73,305.16],\"4600\":[222.78,216.18],\"5236\":[66.926,256.55],\"5271\":[41.5,109.09],\"5272\":[138.05,100.4],\"532\":[150.99,303.82],\"5509\":[218.97,219.29],\"5981\":[165.66,233.25],\"5982\":[135.97,222.12],\"5987\":[115.26,201.4],\"6005\":[228.29,27.956],\"6065\":[49.941,91.34],\"6124\":[219.02,299.17],\"6209\":[80.823,270.45],\"6365\":[112.7,197.2],\"6368\":[103.63,166.83],\"6755\":[219.02,24.663],\"7078\":[199.93,303.82],\"7558\":[45.418,223.76],\"773\":[33.554,186.38],\"774\":[32.215,176.64],\"8140\":[104.88,36.397],\"8567\":[197.24,93.29],\"9114\":[141.37,22.01],\"9161\":[141.37,301.82],\"9633\":[209.55,301.82],\"9921\":[210.75,99.156],\"9922\":[55.05,82.939]}},\"id\":\"734979ff-ccba-4585-bb6e-4a33884e646d\",\"type\":\"StaticLayoutProvider\"},{\"attributes\":{},\"id\":\"f6d5d3f8-3e16-47ac-aed0-79111dc22e46\",\"type\":\"NodesAndLinkedEdges\"},{\"attributes\":{},\"id\":\"26702a3b-0d9a-46d9-9f7b-d3027abdce6f\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"fbbb373e-3dd3-45d4-a1a9-ce818d8cac12\",\"type\":\"NodesOnly\"},{\"attributes\":{},\"id\":\"cc5fb8f6-bcc4-43a6-b6d7-92d348da0390\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"96bd2e61-7f1b-455b-ad0c-0f6d1b630de9\",\"type\":\"WheelZoomTool\"}],\"root_ids\":[\"823695bc-c18a-4a59-bd66-27619ad03bbc\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.7\"}};\n",
       "            var render_items = [{\"docid\":\"47c6125d-7131-4053-a4f4-3d7d6216fb4a\",\"elementid\":\"cee3d2ac-7743-4729-9e9f-316e4825005f\",\"modelid\":\"823695bc-c18a-4a59-bd66-27619ad03bbc\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "          };\n",
       "          if (document.readyState != \"loading\") fn();\n",
       "          else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "        })();\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      \n",
       "      if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "        for (var i = 0; i < inline_js.length; i++) {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        }if (force === true) {\n",
       "          display_loaded();\n",
       "        }} else if (Date.now() < root._bokeh_timeout) {\n",
       "        setTimeout(run_inline_js, 100);\n",
       "      } else if (!root._bokeh_failed_load) {\n",
       "        console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "        root._bokeh_failed_load = true;\n",
       "      } else if (force !== true) {\n",
       "        var cell = $(document.getElementById(\"cee3d2ac-7743-4729-9e9f-316e4825005f\")).parents('.cell').data().cell;\n",
       "        cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "      }\n",
       "  \n",
       "    }\n",
       "  \n",
       "    if (root._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(window));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = graphviz_layout(G, prog='twopi', root = root_node)\n",
    "max_x = max([i[1][0] for i in pos.items()])\n",
    "min_x = min([i[1][0] for i in pos.items()])\n",
    "max_y = max([i[1][1] for i in pos.items()])\n",
    "min_y = min([i[1][1] for i in pos.items()])\n",
    "\n",
    "hover = bokeh.models.tools.HoverTool(tooltips=[(\"Author\",\"@author\"), (\"Source\",\"@source\")])\n",
    "plot = bokeh.plotting.figure(plot_width=1000, plot_height=1000, x_range=bokeh.models.ranges.Range1d(min_x - 20,max_x + 20),\\\n",
    "                             y_range=bokeh.models.ranges.Range1d(min_y - 20,max_y + 20),\\\n",
    "                             tools=[hover, bokeh.models.tools.PanTool(), bokeh.models.tools.WheelZoomTool(), \\\n",
    "                                    bokeh.models.tools.TapTool(), bokeh.models.tools.ResetTool()], \\\n",
    "                             title=\"Network Graph for \" + search.title()\n",
    "                            )\n",
    "\n",
    "nodes = G.nodes()\n",
    "edges = G.edges()\n",
    "edges_start = [edge[0] for edge in edges]\n",
    "edges_end = [edge[1] for edge in edges]\n",
    "node_source = ColumnDataSource(data=dict(index= nodes, \n",
    "                                         fill_color = colours, \n",
    "                                         author = names, \n",
    "                                         source = papers))\n",
    "edge_source = ColumnDataSource(data=dict(\n",
    "                                        start=edges_start,\n",
    "                                        end=edges_end\n",
    "))\n",
    "plot.xaxis.visible = False\n",
    "plot.xgrid.visible = False\n",
    "plot.yaxis.visible = False\n",
    "plot.ygrid.visible = False\n",
    "\n",
    "graph_renderer = bokeh.models.renderers.GraphRenderer()\n",
    "graph_renderer.node_renderer.data_source.data = node_source.data\n",
    "graph_renderer.node_renderer.glyph =  bokeh.models.Circle(size=15, fill_color=\"fill_color\")\n",
    "graph_renderer.node_renderer.selection_glyph =  bokeh.models.Circle(size=15, fill_color=Spectral8[2])\n",
    "graph_renderer.edge_renderer.data_source.data = edge_source.data\n",
    "graph_renderer.edge_renderer.glyph =  bokeh.models.MultiLine(line_color=\"#CCCCCC\", line_alpha=0.8, line_width=5)\n",
    "graph_renderer.edge_renderer.selection_glyph =  bokeh.models.MultiLine(line_color=Spectral4[2], line_width=5)\n",
    "graph_renderer.layout_provider = StaticLayoutProvider(graph_layout=pos)\n",
    "\n",
    "graph_renderer.selection_policy = NodesAndLinkedEdges()\n",
    "\n",
    "plot.renderers.append(graph_renderer)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
